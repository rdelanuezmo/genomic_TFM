{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9npEV6LduOVh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UY_vSsCMnyg",
        "outputId": "463957bb-aed9-4ac0-843c-4626327c24ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0oP9dcSStkFk"
      },
      "outputs": [],
      "source": [
        "filtered_df = pd.read_csv('drive/MyDrive/TFM/GeneRIF/interactions_human_reduced.csv')\n",
        "df = filtered_df[['gene_id','interactant_id']].drop_duplicates().sort_values(by=['gene_id','interactant_id'])\n",
        "graph_df = df.loc[df['gene_id'] != df['interactant_id']]\n",
        "\n",
        "deep_df = pd.read_csv('drive/MyDrive/definitivo/node2vec_embeddings3.csv').drop('Unnamed: 0', axis=1)  # p = q = 1\n",
        "nod1_df = pd.read_csv('drive/MyDrive/definitivo/node2vec_embeddings4.csv').drop('Unnamed: 0', axis=1)  # p = 0.5 ; q = 2\n",
        "nod2_df = pd.read_csv('drive/MyDrive/definitivo/node2vec_embeddings5.csv').drop('Unnamed: 0', axis=1)  # p = 2 ; q = 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dOtynO3YJQrQ"
      },
      "outputs": [],
      "source": [
        "gene_csv = pd.read_csv('drive/MyDrive/TFM/data/gene_information_csv').set_index('gene_id').drop(columns=['pos_min','pos_max'], axis=1)\n",
        "gene_csv.index = gene_csv.index.astype(str)\n",
        "\n",
        "dnabert3_df = pd.read_parquet('drive/MyDrive/TFM/data/embedding_kmer3.parquet').set_index('gene_id')\n",
        "dnabert4_df = pd.read_parquet('drive/MyDrive/TFM/data/embedding_kmer4.parquet').set_index('gene_id')\n",
        "dnabert5_df = pd.read_parquet('drive/MyDrive/TFM/data/embedding_kmer5.parquet').set_index('gene_id')\n",
        "dnabert6_df = pd.read_csv('drive/MyDrive/TFM/data/embedding_dnabert6.csv').drop(columns=['Unnamed: 0']).rename(columns={'gene': 'gene_id'}).set_index('gene_id')\n",
        "\n",
        "dnabert3_df.index = dnabert3_df.index.astype(str)\n",
        "dnabert4_df.index = dnabert4_df.index.astype(str)\n",
        "dnabert5_df.index = dnabert5_df.index.astype(str)\n",
        "dnabert6_df.index = dnabert6_df.index.astype(str)\n",
        "\n",
        "gdnabert3_df = pd.concat([gene_csv, dnabert3_df], axis=1, join='inner').T\n",
        "gdnabert4_df = pd.concat([gene_csv, dnabert4_df], axis=1, join='inner').T\n",
        "gdnabert5_df = pd.concat([gene_csv, dnabert5_df], axis=1, join='inner').T\n",
        "gdnabert6_df = pd.concat([gene_csv, dnabert6_df], axis=1, join='inner').T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K73MOHkDwcde"
      },
      "outputs": [],
      "source": [
        "embedding_dict1 = deep_df.to_dict(orient='list')\n",
        "embedding_dict2 = nod1_df.to_dict(orient='list')\n",
        "embedding_dict3 = nod2_df.to_dict(orient='list')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "heh2j_eAuYDp"
      },
      "outputs": [],
      "source": [
        "G = nx.from_pandas_edgelist(graph_df, source='gene_id', target='interactant_id')\n",
        "node_labels = list(G.nodes())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nDW58mHIusD6"
      },
      "outputs": [],
      "source": [
        "dicc = {}\n",
        "for i, j in enumerate(G.nodes()):\n",
        "  dicc[j] = i\n",
        "\n",
        "idicc = {v: k for k, v in dicc.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0FeRtWp9yi12"
      },
      "outputs": [],
      "source": [
        "positive_edges = list(G.edges())\n",
        "\n",
        "n_positive = len(positive_edges)\n",
        "\n",
        "negative_edges = set()\n",
        "while len(negative_edges) < n_positive:\n",
        "    u, v = random.sample(node_labels, 2)\n",
        "    if not G.has_edge(u, v) and (u, v) not in negative_edges and (v, u) not in negative_edges:\n",
        "        negative_edges.add((u, v))\n",
        "\n",
        "negative_edges = list(negative_edges)\n",
        "\n",
        "edges = positive_edges + negative_edges\n",
        "labels = np.hstack([np.ones(len(positive_edges)), np.zeros(len(negative_edges))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7PI6JEfZzCzO"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(edges, labels, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Rnaiqa0ZzStw"
      },
      "outputs": [],
      "source": [
        "def create_edge_features(edge_list, embedding_dict):\n",
        "    features = []\n",
        "    for u, v in edge_list:\n",
        "        edge_vector = np.concatenate([embedding_dict[str(u)], embedding_dict[str(v)]])\n",
        "        features.append(edge_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "def create_edge_features_mean(edge_list, embedding_dict):\n",
        "    features = []\n",
        "    for u, v in edge_list:\n",
        "        edge_vector = np.mean([embedding_dict[str(u)], embedding_dict[str(v)]], axis=0)\n",
        "        features.append(edge_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "def create_edge_features_df(edge_list, embedding_df):\n",
        "    features = []\n",
        "    i = 0\n",
        "    for u, v in edge_list:\n",
        "        u_vector = embedding_df[str(u)].values\n",
        "        v_vector = embedding_df[str(v)].values\n",
        "\n",
        "        edge_vector = np.mean([u_vector, v_vector], axis=0)\n",
        "        features.append(edge_vector)\n",
        "        i += 1\n",
        "        if i % 1000 == 0:\n",
        "          print(i)\n",
        "\n",
        "    return np.array(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKnj-Ul00mgt"
      },
      "source": [
        "### **DeepWalk**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E72UodNwzyV4"
      },
      "outputs": [],
      "source": [
        "X_train_features = create_edge_features(X_train, embedding_dict1)\n",
        "X_test_features = create_edge_features(X_test, embedding_dict1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joGMtrlbYVXR"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_features = scaler.fit_transform(X_train_features)\n",
        "X_test_features = scaler.transform(X_test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry-xtVIj2lhk"
      },
      "source": [
        "**Regresión Logística**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6kbAg7u2efj",
        "outputId": "76903099-c9ef-4092-df6f-88c065f4f7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7510\n",
            "ROC-AUC Score: 0.8119\n",
            "Precision: 0.8175\n",
            "Recall: 0.7764\n",
            "F1 Score: 0.7964\n",
            "\n",
            "Confusion Matrix:\n",
            "[[106012  43666]\n",
            " [ 56311 195563]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 0: -8.0975\n",
            "Feature 21: -7.4894\n",
            "Feature 1: 7.3389\n",
            "Feature 16: 7.0003\n",
            "Feature 5: 6.8735\n",
            "Feature 13: 6.5623\n",
            "Feature 23: 6.5225\n",
            "Feature 25: -6.2697\n",
            "Feature 18: 5.9456\n",
            "Feature 8: 5.9366\n",
            "Feature 10: -5.9315\n",
            "Feature 52: -5.7944\n",
            "Feature 44: -5.6823\n",
            "Feature 20: -5.5310\n",
            "Feature 59: -5.4909\n",
            "Feature 45: 5.3322\n",
            "Feature 4: -5.3300\n",
            "Feature 60: 4.3999\n",
            "Feature 46: 4.2673\n",
            "Feature 50: -4.2246\n",
            "Feature 35: -4.0246\n",
            "Feature 31: -4.0021\n",
            "Feature 53: -3.9753\n",
            "Feature 14: 3.9247\n",
            "Feature 49: -3.8047\n",
            "Feature 40: -3.6910\n",
            "Feature 3: -3.6572\n",
            "Feature 51: 3.6055\n",
            "Feature 41: -3.4231\n",
            "Feature 30: 3.4136\n",
            "Feature 33: 3.3393\n",
            "Feature 56: 3.2451\n",
            "Feature 26: 3.2051\n",
            "Feature 24: 2.9445\n",
            "Feature 43: -2.8730\n",
            "Feature 55: 2.4209\n",
            "Feature 39: -2.1293\n",
            "Feature 57: 2.1001\n",
            "Feature 62: 2.0768\n",
            "Feature 47: -1.8922\n",
            "Feature 64: -1.7991\n",
            "Feature 38: 1.7877\n",
            "Feature 65: 1.6751\n",
            "Feature 69: 1.6620\n",
            "Feature 22: 1.6599\n",
            "Feature 15: -1.6003\n",
            "Feature 85: -1.5424\n",
            "Feature 12: 1.5267\n",
            "Feature 87: 1.5104\n",
            "Feature 80: 1.4944\n",
            "Feature 72: 1.4762\n",
            "Feature 116: -1.4058\n",
            "Feature 89: -1.3738\n",
            "Feature 63: 1.3489\n",
            "Feature 77: 1.3092\n",
            "Feature 74: -1.3088\n",
            "Feature 84: -1.3046\n",
            "Feature 108: -1.2853\n",
            "Feature 19: -1.2766\n",
            "Feature 82: 1.2674\n",
            "Feature 28: 1.2634\n",
            "Feature 34: -1.1513\n",
            "Feature 9: 1.1110\n",
            "Feature 123: -1.1080\n",
            "Feature 68: -1.0574\n",
            "Feature 109: 1.0388\n",
            "Feature 124: 1.0370\n",
            "Feature 67: -0.9820\n",
            "Feature 110: 0.9369\n",
            "Feature 7: -0.9073\n",
            "Feature 97: 0.8062\n",
            "Feature 58: 0.7983\n",
            "Feature 114: -0.7948\n",
            "Feature 117: -0.7791\n",
            "Feature 104: -0.7504\n",
            "Feature 32: -0.7435\n",
            "Feature 37: 0.7409\n",
            "Feature 90: 0.7309\n",
            "Feature 113: -0.7262\n",
            "Feature 27: -0.7180\n",
            "Feature 107: -0.6845\n",
            "Feature 78: 0.6802\n",
            "Feature 99: -0.6358\n",
            "Feature 105: -0.6295\n",
            "Feature 95: -0.6211\n",
            "Feature 36: -0.6130\n",
            "Feature 88: 0.6124\n",
            "Feature 94: 0.6005\n",
            "Feature 48: 0.5174\n",
            "Feature 119: 0.5065\n",
            "Feature 120: 0.5025\n",
            "Feature 79: -0.4822\n",
            "Feature 115: 0.4715\n",
            "Feature 76: 0.4301\n",
            "Feature 103: -0.4213\n",
            "Feature 121: 0.4213\n",
            "Feature 83: -0.4116\n",
            "Feature 102: 0.4105\n",
            "Feature 2: -0.3708\n",
            "Feature 86: 0.3432\n",
            "Feature 66: -0.3021\n",
            "Feature 42: -0.2861\n",
            "Feature 17: -0.2794\n",
            "Feature 101: 0.2726\n",
            "Feature 73: 0.2607\n",
            "Feature 6: -0.2587\n",
            "Feature 122: 0.2537\n",
            "Feature 98: -0.2453\n",
            "Feature 111: -0.2399\n",
            "Feature 126: 0.2205\n",
            "Feature 92: 0.2203\n",
            "Feature 54: 0.2197\n",
            "Feature 93: 0.1970\n",
            "Feature 61: -0.1916\n",
            "Feature 112: 0.1890\n",
            "Feature 75: 0.1806\n",
            "Feature 11: -0.1671\n",
            "Feature 91: -0.1489\n",
            "Feature 81: -0.1449\n",
            "Feature 71: -0.1296\n",
            "Feature 100: -0.0993\n",
            "Feature 118: 0.0624\n",
            "Feature 96: -0.0472\n",
            "Feature 125: 0.0363\n",
            "Feature 29: 0.0315\n",
            "Feature 70: 0.0310\n",
            "Feature 106: 0.0167\n",
            "Feature 127: 0.0153\n"
          ]
        }
      ],
      "source": [
        "clf = LogisticRegression(random_state=42, penalty='l2', C=1.0, class_weight='balanced')\n",
        "\n",
        "clf.fit(X_train_features, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_features)\n",
        "y_pred_proba = clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "coefficients = clf.coef_[0]\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(coefficients))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, coef in feature_importance:\n",
        "    print(f\"{feature}: {coef:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBra7zTR40g9"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ceZ_BYv40pn",
        "outputId": "dae088cb-0935-45ba-f13d-12e3a6b68a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial RandomForest Model Parameters:\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "RandomForest Model Parameters after Training:\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "RandomForest Model Performance with Specific Parameters\n",
            "Accuracy: 0.7851\n",
            "ROC-AUC Score: 0.8563\n",
            "Precision: 0.7698\n",
            "Recall: 0.8131\n",
            "F1 Score: 0.7909\n",
            "\n",
            "Confusion Matrix:\n",
            "[[190558  61128]\n",
            " [ 46984 204433]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 16: 0.0577\n",
            "Feature 51: 0.0492\n",
            "Feature 50: 0.0439\n",
            "Feature 35: 0.0391\n",
            "Feature 60: 0.0329\n",
            "Feature 14: 0.0325\n",
            "Feature 47: 0.0303\n",
            "Feature 12: 0.0302\n",
            "Feature 19: 0.0289\n",
            "Feature 44: 0.0255\n",
            "Feature 21: 0.0255\n",
            "Feature 31: 0.0243\n",
            "Feature 54: 0.0218\n",
            "Feature 62: 0.0213\n",
            "Feature 32: 0.0206\n",
            "Feature 63: 0.0183\n",
            "Feature 59: 0.0183\n",
            "Feature 5: 0.0181\n",
            "Feature 49: 0.0164\n",
            "Feature 45: 0.0162\n",
            "Feature 55: 0.0157\n",
            "Feature 1: 0.0153\n",
            "Feature 26: 0.0152\n",
            "Feature 39: 0.0146\n",
            "Feature 20: 0.0145\n",
            "Feature 34: 0.0139\n",
            "Feature 18: 0.0134\n",
            "Feature 17: 0.0130\n",
            "Feature 42: 0.0129\n",
            "Feature 56: 0.0129\n",
            "Feature 48: 0.0125\n",
            "Feature 61: 0.0121\n",
            "Feature 23: 0.0113\n",
            "Feature 4: 0.0108\n",
            "Feature 22: 0.0106\n",
            "Feature 37: 0.0102\n",
            "Feature 27: 0.0100\n",
            "Feature 30: 0.0097\n",
            "Feature 38: 0.0097\n",
            "Feature 8: 0.0094\n",
            "Feature 11: 0.0094\n",
            "Feature 46: 0.0092\n",
            "Feature 40: 0.0090\n",
            "Feature 7: 0.0088\n",
            "Feature 3: 0.0088\n",
            "Feature 41: 0.0086\n",
            "Feature 2: 0.0085\n",
            "Feature 24: 0.0080\n",
            "Feature 25: 0.0080\n",
            "Feature 29: 0.0077\n",
            "Feature 0: 0.0074\n",
            "Feature 36: 0.0073\n",
            "Feature 6: 0.0073\n",
            "Feature 15: 0.0071\n",
            "Feature 53: 0.0070\n",
            "Feature 57: 0.0069\n",
            "Feature 10: 0.0062\n",
            "Feature 9: 0.0055\n",
            "Feature 13: 0.0055\n",
            "Feature 52: 0.0053\n",
            "Feature 43: 0.0051\n",
            "Feature 28: 0.0051\n",
            "Feature 58: 0.0049\n",
            "Feature 33: 0.0044\n",
            "Feature 68: 0.0002\n",
            "Feature 78: 0.0002\n",
            "Feature 113: 0.0002\n",
            "Feature 120: 0.0002\n",
            "Feature 81: 0.0002\n",
            "Feature 99: 0.0002\n",
            "Feature 93: 0.0002\n",
            "Feature 125: 0.0002\n",
            "Feature 83: 0.0002\n",
            "Feature 77: 0.0002\n",
            "Feature 88: 0.0002\n",
            "Feature 96: 0.0002\n",
            "Feature 80: 0.0002\n",
            "Feature 91: 0.0002\n",
            "Feature 118: 0.0002\n",
            "Feature 122: 0.0002\n",
            "Feature 127: 0.0002\n",
            "Feature 72: 0.0002\n",
            "Feature 84: 0.0002\n",
            "Feature 105: 0.0002\n",
            "Feature 98: 0.0002\n",
            "Feature 90: 0.0002\n",
            "Feature 87: 0.0002\n",
            "Feature 112: 0.0002\n",
            "Feature 121: 0.0002\n",
            "Feature 114: 0.0002\n",
            "Feature 97: 0.0002\n",
            "Feature 115: 0.0002\n",
            "Feature 79: 0.0002\n",
            "Feature 85: 0.0002\n",
            "Feature 92: 0.0002\n",
            "Feature 119: 0.0002\n",
            "Feature 108: 0.0002\n",
            "Feature 101: 0.0002\n",
            "Feature 110: 0.0002\n",
            "Feature 82: 0.0002\n",
            "Feature 67: 0.0002\n",
            "Feature 89: 0.0002\n",
            "Feature 64: 0.0002\n",
            "Feature 73: 0.0002\n",
            "Feature 76: 0.0002\n",
            "Feature 71: 0.0002\n",
            "Feature 104: 0.0002\n",
            "Feature 106: 0.0002\n",
            "Feature 74: 0.0002\n",
            "Feature 94: 0.0001\n",
            "Feature 126: 0.0001\n",
            "Feature 124: 0.0001\n",
            "Feature 75: 0.0001\n",
            "Feature 103: 0.0001\n",
            "Feature 109: 0.0001\n",
            "Feature 102: 0.0001\n",
            "Feature 69: 0.0001\n",
            "Feature 65: 0.0001\n",
            "Feature 117: 0.0001\n",
            "Feature 70: 0.0001\n",
            "Feature 107: 0.0001\n",
            "Feature 66: 0.0001\n",
            "Feature 123: 0.0001\n",
            "Feature 86: 0.0001\n",
            "Feature 111: 0.0001\n",
            "Feature 95: 0.0001\n",
            "Feature 100: 0.0001\n",
            "Feature 116: 0.0001\n"
          ]
        }
      ],
      "source": [
        "rf_clf = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=10, n_jobs=-1, class_weight='balanced')\n",
        "\n",
        "print(\"Initial RandomForest Model Parameters:\")\n",
        "print(rf_clf.get_params())\n",
        "\n",
        "rf_clf.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"\\nRandomForest Model Parameters after Training:\")\n",
        "print(rf_clf.get_params())\n",
        "\n",
        "rf_y_pred = rf_clf.predict(X_test_features)\n",
        "rf_y_pred_proba = rf_clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        "rf_roc_auc = roc_auc_score(y_test, rf_y_pred_proba)\n",
        "rf_precision = precision_score(y_test, rf_y_pred)\n",
        "rf_recall = recall_score(y_test, rf_y_pred)\n",
        "rf_f1 = f1_score(y_test, rf_y_pred)\n",
        "rf_confusion_matrix = confusion_matrix(y_test, rf_y_pred)\n",
        "\n",
        "print(\"\\nRandomForest Model Performance with Specific Parameters\")\n",
        "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {rf_roc_auc:.4f}\")\n",
        "print(f\"Precision: {rf_precision:.4f}\")\n",
        "print(f\"Recall: {rf_recall:.4f}\")\n",
        "print(f\"F1 Score: {rf_f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(rf_confusion_matrix)\n",
        "\n",
        "feature_importances = rf_clf.feature_importances_\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(feature_importances))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, importance in feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmqHlrwL40we"
      },
      "source": [
        "**XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SPDaUe-404o",
        "outputId": "7fabae33-d1b5-432e-c649-4e411eb4beb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial XGBoost Model Parameters:\n",
            "{'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': 0.999541805558631, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:10:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Model Parameters after Training:\n",
            "{'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': 0.999541805558631, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n",
            "\n",
            "XGBoost Model Performance with Specific Parameters\n",
            "Accuracy: 0.8258\n",
            "ROC-AUC Score: 0.9052\n",
            "Precision: 0.8040\n",
            "Recall: 0.8613\n",
            "F1 Score: 0.8317\n",
            "\n",
            "Confusion Matrix:\n",
            "[[198909  52777]\n",
            " [ 34867 216550]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 16: 0.0299\n",
            "Feature 51: 0.0269\n",
            "Feature 35: 0.0269\n",
            "Feature 55: 0.0226\n",
            "Feature 31: 0.0193\n",
            "Feature 50: 0.0188\n",
            "Feature 21: 0.0184\n",
            "Feature 59: 0.0181\n",
            "Feature 60: 0.0179\n",
            "Feature 32: 0.0174\n",
            "Feature 54: 0.0173\n",
            "Feature 47: 0.0168\n",
            "Feature 23: 0.0162\n",
            "Feature 62: 0.0162\n",
            "Feature 48: 0.0156\n",
            "Feature 49: 0.0155\n",
            "Feature 26: 0.0154\n",
            "Feature 5: 0.0148\n",
            "Feature 14: 0.0147\n",
            "Feature 34: 0.0143\n",
            "Feature 45: 0.0137\n",
            "Feature 20: 0.0135\n",
            "Feature 4: 0.0134\n",
            "Feature 17: 0.0133\n",
            "Feature 61: 0.0132\n",
            "Feature 40: 0.0132\n",
            "Feature 44: 0.0131\n",
            "Feature 8: 0.0131\n",
            "Feature 12: 0.0126\n",
            "Feature 18: 0.0123\n",
            "Feature 39: 0.0119\n",
            "Feature 46: 0.0118\n",
            "Feature 42: 0.0116\n",
            "Feature 57: 0.0116\n",
            "Feature 19: 0.0114\n",
            "Feature 30: 0.0112\n",
            "Feature 1: 0.0110\n",
            "Feature 37: 0.0109\n",
            "Feature 63: 0.0108\n",
            "Feature 15: 0.0107\n",
            "Feature 38: 0.0096\n",
            "Feature 10: 0.0092\n",
            "Feature 0: 0.0090\n",
            "Feature 27: 0.0090\n",
            "Feature 24: 0.0090\n",
            "Feature 56: 0.0088\n",
            "Feature 41: 0.0087\n",
            "Feature 3: 0.0084\n",
            "Feature 13: 0.0084\n",
            "Feature 11: 0.0083\n",
            "Feature 53: 0.0079\n",
            "Feature 22: 0.0077\n",
            "Feature 29: 0.0072\n",
            "Feature 2: 0.0071\n",
            "Feature 28: 0.0069\n",
            "Feature 6: 0.0068\n",
            "Feature 36: 0.0067\n",
            "Feature 52: 0.0065\n",
            "Feature 7: 0.0064\n",
            "Feature 58: 0.0061\n",
            "Feature 33: 0.0060\n",
            "Feature 81: 0.0056\n",
            "Feature 43: 0.0055\n",
            "Feature 25: 0.0054\n",
            "Feature 9: 0.0052\n",
            "Feature 80: 0.0051\n",
            "Feature 84: 0.0048\n",
            "Feature 93: 0.0047\n",
            "Feature 77: 0.0046\n",
            "Feature 67: 0.0044\n",
            "Feature 75: 0.0044\n",
            "Feature 69: 0.0042\n",
            "Feature 115: 0.0042\n",
            "Feature 85: 0.0039\n",
            "Feature 72: 0.0037\n",
            "Feature 90: 0.0037\n",
            "Feature 66: 0.0036\n",
            "Feature 86: 0.0036\n",
            "Feature 118: 0.0036\n",
            "Feature 78: 0.0036\n",
            "Feature 105: 0.0035\n",
            "Feature 94: 0.0035\n",
            "Feature 102: 0.0035\n",
            "Feature 98: 0.0034\n",
            "Feature 120: 0.0034\n",
            "Feature 116: 0.0034\n",
            "Feature 88: 0.0034\n",
            "Feature 123: 0.0034\n",
            "Feature 74: 0.0034\n",
            "Feature 127: 0.0034\n",
            "Feature 103: 0.0032\n",
            "Feature 79: 0.0032\n",
            "Feature 113: 0.0031\n",
            "Feature 87: 0.0030\n",
            "Feature 100: 0.0030\n",
            "Feature 121: 0.0030\n",
            "Feature 73: 0.0030\n",
            "Feature 111: 0.0030\n",
            "Feature 114: 0.0029\n",
            "Feature 70: 0.0029\n",
            "Feature 125: 0.0029\n",
            "Feature 83: 0.0029\n",
            "Feature 68: 0.0029\n",
            "Feature 119: 0.0029\n",
            "Feature 95: 0.0028\n",
            "Feature 122: 0.0028\n",
            "Feature 76: 0.0028\n",
            "Feature 92: 0.0028\n",
            "Feature 71: 0.0028\n",
            "Feature 65: 0.0027\n",
            "Feature 110: 0.0026\n",
            "Feature 109: 0.0026\n",
            "Feature 97: 0.0026\n",
            "Feature 107: 0.0026\n",
            "Feature 117: 0.0026\n",
            "Feature 91: 0.0026\n",
            "Feature 89: 0.0025\n",
            "Feature 112: 0.0025\n",
            "Feature 82: 0.0025\n",
            "Feature 101: 0.0025\n",
            "Feature 124: 0.0024\n",
            "Feature 126: 0.0024\n",
            "Feature 106: 0.0024\n",
            "Feature 99: 0.0022\n",
            "Feature 96: 0.0021\n",
            "Feature 108: 0.0021\n",
            "Feature 64: 0.0018\n",
            "Feature 104: 0.0018\n"
          ]
        }
      ],
      "source": [
        "negative_class_count = sum(y_train == 0)\n",
        "positive_class_count = sum(y_train == 1)\n",
        "scale_pos_weight = negative_class_count / positive_class_count\n",
        "\n",
        "xgb_clf = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=scale_pos_weight)\n",
        "\n",
        "print(\"Initial XGBoost Model Parameters:\")\n",
        "print(xgb_clf.get_params())\n",
        "\n",
        "xgb_clf.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"\\nXGBoost Model Parameters after Training:\")\n",
        "print(xgb_clf.get_params())\n",
        "\n",
        "xgb_y_pred = xgb_clf.predict(X_test_features)\n",
        "xgb_y_pred_proba = xgb_clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
        "xgb_roc_auc = roc_auc_score(y_test, xgb_y_pred_proba)\n",
        "xgb_precision = precision_score(y_test, xgb_y_pred)\n",
        "xgb_recall = recall_score(y_test, xgb_y_pred)\n",
        "xgb_f1 = f1_score(y_test, xgb_y_pred)\n",
        "xgb_confusion_matrix = confusion_matrix(y_test, xgb_y_pred)\n",
        "\n",
        "print(\"\\nXGBoost Model Performance with Specific Parameters\")\n",
        "print(f\"Accuracy: {xgb_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {xgb_roc_auc:.4f}\")\n",
        "print(f\"Precision: {xgb_precision:.4f}\")\n",
        "print(f\"Recall: {xgb_recall:.4f}\")\n",
        "print(f\"F1 Score: {xgb_f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(xgb_confusion_matrix)\n",
        "\n",
        "feature_importances = xgb_clf.feature_importances_\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(feature_importances))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, importance in feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp6Z6-VB0t28"
      },
      "source": [
        "### **node2vec [p = 0.5 y q = 2]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYwnUOpE0eFZ"
      },
      "outputs": [],
      "source": [
        "X_train_features = create_edge_features(X_train, embedding_dict2)\n",
        "X_test_features = create_edge_features(X_test, embedding_dict2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IX1qOr9Yek5"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_features = scaler.fit_transform(X_train_features)\n",
        "X_test_features = scaler.transform(X_test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LEPU9Bs4Hkx"
      },
      "source": [
        "**Regresión Logística**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKb1Gzx94AdC",
        "outputId": "a0e26c86-f587-49dc-d5bb-0c032a5062ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7388\n",
            "ROC-AUC Score: 0.7946\n",
            "Precision: 0.8055\n",
            "Recall: 0.7694\n",
            "F1 Score: 0.7870\n",
            "\n",
            "Confusion Matrix:\n",
            "[[102874  46804]\n",
            " [ 58085 193789]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 16: 8.8205\n",
            "Feature 0: -6.3292\n",
            "Feature 52: -5.4533\n",
            "Feature 13: 5.3772\n",
            "Feature 20: -5.2453\n",
            "Feature 49: -5.1376\n",
            "Feature 14: 4.9219\n",
            "Feature 25: -4.5955\n",
            "Feature 19: -4.5304\n",
            "Feature 37: 4.2115\n",
            "Feature 8: 4.1585\n",
            "Feature 12: 4.1442\n",
            "Feature 56: 4.0905\n",
            "Feature 61: 4.0843\n",
            "Feature 59: -3.8058\n",
            "Feature 40: -3.3348\n",
            "Feature 7: 3.1986\n",
            "Feature 23: 3.1442\n",
            "Feature 47: 3.1353\n",
            "Feature 26: 3.0765\n",
            "Feature 10: -2.8974\n",
            "Feature 33: 2.8419\n",
            "Feature 50: -2.8362\n",
            "Feature 5: 2.7967\n",
            "Feature 3: -2.7467\n",
            "Feature 53: -2.6054\n",
            "Feature 57: 2.6003\n",
            "Feature 51: 2.4651\n",
            "Feature 39: -2.4183\n",
            "Feature 44: -2.3069\n",
            "Feature 60: 2.2764\n",
            "Feature 31: -2.2628\n",
            "Feature 11: 2.2082\n",
            "Feature 2: -2.1018\n",
            "Feature 28: -2.0773\n",
            "Feature 45: 1.9162\n",
            "Feature 36: 1.8923\n",
            "Feature 17: 1.8654\n",
            "Feature 1: 1.8373\n",
            "Feature 22: -1.7763\n",
            "Feature 21: -1.7483\n",
            "Feature 48: 1.7105\n",
            "Feature 32: 1.5874\n",
            "Feature 80: 1.5608\n",
            "Feature 18: 1.4448\n",
            "Feature 29: -1.3601\n",
            "Feature 9: 1.2837\n",
            "Feature 43: 1.1446\n",
            "Feature 54: -1.0855\n",
            "Feature 46: -1.0844\n",
            "Feature 84: -1.0753\n",
            "Feature 64: -1.0662\n",
            "Feature 38: 0.9991\n",
            "Feature 41: -0.8927\n",
            "Feature 89: -0.8570\n",
            "Feature 62: -0.8346\n",
            "Feature 78: 0.8186\n",
            "Feature 15: -0.8161\n",
            "Feature 30: 0.8137\n",
            "Feature 116: -0.8011\n",
            "Feature 77: 0.7976\n",
            "Feature 76: 0.7895\n",
            "Feature 72: 0.7693\n",
            "Feature 83: -0.7365\n",
            "Feature 111: 0.7183\n",
            "Feature 113: -0.7141\n",
            "Feature 58: -0.7047\n",
            "Feature 6: -0.6983\n",
            "Feature 87: 0.6655\n",
            "Feature 55: -0.6518\n",
            "Feature 104: -0.6512\n",
            "Feature 125: 0.6255\n",
            "Feature 123: -0.6150\n",
            "Feature 101: 0.5988\n",
            "Feature 90: 0.5980\n",
            "Feature 103: -0.5833\n",
            "Feature 69: 0.5665\n",
            "Feature 124: 0.5558\n",
            "Feature 114: -0.5550\n",
            "Feature 120: 0.5521\n",
            "Feature 109: 0.5466\n",
            "Feature 92: -0.5322\n",
            "Feature 117: -0.5246\n",
            "Feature 67: -0.5207\n",
            "Feature 42: 0.5008\n",
            "Feature 97: 0.4928\n",
            "Feature 121: 0.4910\n",
            "Feature 75: 0.4906\n",
            "Feature 74: -0.4707\n",
            "Feature 4: 0.4587\n",
            "Feature 115: 0.4328\n",
            "Feature 85: -0.4319\n",
            "Feature 108: -0.4109\n",
            "Feature 71: 0.3940\n",
            "Feature 66: -0.3831\n",
            "Feature 73: 0.3742\n",
            "Feature 96: 0.3659\n",
            "Feature 34: -0.3594\n",
            "Feature 63: 0.3354\n",
            "Feature 65: 0.3340\n",
            "Feature 81: 0.2758\n",
            "Feature 106: 0.2593\n",
            "Feature 93: -0.2532\n",
            "Feature 105: -0.2471\n",
            "Feature 100: 0.2352\n",
            "Feature 95: -0.2276\n",
            "Feature 107: 0.2175\n",
            "Feature 79: -0.1988\n",
            "Feature 126: -0.1916\n",
            "Feature 119: -0.1853\n",
            "Feature 35: 0.1679\n",
            "Feature 94: 0.1669\n",
            "Feature 110: -0.1566\n",
            "Feature 82: 0.1461\n",
            "Feature 118: -0.1214\n",
            "Feature 98: 0.1152\n",
            "Feature 122: -0.1014\n",
            "Feature 88: 0.0881\n",
            "Feature 112: -0.0848\n",
            "Feature 91: -0.0848\n",
            "Feature 24: 0.0765\n",
            "Feature 27: 0.0726\n",
            "Feature 70: 0.0686\n",
            "Feature 68: -0.0567\n",
            "Feature 86: -0.0440\n",
            "Feature 127: 0.0347\n",
            "Feature 102: 0.0276\n",
            "Feature 99: 0.0125\n"
          ]
        }
      ],
      "source": [
        "clf = LogisticRegression(random_state=42, penalty='l2', C=1.0, class_weight='balanced')\n",
        "\n",
        "clf.fit(X_train_features, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_features)\n",
        "y_pred_proba = clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "coefficients = clf.coef_[0]\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(coefficients))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, coef in feature_importance:\n",
        "    print(f\"{feature}: {coef:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtegRpw_4OBR"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFkhyOdo4Pde",
        "outputId": "0ac5244f-6f6d-47bb-9c19-6a053c340492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial RandomForest Model Parameters:\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "RandomForest Model Parameters after Training:\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "RandomForest Model Performance with Specific Parameters\n",
            "Accuracy: 0.7848\n",
            "ROC-AUC Score: 0.8484\n",
            "Precision: 0.7637\n",
            "Recall: 0.9514\n",
            "\n",
            "Feature Importance:\n",
            "Feature 1: 0.0687\n",
            "Feature 51: 0.0508\n",
            "Feature 56: 0.0419\n",
            "Feature 42: 0.0390\n",
            "Feature 44: 0.0362\n",
            "Feature 9: 0.0320\n",
            "Feature 40: 0.0309\n",
            "Feature 63: 0.0298\n",
            "Feature 52: 0.0278\n",
            "Feature 29: 0.0238\n",
            "Feature 3: 0.0225\n",
            "Feature 23: 0.0222\n",
            "Feature 10: 0.0216\n",
            "Feature 39: 0.0204\n",
            "Feature 8: 0.0194\n",
            "Feature 16: 0.0180\n",
            "Feature 45: 0.0163\n",
            "Feature 33: 0.0157\n",
            "Feature 26: 0.0157\n",
            "Feature 17: 0.0150\n",
            "Feature 4: 0.0149\n",
            "Feature 28: 0.0146\n",
            "Feature 22: 0.0145\n",
            "Feature 11: 0.0139\n",
            "Feature 43: 0.0136\n",
            "Feature 20: 0.0124\n",
            "Feature 48: 0.0121\n",
            "Feature 30: 0.0119\n",
            "Feature 5: 0.0116\n",
            "Feature 15: 0.0114\n",
            "Feature 25: 0.0112\n",
            "Feature 49: 0.0110\n",
            "Feature 14: 0.0108\n",
            "Feature 41: 0.0106\n",
            "Feature 36: 0.0101\n",
            "Feature 47: 0.0099\n",
            "Feature 2: 0.0099\n",
            "Feature 60: 0.0098\n",
            "Feature 35: 0.0096\n",
            "Feature 57: 0.0095\n",
            "Feature 19: 0.0095\n",
            "Feature 58: 0.0094\n",
            "Feature 21: 0.0094\n",
            "Feature 31: 0.0093\n",
            "Feature 53: 0.0092\n",
            "Feature 6: 0.0091\n",
            "Feature 18: 0.0085\n",
            "Feature 0: 0.0083\n",
            "Feature 13: 0.0083\n",
            "Feature 24: 0.0080\n",
            "Feature 62: 0.0079\n",
            "Feature 38: 0.0078\n",
            "Feature 34: 0.0077\n",
            "Feature 12: 0.0077\n",
            "Feature 27: 0.0074\n",
            "Feature 50: 0.0073\n",
            "Feature 7: 0.0070\n",
            "Feature 46: 0.0069\n",
            "Feature 37: 0.0068\n",
            "Feature 59: 0.0067\n",
            "Feature 54: 0.0067\n",
            "Feature 32: 0.0064\n",
            "Feature 61: 0.0051\n",
            "Feature 55: 0.0050\n",
            "Feature 117: 0.0003\n",
            "Feature 109: 0.0003\n",
            "Feature 106: 0.0003\n",
            "Feature 108: 0.0003\n",
            "Feature 68: 0.0002\n",
            "Feature 87: 0.0002\n",
            "Feature 85: 0.0002\n",
            "Feature 114: 0.0002\n",
            "Feature 121: 0.0002\n",
            "Feature 122: 0.0002\n",
            "Feature 75: 0.0002\n",
            "Feature 118: 0.0002\n",
            "Feature 69: 0.0002\n",
            "Feature 78: 0.0002\n",
            "Feature 81: 0.0002\n",
            "Feature 65: 0.0002\n",
            "Feature 72: 0.0002\n",
            "Feature 103: 0.0002\n",
            "Feature 97: 0.0002\n",
            "Feature 82: 0.0002\n",
            "Feature 84: 0.0002\n",
            "Feature 77: 0.0002\n",
            "Feature 88: 0.0002\n",
            "Feature 116: 0.0002\n",
            "Feature 105: 0.0002\n",
            "Feature 74: 0.0002\n",
            "Feature 119: 0.0002\n",
            "Feature 71: 0.0002\n",
            "Feature 100: 0.0002\n",
            "Feature 96: 0.0002\n",
            "Feature 90: 0.0002\n",
            "Feature 89: 0.0002\n",
            "Feature 94: 0.0002\n",
            "Feature 115: 0.0002\n",
            "Feature 79: 0.0002\n",
            "Feature 92: 0.0002\n",
            "Feature 124: 0.0002\n",
            "Feature 110: 0.0002\n",
            "Feature 120: 0.0002\n",
            "Feature 111: 0.0002\n",
            "Feature 93: 0.0002\n",
            "Feature 112: 0.0002\n",
            "Feature 123: 0.0002\n",
            "Feature 125: 0.0002\n",
            "Feature 104: 0.0002\n",
            "Feature 64: 0.0002\n",
            "Feature 126: 0.0002\n",
            "Feature 67: 0.0002\n",
            "Feature 98: 0.0002\n",
            "Feature 83: 0.0002\n",
            "Feature 113: 0.0002\n",
            "Feature 91: 0.0002\n",
            "Feature 66: 0.0002\n",
            "Feature 99: 0.0002\n",
            "Feature 80: 0.0002\n",
            "Feature 107: 0.0002\n",
            "Feature 101: 0.0002\n",
            "Feature 102: 0.0002\n",
            "Feature 70: 0.0002\n",
            "Feature 95: 0.0002\n",
            "Feature 127: 0.0002\n",
            "Feature 86: 0.0002\n",
            "Feature 73: 0.0002\n",
            "Feature 76: 0.0002\n"
          ]
        }
      ],
      "source": [
        "rf_clf = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=10, n_jobs=-1)\n",
        "\n",
        "print(\"Initial RandomForest Model Parameters:\")\n",
        "print(rf_clf.get_params())\n",
        "\n",
        "rf_clf.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"\\nRandomForest Model Parameters after Training:\")\n",
        "print(rf_clf.get_params())\n",
        "\n",
        "rf_y_pred = rf_clf.predict(X_test_features)\n",
        "rf_y_pred_proba = rf_clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        "rf_roc_auc = roc_auc_score(y_test, rf_y_pred_proba)\n",
        "rf_precision = precision_score(y_test, rf_y_pred)\n",
        "rf_recall = recall_score(y_test, rf_y_pred)\n",
        "\n",
        "print(\"\\nRandomForest Model Performance with Specific Parameters\")\n",
        "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {rf_roc_auc:.4f}\")\n",
        "print(f\"Precision: {rf_precision:.4f}\")\n",
        "print(f\"Recall: {rf_recall:.4f}\")\n",
        "\n",
        "feature_importances = rf_clf.feature_importances_\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(feature_importances))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, importance in feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmLvLXlh4Pn4"
      },
      "source": [
        "**XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3fZIWrX4Pzq",
        "outputId": "0c8b7053-2359-4d3e-fe81-ed52bad88fa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial XGBoost Model Parameters:\n",
            "{'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': 0.999541805558631, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:18:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Model Parameters after Training:\n",
            "{'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': 0.999541805558631, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n",
            "\n",
            "XGBoost Model Performance with Specific Parameters\n",
            "Accuracy: 0.8241\n",
            "ROC-AUC Score: 0.9043\n",
            "Precision: 0.8020\n",
            "Recall: 0.8604\n",
            "F1 Score: 0.8302\n",
            "\n",
            "Confusion Matrix:\n",
            "[[198266  53420]\n",
            " [ 35089 216328]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 1: 0.0265\n",
            "Feature 56: 0.0261\n",
            "Feature 42: 0.0260\n",
            "Feature 40: 0.0250\n",
            "Feature 51: 0.0239\n",
            "Feature 52: 0.0203\n",
            "Feature 44: 0.0200\n",
            "Feature 23: 0.0184\n",
            "Feature 16: 0.0178\n",
            "Feature 4: 0.0175\n",
            "Feature 9: 0.0172\n",
            "Feature 63: 0.0168\n",
            "Feature 10: 0.0159\n",
            "Feature 29: 0.0157\n",
            "Feature 48: 0.0156\n",
            "Feature 3: 0.0151\n",
            "Feature 8: 0.0146\n",
            "Feature 41: 0.0144\n",
            "Feature 33: 0.0143\n",
            "Feature 39: 0.0137\n",
            "Feature 28: 0.0133\n",
            "Feature 35: 0.0130\n",
            "Feature 59: 0.0124\n",
            "Feature 38: 0.0120\n",
            "Feature 19: 0.0118\n",
            "Feature 22: 0.0118\n",
            "Feature 17: 0.0117\n",
            "Feature 30: 0.0116\n",
            "Feature 20: 0.0115\n",
            "Feature 5: 0.0115\n",
            "Feature 26: 0.0113\n",
            "Feature 49: 0.0109\n",
            "Feature 53: 0.0106\n",
            "Feature 50: 0.0105\n",
            "Feature 43: 0.0105\n",
            "Feature 45: 0.0105\n",
            "Feature 25: 0.0104\n",
            "Feature 60: 0.0104\n",
            "Feature 14: 0.0101\n",
            "Feature 58: 0.0099\n",
            "Feature 34: 0.0093\n",
            "Feature 2: 0.0093\n",
            "Feature 11: 0.0090\n",
            "Feature 32: 0.0090\n",
            "Feature 27: 0.0088\n",
            "Feature 18: 0.0084\n",
            "Feature 47: 0.0083\n",
            "Feature 6: 0.0082\n",
            "Feature 13: 0.0082\n",
            "Feature 62: 0.0082\n",
            "Feature 7: 0.0080\n",
            "Feature 21: 0.0080\n",
            "Feature 15: 0.0080\n",
            "Feature 0: 0.0079\n",
            "Feature 37: 0.0079\n",
            "Feature 36: 0.0079\n",
            "Feature 57: 0.0076\n",
            "Feature 31: 0.0075\n",
            "Feature 24: 0.0074\n",
            "Feature 55: 0.0071\n",
            "Feature 46: 0.0068\n",
            "Feature 61: 0.0061\n",
            "Feature 101: 0.0056\n",
            "Feature 84: 0.0055\n",
            "Feature 54: 0.0053\n",
            "Feature 89: 0.0051\n",
            "Feature 113: 0.0051\n",
            "Feature 112: 0.0049\n",
            "Feature 97: 0.0047\n",
            "Feature 88: 0.0046\n",
            "Feature 108: 0.0044\n",
            "Feature 117: 0.0043\n",
            "Feature 95: 0.0043\n",
            "Feature 119: 0.0042\n",
            "Feature 12: 0.0042\n",
            "Feature 98: 0.0041\n",
            "Feature 109: 0.0041\n",
            "Feature 90: 0.0040\n",
            "Feature 124: 0.0039\n",
            "Feature 79: 0.0039\n",
            "Feature 114: 0.0039\n",
            "Feature 87: 0.0038\n",
            "Feature 92: 0.0038\n",
            "Feature 103: 0.0037\n",
            "Feature 68: 0.0037\n",
            "Feature 86: 0.0035\n",
            "Feature 77: 0.0035\n",
            "Feature 82: 0.0034\n",
            "Feature 73: 0.0034\n",
            "Feature 74: 0.0034\n",
            "Feature 110: 0.0034\n",
            "Feature 69: 0.0033\n",
            "Feature 80: 0.0033\n",
            "Feature 104: 0.0033\n",
            "Feature 96: 0.0033\n",
            "Feature 111: 0.0033\n",
            "Feature 70: 0.0031\n",
            "Feature 125: 0.0031\n",
            "Feature 85: 0.0031\n",
            "Feature 102: 0.0031\n",
            "Feature 93: 0.0031\n",
            "Feature 100: 0.0031\n",
            "Feature 67: 0.0030\n",
            "Feature 81: 0.0029\n",
            "Feature 106: 0.0029\n",
            "Feature 76: 0.0029\n",
            "Feature 105: 0.0028\n",
            "Feature 66: 0.0027\n",
            "Feature 72: 0.0027\n",
            "Feature 116: 0.0027\n",
            "Feature 94: 0.0027\n",
            "Feature 126: 0.0027\n",
            "Feature 127: 0.0027\n",
            "Feature 118: 0.0026\n",
            "Feature 75: 0.0026\n",
            "Feature 115: 0.0026\n",
            "Feature 120: 0.0026\n",
            "Feature 99: 0.0026\n",
            "Feature 121: 0.0025\n",
            "Feature 71: 0.0025\n",
            "Feature 91: 0.0024\n",
            "Feature 64: 0.0024\n",
            "Feature 83: 0.0023\n",
            "Feature 78: 0.0023\n",
            "Feature 107: 0.0022\n",
            "Feature 65: 0.0020\n",
            "Feature 122: 0.0019\n",
            "Feature 123: 0.0018\n"
          ]
        }
      ],
      "source": [
        "negative_class_count = sum(y_train == 0)\n",
        "positive_class_count = sum(y_train == 1)\n",
        "scale_pos_weight = negative_class_count / positive_class_count\n",
        "\n",
        "xgb_clf = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=scale_pos_weight)\n",
        "\n",
        "print(\"Initial XGBoost Model Parameters:\")\n",
        "print(xgb_clf.get_params())\n",
        "\n",
        "xgb_clf.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"\\nXGBoost Model Parameters after Training:\")\n",
        "print(xgb_clf.get_params())\n",
        "\n",
        "xgb_y_pred = xgb_clf.predict(X_test_features)\n",
        "xgb_y_pred_proba = xgb_clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
        "xgb_roc_auc = roc_auc_score(y_test, xgb_y_pred_proba)\n",
        "xgb_precision = precision_score(y_test, xgb_y_pred)\n",
        "xgb_recall = recall_score(y_test, xgb_y_pred)\n",
        "xgb_f1 = f1_score(y_test, xgb_y_pred)\n",
        "xgb_confusion_matrix = confusion_matrix(y_test, xgb_y_pred)\n",
        "\n",
        "print(\"\\nXGBoost Model Performance with Specific Parameters\")\n",
        "print(f\"Accuracy: {xgb_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {xgb_roc_auc:.4f}\")\n",
        "print(f\"Precision: {xgb_precision:.4f}\")\n",
        "print(f\"Recall: {xgb_recall:.4f}\")\n",
        "print(f\"F1 Score: {xgb_f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(xgb_confusion_matrix)\n",
        "\n",
        "feature_importances = xgb_clf.feature_importances_\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(feature_importances))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, importance in feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu0dQnsa072O"
      },
      "source": [
        "### **node2vec** [p = 2 y q = 0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAXdBSZA0eOn"
      },
      "outputs": [],
      "source": [
        "X_train_features = create_edge_features(X_train, embedding_dict3)\n",
        "X_test_features = create_edge_features(X_test, embedding_dict3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omydo0_5awOs"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_features = scaler.fit_transform(X_train_features)\n",
        "X_test_features = scaler.transform(X_test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMRJWRmB4K9K"
      },
      "source": [
        "**Regresión Logística**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25OswoXX4Dsk",
        "outputId": "bd7de89c-cbbe-4763-b272-1b650106ec66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7563\n",
            "ROC-AUC Score: 0.8203\n",
            "Precision: 0.8222\n",
            "Recall: 0.7802\n",
            "F1 Score: 0.8006\n",
            "\n",
            "Confusion Matrix:\n",
            "[[107173  42505]\n",
            " [ 55371 196503]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 0: -11.7498\n",
            "Feature 16: 10.0500\n",
            "Feature 26: 9.9966\n",
            "Feature 29: -8.3773\n",
            "Feature 23: 7.5330\n",
            "Feature 20: -6.8936\n",
            "Feature 44: -6.7206\n",
            "Feature 62: 6.2197\n",
            "Feature 5: 6.1112\n",
            "Feature 8: 6.0667\n",
            "Feature 1: 5.8001\n",
            "Feature 10: -5.7669\n",
            "Feature 19: -5.7470\n",
            "Feature 54: -5.5753\n",
            "Feature 17: 5.5124\n",
            "Feature 25: -5.2928\n",
            "Feature 35: -5.0806\n",
            "Feature 49: -4.9880\n",
            "Feature 3: -4.8704\n",
            "Feature 60: 4.7246\n",
            "Feature 18: 4.6630\n",
            "Feature 59: -4.6302\n",
            "Feature 40: -4.4945\n",
            "Feature 34: -4.3835\n",
            "Feature 2: -4.1879\n",
            "Feature 57: 3.8619\n",
            "Feature 45: 3.7292\n",
            "Feature 50: -3.6287\n",
            "Feature 43: 3.5879\n",
            "Feature 15: -3.4904\n",
            "Feature 33: 3.4471\n",
            "Feature 24: 3.4398\n",
            "Feature 63: -3.0112\n",
            "Feature 21: -3.0062\n",
            "Feature 31: -2.8416\n",
            "Feature 42: -2.7943\n",
            "Feature 11: 2.7932\n",
            "Feature 36: 2.6792\n",
            "Feature 55: -2.6616\n",
            "Feature 47: 2.4696\n",
            "Feature 53: -2.3162\n",
            "Feature 64: -2.2361\n",
            "Feature 38: -2.1993\n",
            "Feature 52: -2.1401\n",
            "Feature 28: -2.0623\n",
            "Feature 7: 1.9823\n",
            "Feature 46: 1.9503\n",
            "Feature 37: 1.9172\n",
            "Feature 90: 1.9051\n",
            "Feature 30: 1.8982\n",
            "Feature 9: 1.8383\n",
            "Feature 80: 1.7865\n",
            "Feature 13: 1.6807\n",
            "Feature 6: -1.3850\n",
            "Feature 27: -1.3724\n",
            "Feature 93: -1.3549\n",
            "Feature 87: 1.3135\n",
            "Feature 12: 1.2881\n",
            "Feature 108: -1.2668\n",
            "Feature 69: 1.2453\n",
            "Feature 51: 1.2242\n",
            "Feature 74: -1.1958\n",
            "Feature 126: 1.1935\n",
            "Feature 83: -1.1687\n",
            "Feature 84: -1.1686\n",
            "Feature 81: 1.1659\n",
            "Feature 14: 1.1275\n",
            "Feature 89: -1.1202\n",
            "Feature 65: 1.0806\n",
            "Feature 124: 1.0530\n",
            "Feature 72: 1.0102\n",
            "Feature 118: -0.9616\n",
            "Feature 67: -0.9278\n",
            "Feature 99: -0.9185\n",
            "Feature 98: -0.9002\n",
            "Feature 123: -0.8844\n",
            "Feature 61: 0.8800\n",
            "Feature 41: -0.8436\n",
            "Feature 121: 0.8126\n",
            "Feature 82: 0.8024\n",
            "Feature 66: -0.7998\n",
            "Feature 88: 0.7674\n",
            "Feature 32: -0.7662\n",
            "Feature 79: -0.7596\n",
            "Feature 75: 0.7286\n",
            "Feature 127: -0.7185\n",
            "Feature 113: -0.7084\n",
            "Feature 97: 0.6978\n",
            "Feature 107: 0.6640\n",
            "Feature 48: 0.6429\n",
            "Feature 85: -0.6169\n",
            "Feature 56: -0.6158\n",
            "Feature 104: -0.5591\n",
            "Feature 109: 0.5501\n",
            "Feature 114: -0.5401\n",
            "Feature 116: -0.5375\n",
            "Feature 122: 0.4940\n",
            "Feature 95: -0.4772\n",
            "Feature 100: 0.4396\n",
            "Feature 111: 0.4203\n",
            "Feature 92: -0.4006\n",
            "Feature 58: 0.4003\n",
            "Feature 110: 0.3968\n",
            "Feature 106: -0.3620\n",
            "Feature 73: 0.3604\n",
            "Feature 119: -0.3543\n",
            "Feature 102: -0.3526\n",
            "Feature 39: 0.3517\n",
            "Feature 91: -0.3494\n",
            "Feature 120: -0.3488\n",
            "Feature 117: -0.3205\n",
            "Feature 105: -0.3191\n",
            "Feature 4: -0.3186\n",
            "Feature 94: 0.3174\n",
            "Feature 77: 0.3159\n",
            "Feature 76: 0.3130\n",
            "Feature 101: 0.2689\n",
            "Feature 70: -0.2042\n",
            "Feature 125: 0.1809\n",
            "Feature 71: 0.1730\n",
            "Feature 78: 0.1637\n",
            "Feature 96: -0.1433\n",
            "Feature 103: -0.1411\n",
            "Feature 86: -0.1242\n",
            "Feature 68: -0.1139\n",
            "Feature 22: -0.0879\n",
            "Feature 115: 0.0807\n",
            "Feature 112: 0.0478\n"
          ]
        }
      ],
      "source": [
        "clf = LogisticRegression(random_state=42, penalty='l2', C=1.0, class_weight='balanced')\n",
        "\n",
        "clf.fit(X_train_features, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_features)\n",
        "y_pred_proba = clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "coefficients = clf.coef_[0]\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(coefficients))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, coef in feature_importance:\n",
        "    print(f\"{feature}: {coef:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrijjRUo4p1G"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2bfgJ5z4qAP",
        "outputId": "157d81b5-ae80-47f6-c92b-1eafc45098bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial RandomForest Model Parameters:\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "RandomForest Model Parameters after Training:\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "RandomForest Model Performance with Specific Parameters\n",
            "Accuracy: 0.7761\n",
            "ROC-AUC Score: 0.8505\n",
            "Precision: 0.7538\n",
            "Recall: 0.8196\n",
            "F1 Score: 0.7853\n",
            "\n",
            "Confusion Matrix:\n",
            "[[184387  67299]\n",
            " [ 45368 206049]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 29: 0.0762\n",
            "Feature 13: 0.0498\n",
            "Feature 51: 0.0490\n",
            "Feature 8: 0.0409\n",
            "Feature 4: 0.0395\n",
            "Feature 54: 0.0373\n",
            "Feature 56: 0.0286\n",
            "Feature 35: 0.0282\n",
            "Feature 11: 0.0276\n",
            "Feature 17: 0.0264\n",
            "Feature 41: 0.0254\n",
            "Feature 53: 0.0253\n",
            "Feature 5: 0.0217\n",
            "Feature 39: 0.0191\n",
            "Feature 14: 0.0189\n",
            "Feature 10: 0.0187\n",
            "Feature 7: 0.0179\n",
            "Feature 24: 0.0174\n",
            "Feature 20: 0.0171\n",
            "Feature 37: 0.0164\n",
            "Feature 21: 0.0162\n",
            "Feature 49: 0.0149\n",
            "Feature 58: 0.0145\n",
            "Feature 40: 0.0143\n",
            "Feature 34: 0.0140\n",
            "Feature 19: 0.0128\n",
            "Feature 0: 0.0125\n",
            "Feature 33: 0.0118\n",
            "Feature 42: 0.0110\n",
            "Feature 36: 0.0106\n",
            "Feature 2: 0.0100\n",
            "Feature 31: 0.0098\n",
            "Feature 28: 0.0097\n",
            "Feature 60: 0.0092\n",
            "Feature 1: 0.0091\n",
            "Feature 22: 0.0090\n",
            "Feature 25: 0.0086\n",
            "Feature 50: 0.0085\n",
            "Feature 61: 0.0085\n",
            "Feature 32: 0.0083\n",
            "Feature 62: 0.0083\n",
            "Feature 30: 0.0083\n",
            "Feature 38: 0.0083\n",
            "Feature 48: 0.0082\n",
            "Feature 27: 0.0082\n",
            "Feature 55: 0.0077\n",
            "Feature 15: 0.0073\n",
            "Feature 3: 0.0073\n",
            "Feature 59: 0.0072\n",
            "Feature 6: 0.0070\n",
            "Feature 52: 0.0070\n",
            "Feature 16: 0.0070\n",
            "Feature 23: 0.0069\n",
            "Feature 45: 0.0068\n",
            "Feature 43: 0.0067\n",
            "Feature 44: 0.0066\n",
            "Feature 26: 0.0065\n",
            "Feature 57: 0.0065\n",
            "Feature 63: 0.0065\n",
            "Feature 47: 0.0060\n",
            "Feature 18: 0.0059\n",
            "Feature 46: 0.0056\n",
            "Feature 12: 0.0047\n",
            "Feature 9: 0.0040\n",
            "Feature 81: 0.0002\n",
            "Feature 65: 0.0002\n",
            "Feature 64: 0.0002\n",
            "Feature 124: 0.0002\n",
            "Feature 97: 0.0002\n",
            "Feature 94: 0.0002\n",
            "Feature 127: 0.0002\n",
            "Feature 66: 0.0002\n",
            "Feature 113: 0.0002\n",
            "Feature 93: 0.0002\n",
            "Feature 104: 0.0002\n",
            "Feature 116: 0.0002\n",
            "Feature 115: 0.0002\n",
            "Feature 83: 0.0002\n",
            "Feature 68: 0.0002\n",
            "Feature 123: 0.0002\n",
            "Feature 75: 0.0002\n",
            "Feature 72: 0.0002\n",
            "Feature 109: 0.0002\n",
            "Feature 91: 0.0002\n",
            "Feature 77: 0.0002\n",
            "Feature 92: 0.0002\n",
            "Feature 79: 0.0002\n",
            "Feature 101: 0.0002\n",
            "Feature 88: 0.0002\n",
            "Feature 70: 0.0002\n",
            "Feature 122: 0.0002\n",
            "Feature 96: 0.0002\n",
            "Feature 103: 0.0002\n",
            "Feature 73: 0.0002\n",
            "Feature 99: 0.0002\n",
            "Feature 106: 0.0002\n",
            "Feature 112: 0.0002\n",
            "Feature 74: 0.0002\n",
            "Feature 85: 0.0002\n",
            "Feature 102: 0.0002\n",
            "Feature 82: 0.0002\n",
            "Feature 95: 0.0002\n",
            "Feature 98: 0.0002\n",
            "Feature 118: 0.0002\n",
            "Feature 78: 0.0002\n",
            "Feature 86: 0.0002\n",
            "Feature 110: 0.0002\n",
            "Feature 100: 0.0002\n",
            "Feature 111: 0.0002\n",
            "Feature 76: 0.0002\n",
            "Feature 117: 0.0002\n",
            "Feature 120: 0.0002\n",
            "Feature 69: 0.0002\n",
            "Feature 90: 0.0002\n",
            "Feature 125: 0.0002\n",
            "Feature 119: 0.0002\n",
            "Feature 80: 0.0002\n",
            "Feature 114: 0.0001\n",
            "Feature 84: 0.0001\n",
            "Feature 89: 0.0001\n",
            "Feature 67: 0.0001\n",
            "Feature 108: 0.0001\n",
            "Feature 105: 0.0001\n",
            "Feature 87: 0.0001\n",
            "Feature 107: 0.0001\n",
            "Feature 71: 0.0001\n",
            "Feature 121: 0.0001\n",
            "Feature 126: 0.0001\n"
          ]
        }
      ],
      "source": [
        "rf_clf = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=10, n_jobs=-1, class_weight='balanced')\n",
        "\n",
        "print(\"Initial RandomForest Model Parameters:\")\n",
        "print(rf_clf.get_params())\n",
        "\n",
        "rf_clf.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"\\nRandomForest Model Parameters after Training:\")\n",
        "print(rf_clf.get_params())\n",
        "\n",
        "rf_y_pred = rf_clf.predict(X_test_features)\n",
        "rf_y_pred_proba = rf_clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        "rf_roc_auc = roc_auc_score(y_test, rf_y_pred_proba)\n",
        "rf_precision = precision_score(y_test, rf_y_pred)\n",
        "rf_recall = recall_score(y_test, rf_y_pred)\n",
        "rf_f1 = f1_score(y_test, rf_y_pred)\n",
        "rf_confusion_matrix = confusion_matrix(y_test, rf_y_pred)\n",
        "\n",
        "print(\"\\nRandomForest Model Performance with Specific Parameters\")\n",
        "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {rf_roc_auc:.4f}\")\n",
        "print(f\"Precision: {rf_precision:.4f}\")\n",
        "print(f\"Recall: {rf_recall:.4f}\")\n",
        "print(f\"F1 Score: {rf_f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(rf_confusion_matrix)\n",
        "\n",
        "feature_importances = rf_clf.feature_importances_\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(feature_importances))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, importance in feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umZYyjID4qH3"
      },
      "source": [
        "**XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXNNkRXA4qS7",
        "outputId": "2bec6af8-353f-4aff-f39f-6e0db27431d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial XGBoost Model Parameters:\n",
            "{'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': 0.999541805558631, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:15:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Model Parameters after Training:\n",
            "{'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': 0.999541805558631, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n",
            "\n",
            "XGBoost Model Performance with Specific Parameters\n",
            "Accuracy: 0.8245\n",
            "ROC-AUC Score: 0.9033\n",
            "Precision: 0.8045\n",
            "Recall: 0.8571\n",
            "F1 Score: 0.8300\n",
            "\n",
            "Confusion Matrix:\n",
            "[[199326  52360]\n",
            " [ 35929 215488]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 29: 0.0299\n",
            "Feature 13: 0.0245\n",
            "Feature 8: 0.0231\n",
            "Feature 37: 0.0226\n",
            "Feature 17: 0.0217\n",
            "Feature 14: 0.0209\n",
            "Feature 51: 0.0204\n",
            "Feature 54: 0.0204\n",
            "Feature 11: 0.0187\n",
            "Feature 41: 0.0181\n",
            "Feature 4: 0.0179\n",
            "Feature 35: 0.0174\n",
            "Feature 56: 0.0168\n",
            "Feature 33: 0.0157\n",
            "Feature 24: 0.0150\n",
            "Feature 34: 0.0147\n",
            "Feature 53: 0.0144\n",
            "Feature 61: 0.0141\n",
            "Feature 7: 0.0140\n",
            "Feature 5: 0.0139\n",
            "Feature 20: 0.0137\n",
            "Feature 45: 0.0131\n",
            "Feature 31: 0.0130\n",
            "Feature 27: 0.0129\n",
            "Feature 52: 0.0126\n",
            "Feature 25: 0.0122\n",
            "Feature 58: 0.0119\n",
            "Feature 40: 0.0118\n",
            "Feature 10: 0.0118\n",
            "Feature 23: 0.0111\n",
            "Feature 49: 0.0110\n",
            "Feature 18: 0.0109\n",
            "Feature 28: 0.0108\n",
            "Feature 39: 0.0107\n",
            "Feature 57: 0.0107\n",
            "Feature 43: 0.0106\n",
            "Feature 1: 0.0104\n",
            "Feature 22: 0.0103\n",
            "Feature 60: 0.0103\n",
            "Feature 38: 0.0103\n",
            "Feature 15: 0.0100\n",
            "Feature 32: 0.0099\n",
            "Feature 44: 0.0099\n",
            "Feature 48: 0.0098\n",
            "Feature 36: 0.0098\n",
            "Feature 59: 0.0095\n",
            "Feature 42: 0.0088\n",
            "Feature 21: 0.0087\n",
            "Feature 2: 0.0086\n",
            "Feature 3: 0.0085\n",
            "Feature 46: 0.0085\n",
            "Feature 19: 0.0084\n",
            "Feature 63: 0.0079\n",
            "Feature 26: 0.0076\n",
            "Feature 50: 0.0076\n",
            "Feature 16: 0.0071\n",
            "Feature 47: 0.0071\n",
            "Feature 12: 0.0068\n",
            "Feature 0: 0.0066\n",
            "Feature 71: 0.0066\n",
            "Feature 62: 0.0065\n",
            "Feature 6: 0.0064\n",
            "Feature 104: 0.0062\n",
            "Feature 55: 0.0061\n",
            "Feature 122: 0.0055\n",
            "Feature 116: 0.0054\n",
            "Feature 30: 0.0053\n",
            "Feature 9: 0.0049\n",
            "Feature 106: 0.0047\n",
            "Feature 89: 0.0046\n",
            "Feature 113: 0.0046\n",
            "Feature 81: 0.0042\n",
            "Feature 68: 0.0039\n",
            "Feature 90: 0.0038\n",
            "Feature 103: 0.0037\n",
            "Feature 118: 0.0037\n",
            "Feature 124: 0.0036\n",
            "Feature 98: 0.0036\n",
            "Feature 120: 0.0036\n",
            "Feature 127: 0.0036\n",
            "Feature 84: 0.0036\n",
            "Feature 78: 0.0035\n",
            "Feature 80: 0.0035\n",
            "Feature 99: 0.0035\n",
            "Feature 73: 0.0035\n",
            "Feature 107: 0.0034\n",
            "Feature 95: 0.0034\n",
            "Feature 77: 0.0033\n",
            "Feature 79: 0.0033\n",
            "Feature 91: 0.0033\n",
            "Feature 121: 0.0032\n",
            "Feature 70: 0.0032\n",
            "Feature 101: 0.0032\n",
            "Feature 86: 0.0031\n",
            "Feature 74: 0.0030\n",
            "Feature 126: 0.0030\n",
            "Feature 93: 0.0030\n",
            "Feature 109: 0.0030\n",
            "Feature 115: 0.0029\n",
            "Feature 75: 0.0029\n",
            "Feature 114: 0.0029\n",
            "Feature 110: 0.0029\n",
            "Feature 100: 0.0029\n",
            "Feature 123: 0.0029\n",
            "Feature 119: 0.0029\n",
            "Feature 125: 0.0028\n",
            "Feature 87: 0.0028\n",
            "Feature 97: 0.0027\n",
            "Feature 67: 0.0027\n",
            "Feature 92: 0.0027\n",
            "Feature 96: 0.0027\n",
            "Feature 69: 0.0026\n",
            "Feature 83: 0.0026\n",
            "Feature 111: 0.0025\n",
            "Feature 102: 0.0024\n",
            "Feature 72: 0.0024\n",
            "Feature 85: 0.0024\n",
            "Feature 66: 0.0024\n",
            "Feature 65: 0.0023\n",
            "Feature 88: 0.0023\n",
            "Feature 64: 0.0023\n",
            "Feature 117: 0.0022\n",
            "Feature 82: 0.0022\n",
            "Feature 105: 0.0022\n",
            "Feature 76: 0.0021\n",
            "Feature 112: 0.0021\n",
            "Feature 94: 0.0019\n",
            "Feature 108: 0.0016\n"
          ]
        }
      ],
      "source": [
        "negative_class_count = sum(y_train == 0)\n",
        "positive_class_count = sum(y_train == 1)\n",
        "scale_pos_weight = negative_class_count / positive_class_count\n",
        "\n",
        "xgb_clf = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=scale_pos_weight)\n",
        "\n",
        "print(\"Initial XGBoost Model Parameters:\")\n",
        "print(xgb_clf.get_params())\n",
        "\n",
        "xgb_clf.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"\\nXGBoost Model Parameters after Training:\")\n",
        "print(xgb_clf.get_params())\n",
        "\n",
        "xgb_y_pred = xgb_clf.predict(X_test_features)\n",
        "xgb_y_pred_proba = xgb_clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
        "xgb_roc_auc = roc_auc_score(y_test, xgb_y_pred_proba)\n",
        "xgb_precision = precision_score(y_test, xgb_y_pred)\n",
        "xgb_recall = recall_score(y_test, xgb_y_pred)\n",
        "xgb_f1 = f1_score(y_test, xgb_y_pred)\n",
        "xgb_confusion_matrix = confusion_matrix(y_test, xgb_y_pred)\n",
        "\n",
        "print(\"\\nXGBoost Model Performance with Specific Parameters\")\n",
        "print(f\"Accuracy: {xgb_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {xgb_roc_auc:.4f}\")\n",
        "print(f\"Precision: {xgb_precision:.4f}\")\n",
        "print(f\"Recall: {xgb_recall:.4f}\")\n",
        "print(f\"F1 Score: {xgb_f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(xgb_confusion_matrix)\n",
        "\n",
        "feature_importances = xgb_clf.feature_importances_\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(feature_importances))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, importance in feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTR9sKBw61lF"
      },
      "source": [
        "### **deepWalk + DNABERT3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KQ-qJBV8PY93"
      },
      "outputs": [],
      "source": [
        "node_train_features = create_edge_features_mean(X_train, embedding_dict1)\n",
        "node_test_features = create_edge_features_mean(X_test, embedding_dict1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oiq1FT0fPa76",
        "outputId": "7b1105d8-9b71-4d0d-9584-738ecab26e8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "61000\n",
            "62000\n",
            "63000\n",
            "64000\n",
            "65000\n",
            "66000\n",
            "67000\n",
            "68000\n",
            "69000\n",
            "70000\n",
            "71000\n",
            "72000\n",
            "73000\n",
            "74000\n",
            "75000\n",
            "76000\n",
            "77000\n",
            "78000\n",
            "79000\n",
            "80000\n",
            "81000\n",
            "82000\n",
            "83000\n",
            "84000\n",
            "85000\n",
            "86000\n",
            "87000\n",
            "88000\n",
            "89000\n",
            "90000\n",
            "91000\n",
            "92000\n",
            "93000\n",
            "94000\n",
            "95000\n",
            "96000\n",
            "97000\n",
            "98000\n",
            "99000\n",
            "100000\n",
            "101000\n",
            "102000\n",
            "103000\n",
            "104000\n",
            "105000\n",
            "106000\n",
            "107000\n",
            "108000\n",
            "109000\n",
            "110000\n",
            "111000\n",
            "112000\n",
            "113000\n",
            "114000\n",
            "115000\n",
            "116000\n",
            "117000\n",
            "118000\n",
            "119000\n",
            "120000\n",
            "121000\n",
            "122000\n",
            "123000\n",
            "124000\n",
            "125000\n",
            "126000\n",
            "127000\n",
            "128000\n",
            "129000\n",
            "130000\n",
            "131000\n",
            "132000\n",
            "133000\n",
            "134000\n",
            "135000\n",
            "136000\n",
            "137000\n",
            "138000\n",
            "139000\n",
            "140000\n",
            "141000\n",
            "142000\n",
            "143000\n",
            "144000\n",
            "145000\n",
            "146000\n",
            "147000\n",
            "148000\n",
            "149000\n",
            "150000\n",
            "151000\n",
            "152000\n",
            "153000\n",
            "154000\n",
            "155000\n",
            "156000\n",
            "157000\n",
            "158000\n",
            "159000\n",
            "160000\n",
            "161000\n",
            "162000\n",
            "163000\n",
            "164000\n",
            "165000\n",
            "166000\n",
            "167000\n",
            "168000\n",
            "169000\n",
            "170000\n",
            "171000\n",
            "172000\n",
            "173000\n",
            "174000\n",
            "175000\n",
            "176000\n",
            "177000\n",
            "178000\n",
            "179000\n",
            "180000\n",
            "181000\n",
            "182000\n",
            "183000\n",
            "184000\n",
            "185000\n",
            "186000\n",
            "187000\n",
            "188000\n",
            "189000\n",
            "190000\n",
            "191000\n",
            "192000\n",
            "193000\n",
            "194000\n",
            "195000\n",
            "196000\n",
            "197000\n",
            "198000\n",
            "199000\n",
            "200000\n",
            "201000\n",
            "202000\n",
            "203000\n",
            "204000\n",
            "205000\n",
            "206000\n",
            "207000\n",
            "208000\n",
            "209000\n",
            "210000\n",
            "211000\n",
            "212000\n",
            "213000\n",
            "214000\n",
            "215000\n",
            "216000\n",
            "217000\n",
            "218000\n",
            "219000\n",
            "220000\n",
            "221000\n",
            "222000\n",
            "223000\n",
            "224000\n",
            "225000\n",
            "226000\n",
            "227000\n",
            "228000\n",
            "229000\n",
            "230000\n",
            "231000\n",
            "232000\n",
            "233000\n",
            "234000\n",
            "235000\n",
            "236000\n",
            "237000\n",
            "238000\n",
            "239000\n",
            "240000\n",
            "241000\n",
            "242000\n",
            "243000\n",
            "244000\n",
            "245000\n",
            "246000\n",
            "247000\n",
            "248000\n",
            "249000\n",
            "250000\n",
            "251000\n",
            "252000\n",
            "253000\n",
            "254000\n",
            "255000\n",
            "256000\n",
            "257000\n",
            "258000\n",
            "259000\n",
            "260000\n",
            "261000\n",
            "262000\n",
            "263000\n",
            "264000\n",
            "265000\n",
            "266000\n",
            "267000\n",
            "268000\n",
            "269000\n",
            "270000\n",
            "271000\n",
            "272000\n",
            "273000\n",
            "274000\n",
            "275000\n",
            "276000\n",
            "277000\n",
            "278000\n",
            "279000\n",
            "280000\n",
            "281000\n",
            "282000\n",
            "283000\n",
            "284000\n",
            "285000\n",
            "286000\n",
            "287000\n",
            "288000\n",
            "289000\n",
            "290000\n",
            "291000\n",
            "292000\n",
            "293000\n",
            "294000\n",
            "295000\n",
            "296000\n",
            "297000\n",
            "298000\n",
            "299000\n",
            "300000\n",
            "301000\n",
            "302000\n",
            "303000\n",
            "304000\n",
            "305000\n",
            "306000\n",
            "307000\n",
            "308000\n",
            "309000\n",
            "310000\n",
            "311000\n",
            "312000\n",
            "313000\n",
            "314000\n",
            "315000\n",
            "316000\n",
            "317000\n",
            "318000\n",
            "319000\n",
            "320000\n",
            "321000\n",
            "322000\n",
            "323000\n",
            "324000\n",
            "325000\n",
            "326000\n",
            "327000\n",
            "328000\n",
            "329000\n",
            "330000\n",
            "331000\n",
            "332000\n",
            "333000\n",
            "334000\n",
            "335000\n",
            "336000\n",
            "337000\n",
            "338000\n",
            "339000\n",
            "340000\n",
            "341000\n",
            "342000\n",
            "343000\n",
            "344000\n",
            "345000\n",
            "346000\n",
            "347000\n",
            "348000\n",
            "349000\n",
            "350000\n",
            "351000\n",
            "352000\n",
            "353000\n",
            "354000\n",
            "355000\n",
            "356000\n",
            "357000\n",
            "358000\n",
            "359000\n",
            "360000\n",
            "361000\n",
            "362000\n",
            "363000\n",
            "364000\n",
            "365000\n",
            "366000\n",
            "367000\n",
            "368000\n",
            "369000\n",
            "370000\n",
            "371000\n",
            "372000\n",
            "373000\n",
            "374000\n",
            "375000\n",
            "376000\n",
            "377000\n",
            "378000\n",
            "379000\n",
            "380000\n",
            "381000\n",
            "382000\n",
            "383000\n",
            "384000\n",
            "385000\n",
            "386000\n",
            "387000\n",
            "388000\n",
            "389000\n",
            "390000\n",
            "391000\n",
            "392000\n",
            "393000\n",
            "394000\n",
            "395000\n",
            "396000\n",
            "397000\n",
            "398000\n",
            "399000\n",
            "400000\n",
            "401000\n",
            "402000\n",
            "403000\n",
            "404000\n",
            "405000\n",
            "406000\n",
            "407000\n",
            "408000\n",
            "409000\n",
            "410000\n",
            "411000\n",
            "412000\n",
            "413000\n",
            "414000\n",
            "415000\n",
            "416000\n",
            "417000\n",
            "418000\n",
            "419000\n",
            "420000\n",
            "421000\n",
            "422000\n",
            "423000\n",
            "424000\n",
            "425000\n",
            "426000\n",
            "427000\n",
            "428000\n",
            "429000\n",
            "430000\n",
            "431000\n",
            "432000\n",
            "433000\n",
            "434000\n",
            "435000\n",
            "436000\n",
            "437000\n",
            "438000\n",
            "439000\n",
            "440000\n",
            "441000\n",
            "442000\n",
            "443000\n",
            "444000\n",
            "445000\n",
            "446000\n",
            "447000\n",
            "448000\n",
            "449000\n",
            "450000\n",
            "451000\n",
            "452000\n",
            "453000\n",
            "454000\n",
            "455000\n",
            "456000\n",
            "457000\n",
            "458000\n",
            "459000\n",
            "460000\n",
            "461000\n",
            "462000\n",
            "463000\n",
            "464000\n",
            "465000\n",
            "466000\n",
            "467000\n",
            "468000\n",
            "469000\n",
            "470000\n",
            "471000\n",
            "472000\n",
            "473000\n",
            "474000\n",
            "475000\n",
            "476000\n",
            "477000\n",
            "478000\n",
            "479000\n",
            "480000\n",
            "481000\n",
            "482000\n",
            "483000\n",
            "484000\n",
            "485000\n",
            "486000\n",
            "487000\n",
            "488000\n",
            "489000\n",
            "490000\n",
            "491000\n",
            "492000\n",
            "493000\n",
            "494000\n",
            "495000\n",
            "496000\n",
            "497000\n",
            "498000\n",
            "499000\n",
            "500000\n",
            "501000\n",
            "502000\n",
            "503000\n",
            "504000\n",
            "505000\n",
            "506000\n",
            "507000\n",
            "508000\n",
            "509000\n",
            "510000\n",
            "511000\n",
            "512000\n",
            "513000\n",
            "514000\n",
            "515000\n",
            "516000\n",
            "517000\n",
            "518000\n",
            "519000\n",
            "520000\n",
            "521000\n",
            "522000\n",
            "523000\n",
            "524000\n",
            "525000\n",
            "526000\n",
            "527000\n",
            "528000\n",
            "529000\n",
            "530000\n",
            "531000\n",
            "532000\n",
            "533000\n",
            "534000\n",
            "535000\n",
            "536000\n",
            "537000\n",
            "538000\n",
            "539000\n",
            "540000\n",
            "541000\n",
            "542000\n",
            "543000\n",
            "544000\n",
            "545000\n",
            "546000\n",
            "547000\n",
            "548000\n",
            "549000\n",
            "550000\n",
            "551000\n",
            "552000\n",
            "553000\n",
            "554000\n",
            "555000\n",
            "556000\n",
            "557000\n",
            "558000\n",
            "559000\n",
            "560000\n",
            "561000\n",
            "562000\n",
            "563000\n",
            "564000\n",
            "565000\n",
            "566000\n",
            "567000\n",
            "568000\n",
            "569000\n",
            "570000\n",
            "571000\n",
            "572000\n",
            "573000\n",
            "574000\n",
            "575000\n",
            "576000\n",
            "577000\n",
            "578000\n",
            "579000\n",
            "580000\n",
            "581000\n",
            "582000\n",
            "583000\n",
            "584000\n",
            "585000\n",
            "586000\n",
            "587000\n",
            "588000\n",
            "589000\n",
            "590000\n",
            "591000\n",
            "592000\n",
            "593000\n",
            "594000\n",
            "595000\n",
            "596000\n",
            "597000\n",
            "598000\n",
            "599000\n",
            "600000\n",
            "601000\n",
            "602000\n",
            "603000\n",
            "604000\n",
            "605000\n",
            "606000\n",
            "607000\n",
            "608000\n",
            "609000\n",
            "610000\n",
            "611000\n",
            "612000\n",
            "613000\n",
            "614000\n",
            "615000\n",
            "616000\n",
            "617000\n",
            "618000\n",
            "619000\n",
            "620000\n",
            "621000\n",
            "622000\n",
            "623000\n",
            "624000\n",
            "625000\n",
            "626000\n",
            "627000\n",
            "628000\n",
            "629000\n",
            "630000\n",
            "631000\n",
            "632000\n",
            "633000\n",
            "634000\n",
            "635000\n",
            "636000\n",
            "637000\n",
            "638000\n",
            "639000\n",
            "640000\n",
            "641000\n",
            "642000\n",
            "643000\n",
            "644000\n",
            "645000\n",
            "646000\n",
            "647000\n",
            "648000\n",
            "649000\n",
            "650000\n",
            "651000\n",
            "652000\n",
            "653000\n",
            "654000\n",
            "655000\n",
            "656000\n",
            "657000\n",
            "658000\n",
            "659000\n",
            "660000\n",
            "661000\n",
            "662000\n",
            "663000\n",
            "664000\n",
            "665000\n",
            "666000\n",
            "667000\n",
            "668000\n",
            "669000\n",
            "670000\n",
            "671000\n",
            "672000\n",
            "673000\n",
            "674000\n",
            "675000\n",
            "676000\n",
            "677000\n",
            "678000\n",
            "679000\n",
            "680000\n",
            "681000\n",
            "682000\n",
            "683000\n",
            "684000\n",
            "685000\n",
            "686000\n",
            "687000\n",
            "688000\n",
            "689000\n",
            "690000\n",
            "691000\n",
            "692000\n",
            "693000\n",
            "694000\n",
            "695000\n",
            "696000\n",
            "697000\n",
            "698000\n",
            "699000\n",
            "700000\n",
            "701000\n",
            "702000\n",
            "703000\n",
            "704000\n",
            "705000\n",
            "706000\n",
            "707000\n",
            "708000\n",
            "709000\n",
            "710000\n",
            "711000\n",
            "712000\n",
            "713000\n",
            "714000\n",
            "715000\n",
            "716000\n",
            "717000\n",
            "718000\n",
            "719000\n",
            "720000\n",
            "721000\n",
            "722000\n",
            "723000\n",
            "724000\n",
            "725000\n",
            "726000\n",
            "727000\n",
            "728000\n",
            "729000\n",
            "730000\n",
            "731000\n",
            "732000\n",
            "733000\n",
            "734000\n",
            "735000\n",
            "736000\n",
            "737000\n",
            "738000\n",
            "739000\n",
            "740000\n",
            "741000\n",
            "742000\n",
            "743000\n",
            "744000\n",
            "745000\n",
            "746000\n",
            "747000\n",
            "748000\n",
            "749000\n",
            "750000\n",
            "751000\n",
            "752000\n",
            "753000\n",
            "754000\n",
            "755000\n",
            "756000\n",
            "757000\n",
            "758000\n",
            "759000\n",
            "760000\n",
            "761000\n",
            "762000\n",
            "763000\n",
            "764000\n",
            "765000\n",
            "766000\n",
            "767000\n",
            "768000\n",
            "769000\n",
            "770000\n",
            "771000\n",
            "772000\n",
            "773000\n",
            "774000\n",
            "775000\n",
            "776000\n",
            "777000\n",
            "778000\n",
            "779000\n",
            "780000\n",
            "781000\n",
            "782000\n",
            "783000\n",
            "784000\n",
            "785000\n",
            "786000\n",
            "787000\n",
            "788000\n",
            "789000\n",
            "790000\n",
            "791000\n",
            "792000\n",
            "793000\n",
            "794000\n",
            "795000\n",
            "796000\n",
            "797000\n",
            "798000\n",
            "799000\n",
            "800000\n",
            "801000\n",
            "802000\n",
            "803000\n",
            "804000\n",
            "805000\n",
            "806000\n",
            "807000\n",
            "808000\n",
            "809000\n",
            "810000\n",
            "811000\n",
            "812000\n",
            "813000\n",
            "814000\n",
            "815000\n",
            "816000\n",
            "817000\n",
            "818000\n",
            "819000\n",
            "820000\n",
            "821000\n",
            "822000\n",
            "823000\n",
            "824000\n",
            "825000\n",
            "826000\n",
            "827000\n",
            "828000\n",
            "829000\n",
            "830000\n",
            "831000\n",
            "832000\n",
            "833000\n",
            "834000\n",
            "835000\n",
            "836000\n",
            "837000\n",
            "838000\n",
            "839000\n",
            "840000\n",
            "841000\n",
            "842000\n",
            "843000\n",
            "844000\n",
            "845000\n",
            "846000\n",
            "847000\n",
            "848000\n",
            "849000\n",
            "850000\n",
            "851000\n",
            "852000\n",
            "853000\n",
            "854000\n",
            "855000\n",
            "856000\n",
            "857000\n",
            "858000\n",
            "859000\n",
            "860000\n",
            "861000\n",
            "862000\n",
            "863000\n",
            "864000\n",
            "865000\n",
            "866000\n",
            "867000\n",
            "868000\n",
            "869000\n",
            "870000\n",
            "871000\n",
            "872000\n",
            "873000\n",
            "874000\n",
            "875000\n",
            "876000\n",
            "877000\n",
            "878000\n",
            "879000\n",
            "880000\n",
            "881000\n",
            "882000\n",
            "883000\n",
            "884000\n",
            "885000\n",
            "886000\n",
            "887000\n",
            "888000\n",
            "889000\n",
            "890000\n",
            "891000\n",
            "892000\n",
            "893000\n",
            "894000\n",
            "895000\n",
            "896000\n",
            "897000\n",
            "898000\n",
            "899000\n",
            "900000\n",
            "901000\n",
            "902000\n",
            "903000\n",
            "904000\n",
            "905000\n",
            "906000\n",
            "907000\n",
            "908000\n",
            "909000\n",
            "910000\n",
            "911000\n",
            "912000\n",
            "913000\n",
            "914000\n",
            "915000\n",
            "916000\n",
            "917000\n",
            "918000\n",
            "919000\n",
            "920000\n",
            "921000\n",
            "922000\n",
            "923000\n",
            "924000\n",
            "925000\n",
            "926000\n",
            "927000\n",
            "928000\n",
            "929000\n",
            "930000\n",
            "931000\n",
            "932000\n",
            "933000\n",
            "934000\n",
            "935000\n",
            "936000\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "61000\n",
            "62000\n",
            "63000\n",
            "64000\n",
            "65000\n",
            "66000\n",
            "67000\n",
            "68000\n",
            "69000\n",
            "70000\n",
            "71000\n",
            "72000\n",
            "73000\n",
            "74000\n",
            "75000\n",
            "76000\n",
            "77000\n",
            "78000\n",
            "79000\n",
            "80000\n",
            "81000\n",
            "82000\n",
            "83000\n",
            "84000\n",
            "85000\n",
            "86000\n",
            "87000\n",
            "88000\n",
            "89000\n",
            "90000\n",
            "91000\n",
            "92000\n",
            "93000\n",
            "94000\n",
            "95000\n",
            "96000\n",
            "97000\n",
            "98000\n",
            "99000\n",
            "100000\n",
            "101000\n",
            "102000\n",
            "103000\n",
            "104000\n",
            "105000\n",
            "106000\n",
            "107000\n",
            "108000\n",
            "109000\n",
            "110000\n",
            "111000\n",
            "112000\n",
            "113000\n",
            "114000\n",
            "115000\n",
            "116000\n",
            "117000\n",
            "118000\n",
            "119000\n",
            "120000\n",
            "121000\n",
            "122000\n",
            "123000\n",
            "124000\n",
            "125000\n",
            "126000\n",
            "127000\n",
            "128000\n",
            "129000\n",
            "130000\n",
            "131000\n",
            "132000\n",
            "133000\n",
            "134000\n",
            "135000\n",
            "136000\n",
            "137000\n",
            "138000\n",
            "139000\n",
            "140000\n",
            "141000\n",
            "142000\n",
            "143000\n",
            "144000\n",
            "145000\n",
            "146000\n",
            "147000\n",
            "148000\n",
            "149000\n",
            "150000\n",
            "151000\n",
            "152000\n",
            "153000\n",
            "154000\n",
            "155000\n",
            "156000\n",
            "157000\n",
            "158000\n",
            "159000\n",
            "160000\n",
            "161000\n",
            "162000\n",
            "163000\n",
            "164000\n",
            "165000\n",
            "166000\n",
            "167000\n",
            "168000\n",
            "169000\n",
            "170000\n",
            "171000\n",
            "172000\n",
            "173000\n",
            "174000\n",
            "175000\n",
            "176000\n",
            "177000\n",
            "178000\n",
            "179000\n",
            "180000\n",
            "181000\n",
            "182000\n",
            "183000\n",
            "184000\n",
            "185000\n",
            "186000\n",
            "187000\n",
            "188000\n",
            "189000\n",
            "190000\n",
            "191000\n",
            "192000\n",
            "193000\n",
            "194000\n",
            "195000\n",
            "196000\n",
            "197000\n",
            "198000\n",
            "199000\n",
            "200000\n",
            "201000\n",
            "202000\n",
            "203000\n",
            "204000\n",
            "205000\n",
            "206000\n",
            "207000\n",
            "208000\n",
            "209000\n",
            "210000\n",
            "211000\n",
            "212000\n",
            "213000\n",
            "214000\n",
            "215000\n",
            "216000\n",
            "217000\n",
            "218000\n",
            "219000\n",
            "220000\n",
            "221000\n",
            "222000\n",
            "223000\n",
            "224000\n",
            "225000\n",
            "226000\n",
            "227000\n",
            "228000\n",
            "229000\n",
            "230000\n",
            "231000\n",
            "232000\n",
            "233000\n",
            "234000\n",
            "235000\n",
            "236000\n",
            "237000\n",
            "238000\n",
            "239000\n",
            "240000\n",
            "241000\n",
            "242000\n",
            "243000\n",
            "244000\n",
            "245000\n",
            "246000\n",
            "247000\n",
            "248000\n",
            "249000\n",
            "250000\n",
            "251000\n",
            "252000\n",
            "253000\n",
            "254000\n",
            "255000\n",
            "256000\n",
            "257000\n",
            "258000\n",
            "259000\n",
            "260000\n",
            "261000\n",
            "262000\n",
            "263000\n",
            "264000\n",
            "265000\n",
            "266000\n",
            "267000\n",
            "268000\n",
            "269000\n",
            "270000\n",
            "271000\n",
            "272000\n",
            "273000\n",
            "274000\n",
            "275000\n",
            "276000\n",
            "277000\n",
            "278000\n",
            "279000\n",
            "280000\n",
            "281000\n",
            "282000\n",
            "283000\n",
            "284000\n",
            "285000\n",
            "286000\n",
            "287000\n",
            "288000\n",
            "289000\n",
            "290000\n",
            "291000\n",
            "292000\n",
            "293000\n",
            "294000\n",
            "295000\n",
            "296000\n",
            "297000\n",
            "298000\n",
            "299000\n",
            "300000\n",
            "301000\n",
            "302000\n",
            "303000\n",
            "304000\n",
            "305000\n",
            "306000\n",
            "307000\n",
            "308000\n",
            "309000\n",
            "310000\n",
            "311000\n",
            "312000\n",
            "313000\n",
            "314000\n",
            "315000\n",
            "316000\n",
            "317000\n",
            "318000\n",
            "319000\n",
            "320000\n",
            "321000\n",
            "322000\n",
            "323000\n",
            "324000\n",
            "325000\n",
            "326000\n",
            "327000\n",
            "328000\n",
            "329000\n",
            "330000\n",
            "331000\n",
            "332000\n",
            "333000\n",
            "334000\n",
            "335000\n",
            "336000\n",
            "337000\n",
            "338000\n",
            "339000\n",
            "340000\n",
            "341000\n",
            "342000\n",
            "343000\n",
            "344000\n",
            "345000\n",
            "346000\n",
            "347000\n",
            "348000\n",
            "349000\n",
            "350000\n",
            "351000\n",
            "352000\n",
            "353000\n",
            "354000\n",
            "355000\n",
            "356000\n",
            "357000\n",
            "358000\n",
            "359000\n",
            "360000\n",
            "361000\n",
            "362000\n",
            "363000\n",
            "364000\n",
            "365000\n",
            "366000\n",
            "367000\n",
            "368000\n",
            "369000\n",
            "370000\n",
            "371000\n",
            "372000\n",
            "373000\n",
            "374000\n",
            "375000\n",
            "376000\n",
            "377000\n",
            "378000\n",
            "379000\n",
            "380000\n",
            "381000\n",
            "382000\n",
            "383000\n",
            "384000\n",
            "385000\n",
            "386000\n",
            "387000\n",
            "388000\n",
            "389000\n",
            "390000\n",
            "391000\n",
            "392000\n",
            "393000\n",
            "394000\n",
            "395000\n",
            "396000\n",
            "397000\n",
            "398000\n",
            "399000\n",
            "400000\n",
            "401000\n"
          ]
        }
      ],
      "source": [
        "dna_train_features = create_edge_features_df(X_train, gdnabert3_df)\n",
        "dna_test_features = create_edge_features_df(X_test, gdnabert3_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hXxVWYde63-Z"
      },
      "outputs": [],
      "source": [
        "X_train_features = np.concatenate((node_train_features, dna_train_features), axis=1)\n",
        "X_test_features = np.concatenate((node_test_features, dna_test_features), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Bwk1s4ofdIoy"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_features = scaler.fit_transform(X_train_features)\n",
        "X_test_features = scaler.transform(X_test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNTOK_Hz64HO"
      },
      "source": [
        "**Regresión Logística**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V8rmzQ964Sh",
        "outputId": "86c1e9bb-a0bd-4b63-9c28-710337f66857"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7457\n",
            "ROC-AUC Score: 0.8026\n",
            "Precision: 0.7646\n",
            "Recall: 0.8590\n",
            "F1 Score: 0.8091\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 83065  66613]\n",
            " [ 35515 216359]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 0: -1.2347\n",
            "Feature 21: -1.1661\n",
            "Feature 1: 1.1352\n",
            "Feature 5: 1.0381\n",
            "Feature 23: 1.0241\n",
            "Feature 16: 1.0124\n",
            "Feature 13: 1.0109\n",
            "Feature 25: -0.9671\n",
            "Feature 44: -0.9380\n",
            "Feature 52: -0.9062\n",
            "Feature 10: -0.8918\n",
            "Feature 18: 0.8874\n",
            "Feature 20: -0.8840\n",
            "Feature 8: 0.8763\n",
            "Feature 45: 0.8628\n",
            "Feature 59: -0.8536\n",
            "Feature 4: -0.8173\n",
            "Feature 50: -0.6991\n",
            "Feature 60: 0.6910\n",
            "Feature 46: 0.6516\n",
            "Feature 31: -0.6385\n",
            "Feature 14: 0.6353\n",
            "Feature 53: -0.6126\n",
            "Feature 35: -0.5962\n",
            "Feature 3: -0.5822\n",
            "Feature 49: -0.5705\n",
            "Feature 33: 0.5627\n",
            "Feature 40: -0.5515\n",
            "Feature 51: 0.5486\n",
            "Feature 41: -0.5436\n",
            "Feature 26: 0.5280\n",
            "Feature 30: 0.5191\n",
            "Feature 43: -0.4708\n",
            "Feature 56: 0.4694\n",
            "Feature 24: 0.4447\n",
            "Feature 55: 0.3802\n",
            "Feature 39: -0.3756\n",
            "Feature 113: 0.3512\n",
            "Feature 62: 0.3385\n",
            "Feature 57: 0.3301\n",
            "Feature 15: -0.3226\n",
            "Feature 352: 0.3224\n",
            "Feature 22: 0.2973\n",
            "Feature 827: -0.2895\n",
            "Feature 760: -0.2869\n",
            "Feature 154: -0.2822\n",
            "Feature 47: -0.2727\n",
            "Feature 19: -0.2613\n",
            "Feature 12: 0.2569\n",
            "Feature 210: -0.2464\n",
            "Feature 38: 0.2457\n",
            "Feature 785: -0.2436\n",
            "Feature 290: 0.2424\n",
            "Feature 735: 0.2397\n",
            "Feature 28: 0.2393\n",
            "Feature 200: -0.2262\n",
            "Feature 631: 0.2261\n",
            "Feature 254: 0.2182\n",
            "Feature 432: 0.2135\n",
            "Feature 226: -0.2126\n",
            "Feature 188: 0.2120\n",
            "Feature 260: -0.2068\n",
            "Feature 134: -0.2046\n",
            "Feature 530: 0.2046\n",
            "Feature 95: 0.2029\n",
            "Feature 244: 0.1980\n",
            "Feature 63: 0.1970\n",
            "Feature 614: -0.1966\n",
            "Feature 844: -0.1951\n",
            "Feature 299: 0.1948\n",
            "Feature 725: 0.1929\n",
            "Feature 556: 0.1921\n",
            "Feature 749: -0.1920\n",
            "Feature 505: -0.1905\n",
            "Feature 525: -0.1874\n",
            "Feature 636: 0.1858\n",
            "Feature 224: 0.1851\n",
            "Feature 243: 0.1843\n",
            "Feature 333: 0.1833\n",
            "Feature 206: -0.1833\n",
            "Feature 406: 0.1795\n",
            "Feature 574: -0.1767\n",
            "Feature 528: -0.1765\n",
            "Feature 389: 0.1756\n",
            "Feature 9: 0.1748\n",
            "Feature 818: -0.1747\n",
            "Feature 261: -0.1735\n",
            "Feature 413: -0.1734\n",
            "Feature 640: -0.1719\n",
            "Feature 129: 0.1712\n",
            "Feature 458: 0.1704\n",
            "Feature 326: -0.1693\n",
            "Feature 187: 0.1684\n",
            "Feature 811: -0.1667\n",
            "Feature 592: -0.1665\n",
            "Feature 403: -0.1659\n",
            "Feature 369: -0.1647\n",
            "Feature 799: -0.1635\n",
            "Feature 249: 0.1620\n",
            "Feature 264: 0.1620\n",
            "Feature 597: 0.1614\n",
            "Feature 693: 0.1605\n",
            "Feature 655: 0.1597\n",
            "Feature 447: -0.1596\n",
            "Feature 855: -0.1587\n",
            "Feature 647: -0.1581\n",
            "Feature 790: -0.1577\n",
            "Feature 34: -0.1555\n",
            "Feature 232: 0.1553\n",
            "Feature 569: 0.1551\n",
            "Feature 394: 0.1544\n",
            "Feature 814: -0.1543\n",
            "Feature 603: 0.1540\n",
            "Feature 131: -0.1526\n",
            "Feature 354: 0.1520\n",
            "Feature 575: -0.1517\n",
            "Feature 851: 0.1517\n",
            "Feature 143: -0.1512\n",
            "Feature 278: 0.1508\n",
            "Feature 815: 0.1503\n",
            "Feature 547: 0.1501\n",
            "Feature 768: -0.1492\n",
            "Feature 109: -0.1483\n",
            "Feature 272: -0.1481\n",
            "Feature 692: -0.1468\n",
            "Feature 334: -0.1468\n",
            "Feature 699: -0.1452\n",
            "Feature 468: -0.1451\n",
            "Feature 615: -0.1439\n",
            "Feature 594: 0.1437\n",
            "Feature 746: 0.1423\n",
            "Feature 145: 0.1421\n",
            "Feature 586: -0.1413\n",
            "Feature 734: 0.1412\n",
            "Feature 796: -0.1411\n",
            "Feature 789: 0.1409\n",
            "Feature 513: 0.1408\n",
            "Feature 222: 0.1407\n",
            "Feature 108: 0.1393\n",
            "Feature 521: 0.1390\n",
            "Feature 587: 0.1385\n",
            "Feature 370: 0.1383\n",
            "Feature 112: 0.1382\n",
            "Feature 499: 0.1368\n",
            "Feature 824: -0.1366\n",
            "Feature 618: 0.1362\n",
            "Feature 701: -0.1361\n",
            "Feature 743: -0.1358\n",
            "Feature 795: 0.1356\n",
            "Feature 777: 0.1351\n",
            "Feature 466: 0.1345\n",
            "Feature 378: -0.1344\n",
            "Feature 542: -0.1341\n",
            "Feature 435: -0.1340\n",
            "Feature 262: 0.1335\n",
            "Feature 205: 0.1329\n",
            "Feature 297: 0.1321\n",
            "Feature 255: -0.1317\n",
            "Feature 330: -0.1314\n",
            "Feature 184: 0.1313\n",
            "Feature 629: -0.1306\n",
            "Feature 780: -0.1306\n",
            "Feature 247: 0.1299\n",
            "Feature 98: 0.1298\n",
            "Feature 517: 0.1289\n",
            "Feature 856: 0.1288\n",
            "Feature 58: 0.1285\n",
            "Feature 544: -0.1283\n",
            "Feature 576: -0.1278\n",
            "Feature 642: 0.1277\n",
            "Feature 213: 0.1273\n",
            "Feature 156: -0.1271\n",
            "Feature 724: -0.1269\n",
            "Feature 736: 0.1267\n",
            "Feature 97: 0.1264\n",
            "Feature 327: -0.1255\n",
            "Feature 110: 0.1254\n",
            "Feature 339: -0.1251\n",
            "Feature 787: 0.1249\n",
            "Feature 460: 0.1248\n",
            "Feature 829: 0.1245\n",
            "Feature 845: -0.1237\n",
            "Feature 480: 0.1237\n",
            "Feature 737: 0.1225\n",
            "Feature 27: -0.1219\n",
            "Feature 486: -0.1213\n",
            "Feature 649: 0.1213\n",
            "Feature 361: 0.1208\n",
            "Feature 398: -0.1206\n",
            "Feature 543: -0.1203\n",
            "Feature 208: -0.1202\n",
            "Feature 690: -0.1200\n",
            "Feature 579: 0.1191\n",
            "Feature 848: -0.1189\n",
            "Feature 341: 0.1187\n",
            "Feature 532: 0.1187\n",
            "Feature 677: -0.1186\n",
            "Feature 712: -0.1176\n",
            "Feature 691: -0.1176\n",
            "Feature 233: 0.1173\n",
            "Feature 483: -0.1172\n",
            "Feature 786: 0.1169\n",
            "Feature 332: -0.1168\n",
            "Feature 355: -0.1164\n",
            "Feature 7: -0.1163\n",
            "Feature 509: -0.1162\n",
            "Feature 308: -0.1158\n",
            "Feature 635: 0.1158\n",
            "Feature 140: -0.1158\n",
            "Feature 317: -0.1154\n",
            "Feature 105: -0.1153\n",
            "Feature 157: -0.1153\n",
            "Feature 726: -0.1152\n",
            "Feature 702: 0.1150\n",
            "Feature 417: 0.1148\n",
            "Feature 489: -0.1142\n",
            "Feature 491: -0.1138\n",
            "Feature 37: 0.1130\n",
            "Feature 752: 0.1120\n",
            "Feature 274: -0.1117\n",
            "Feature 498: -0.1116\n",
            "Feature 445: -0.1110\n",
            "Feature 819: 0.1106\n",
            "Feature 235: 0.1101\n",
            "Feature 162: 0.1097\n",
            "Feature 257: 0.1096\n",
            "Feature 497: 0.1093\n",
            "Feature 664: 0.1089\n",
            "Feature 358: 0.1089\n",
            "Feature 833: -0.1088\n",
            "Feature 173: 0.1082\n",
            "Feature 709: 0.1080\n",
            "Feature 179: -0.1077\n",
            "Feature 711: -0.1076\n",
            "Feature 391: -0.1076\n",
            "Feature 32: -0.1069\n",
            "Feature 171: 0.1066\n",
            "Feature 670: -0.1066\n",
            "Feature 218: -0.1064\n",
            "Feature 281: 0.1060\n",
            "Feature 763: 0.1059\n",
            "Feature 620: 0.1056\n",
            "Feature 761: -0.1051\n",
            "Feature 231: -0.1048\n",
            "Feature 367: 0.1040\n",
            "Feature 270: 0.1036\n",
            "Feature 776: -0.1035\n",
            "Feature 487: -0.1034\n",
            "Feature 639: 0.1030\n",
            "Feature 533: -0.1022\n",
            "Feature 408: 0.1020\n",
            "Feature 415: -0.1017\n",
            "Feature 801: -0.1017\n",
            "Feature 857: 0.1014\n",
            "Feature 791: -0.1009\n",
            "Feature 216: -0.1006\n",
            "Feature 455: 0.1002\n",
            "Feature 625: -0.0992\n",
            "Feature 277: 0.0989\n",
            "Feature 679: 0.0988\n",
            "Feature 203: 0.0983\n",
            "Feature 602: 0.0980\n",
            "Feature 172: -0.0979\n",
            "Feature 329: -0.0976\n",
            "Feature 560: -0.0973\n",
            "Feature 678: -0.0973\n",
            "Feature 169: 0.0969\n",
            "Feature 604: -0.0966\n",
            "Feature 832: 0.0959\n",
            "Feature 478: 0.0959\n",
            "Feature 456: 0.0958\n",
            "Feature 582: -0.0956\n",
            "Feature 800: 0.0956\n",
            "Feature 285: 0.0952\n",
            "Feature 847: 0.0950\n",
            "Feature 584: 0.0946\n",
            "Feature 148: -0.0945\n",
            "Feature 269: 0.0944\n",
            "Feature 321: 0.0941\n",
            "Feature 762: -0.0930\n",
            "Feature 682: 0.0927\n",
            "Feature 838: -0.0927\n",
            "Feature 688: -0.0926\n",
            "Feature 227: 0.0926\n",
            "Feature 607: -0.0925\n",
            "Feature 106: 0.0923\n",
            "Feature 740: 0.0923\n",
            "Feature 364: -0.0921\n",
            "Feature 181: -0.0919\n",
            "Feature 806: -0.0915\n",
            "Feature 524: 0.0908\n",
            "Feature 132: -0.0905\n",
            "Feature 304: 0.0899\n",
            "Feature 362: -0.0898\n",
            "Feature 646: -0.0898\n",
            "Feature 168: 0.0897\n",
            "Feature 350: -0.0895\n",
            "Feature 705: -0.0893\n",
            "Feature 420: 0.0890\n",
            "Feature 379: -0.0887\n",
            "Feature 395: 0.0885\n",
            "Feature 164: -0.0881\n",
            "Feature 311: -0.0879\n",
            "Feature 516: -0.0878\n",
            "Feature 606: -0.0877\n",
            "Feature 404: 0.0875\n",
            "Feature 713: 0.0873\n",
            "Feature 294: -0.0868\n",
            "Feature 619: -0.0864\n",
            "Feature 541: -0.0862\n",
            "Feature 545: -0.0858\n",
            "Feature 641: -0.0855\n",
            "Feature 271: 0.0852\n",
            "Feature 280: 0.0850\n",
            "Feature 717: -0.0848\n",
            "Feature 767: 0.0848\n",
            "Feature 166: 0.0848\n",
            "Feature 482: -0.0841\n",
            "Feature 300: 0.0834\n",
            "Feature 744: -0.0833\n",
            "Feature 223: 0.0832\n",
            "Feature 454: -0.0832\n",
            "Feature 457: -0.0821\n",
            "Feature 650: -0.0818\n",
            "Feature 805: 0.0817\n",
            "Feature 439: 0.0817\n",
            "Feature 48: 0.0812\n",
            "Feature 535: 0.0812\n",
            "Feature 573: -0.0806\n",
            "Feature 730: 0.0803\n",
            "Feature 839: -0.0803\n",
            "Feature 548: 0.0800\n",
            "Feature 322: 0.0799\n",
            "Feature 428: -0.0798\n",
            "Feature 115: 0.0792\n",
            "Feature 246: -0.0791\n",
            "Feature 423: 0.0791\n",
            "Feature 323: -0.0789\n",
            "Feature 313: -0.0788\n",
            "Feature 446: 0.0787\n",
            "Feature 596: 0.0776\n",
            "Feature 267: 0.0773\n",
            "Feature 289: -0.0772\n",
            "Feature 384: -0.0772\n",
            "Feature 120: 0.0768\n",
            "Feature 421: 0.0767\n",
            "Feature 174: 0.0765\n",
            "Feature 2: -0.0761\n",
            "Feature 775: 0.0759\n",
            "Feature 344: 0.0758\n",
            "Feature 368: -0.0758\n",
            "Feature 706: 0.0758\n",
            "Feature 348: -0.0756\n",
            "Feature 251: -0.0755\n",
            "Feature 36: -0.0755\n",
            "Feature 146: 0.0755\n",
            "Feature 522: -0.0754\n",
            "Feature 165: -0.0749\n",
            "Feature 756: -0.0744\n",
            "Feature 412: -0.0743\n",
            "Feature 846: 0.0743\n",
            "Feature 438: -0.0738\n",
            "Feature 661: -0.0736\n",
            "Feature 836: -0.0735\n",
            "Feature 529: -0.0735\n",
            "Feature 170: 0.0734\n",
            "Feature 376: -0.0726\n",
            "Feature 258: -0.0722\n",
            "Feature 684: -0.0721\n",
            "Feature 360: 0.0720\n",
            "Feature 506: -0.0719\n",
            "Feature 704: 0.0716\n",
            "Feature 644: -0.0716\n",
            "Feature 245: -0.0714\n",
            "Feature 405: -0.0714\n",
            "Feature 512: 0.0710\n",
            "Feature 852: -0.0710\n",
            "Feature 229: 0.0709\n",
            "Feature 191: -0.0709\n",
            "Feature 666: -0.0705\n",
            "Feature 797: 0.0701\n",
            "Feature 675: 0.0699\n",
            "Feature 816: 0.0699\n",
            "Feature 669: 0.0699\n",
            "Feature 610: -0.0698\n",
            "Feature 17: -0.0697\n",
            "Feature 273: 0.0695\n",
            "Feature 467: -0.0694\n",
            "Feature 643: 0.0694\n",
            "Feature 611: 0.0685\n",
            "Feature 301: -0.0683\n",
            "Feature 507: -0.0682\n",
            "Feature 471: -0.0681\n",
            "Feature 809: 0.0676\n",
            "Feature 225: -0.0669\n",
            "Feature 668: -0.0668\n",
            "Feature 707: 0.0666\n",
            "Feature 662: -0.0666\n",
            "Feature 654: 0.0663\n",
            "Feature 589: -0.0663\n",
            "Feature 651: -0.0660\n",
            "Feature 338: 0.0658\n",
            "Feature 137: -0.0656\n",
            "Feature 135: -0.0653\n",
            "Feature 167: 0.0651\n",
            "Feature 630: 0.0651\n",
            "Feature 841: 0.0651\n",
            "Feature 371: -0.0650\n",
            "Feature 764: 0.0650\n",
            "Feature 812: -0.0649\n",
            "Feature 303: -0.0647\n",
            "Feature 324: -0.0645\n",
            "Feature 117: 0.0645\n",
            "Feature 748: 0.0645\n",
            "Feature 347: 0.0645\n",
            "Feature 342: 0.0642\n",
            "Feature 363: 0.0640\n",
            "Feature 239: 0.0639\n",
            "Feature 176: 0.0637\n",
            "Feature 451: 0.0637\n",
            "Feature 708: 0.0636\n",
            "Feature 700: 0.0635\n",
            "Feature 783: 0.0633\n",
            "Feature 291: -0.0632\n",
            "Feature 448: 0.0630\n",
            "Feature 770: -0.0630\n",
            "Feature 581: 0.0624\n",
            "Feature 802: 0.0621\n",
            "Feature 465: 0.0621\n",
            "Feature 683: -0.0618\n",
            "Feature 538: -0.0618\n",
            "Feature 539: -0.0618\n",
            "Feature 305: -0.0614\n",
            "Feature 293: 0.0612\n",
            "Feature 810: -0.0612\n",
            "Feature 681: -0.0608\n",
            "Feature 788: -0.0605\n",
            "Feature 315: -0.0603\n",
            "Feature 116: 0.0602\n",
            "Feature 577: 0.0599\n",
            "Feature 676: -0.0598\n",
            "Feature 182: 0.0598\n",
            "Feature 550: -0.0598\n",
            "Feature 93: 0.0597\n",
            "Feature 461: -0.0597\n",
            "Feature 104: -0.0596\n",
            "Feature 221: 0.0595\n",
            "Feature 128: 0.0593\n",
            "Feature 750: -0.0592\n",
            "Feature 318: -0.0590\n",
            "Feature 346: -0.0589\n",
            "Feature 198: 0.0587\n",
            "Feature 565: 0.0586\n",
            "Feature 219: 0.0586\n",
            "Feature 377: -0.0584\n",
            "Feature 153: 0.0584\n",
            "Feature 685: -0.0583\n",
            "Feature 388: 0.0581\n",
            "Feature 418: -0.0581\n",
            "Feature 401: 0.0580\n",
            "Feature 638: 0.0574\n",
            "Feature 295: 0.0573\n",
            "Feature 159: 0.0569\n",
            "Feature 591: -0.0568\n",
            "Feature 101: -0.0560\n",
            "Feature 204: 0.0560\n",
            "Feature 484: -0.0559\n",
            "Feature 751: -0.0558\n",
            "Feature 817: 0.0556\n",
            "Feature 600: -0.0551\n",
            "Feature 419: -0.0550\n",
            "Feature 626: -0.0548\n",
            "Feature 201: -0.0542\n",
            "Feature 490: 0.0540\n",
            "Feature 383: 0.0540\n",
            "Feature 771: -0.0537\n",
            "Feature 536: 0.0535\n",
            "Feature 813: -0.0534\n",
            "Feature 356: -0.0533\n",
            "Feature 822: 0.0533\n",
            "Feature 42: -0.0526\n",
            "Feature 508: -0.0526\n",
            "Feature 310: 0.0525\n",
            "Feature 427: -0.0524\n",
            "Feature 837: -0.0514\n",
            "Feature 842: 0.0514\n",
            "Feature 719: 0.0512\n",
            "Feature 6: -0.0512\n",
            "Feature 211: 0.0509\n",
            "Feature 407: -0.0508\n",
            "Feature 578: 0.0506\n",
            "Feature 453: -0.0505\n",
            "Feature 792: 0.0503\n",
            "Feature 621: -0.0503\n",
            "Feature 381: -0.0499\n",
            "Feature 237: 0.0496\n",
            "Feature 217: -0.0494\n",
            "Feature 186: -0.0493\n",
            "Feature 728: 0.0492\n",
            "Feature 563: -0.0491\n",
            "Feature 114: -0.0491\n",
            "Feature 207: -0.0490\n",
            "Feature 632: -0.0490\n",
            "Feature 433: -0.0488\n",
            "Feature 195: -0.0487\n",
            "Feature 656: 0.0486\n",
            "Feature 397: -0.0485\n",
            "Feature 593: -0.0485\n",
            "Feature 359: 0.0484\n",
            "Feature 90: -0.0480\n",
            "Feature 659: -0.0476\n",
            "Feature 840: -0.0475\n",
            "Feature 345: -0.0474\n",
            "Feature 265: -0.0470\n",
            "Feature 718: 0.0468\n",
            "Feature 253: 0.0466\n",
            "Feature 158: -0.0466\n",
            "Feature 562: 0.0463\n",
            "Feature 758: -0.0462\n",
            "Feature 495: -0.0462\n",
            "Feature 694: 0.0461\n",
            "Feature 808: -0.0460\n",
            "Feature 698: -0.0460\n",
            "Feature 96: 0.0459\n",
            "Feature 118: 0.0459\n",
            "Feature 671: 0.0457\n",
            "Feature 714: -0.0451\n",
            "Feature 697: 0.0450\n",
            "Feature 357: -0.0449\n",
            "Feature 212: -0.0447\n",
            "Feature 772: 0.0446\n",
            "Feature 665: 0.0445\n",
            "Feature 599: 0.0445\n",
            "Feature 721: 0.0443\n",
            "Feature 479: 0.0440\n",
            "Feature 511: 0.0438\n",
            "Feature 493: 0.0435\n",
            "Feature 416: -0.0434\n",
            "Feature 729: 0.0433\n",
            "Feature 430: 0.0430\n",
            "Feature 703: 0.0428\n",
            "Feature 686: -0.0427\n",
            "Feature 426: -0.0426\n",
            "Feature 161: -0.0425\n",
            "Feature 608: -0.0424\n",
            "Feature 393: 0.0424\n",
            "Feature 286: -0.0423\n",
            "Feature 351: -0.0421\n",
            "Feature 738: -0.0419\n",
            "Feature 283: -0.0417\n",
            "Feature 733: -0.0416\n",
            "Feature 390: -0.0414\n",
            "Feature 100: -0.0413\n",
            "Feature 365: 0.0408\n",
            "Feature 807: 0.0406\n",
            "Feature 774: -0.0405\n",
            "Feature 595: -0.0403\n",
            "Feature 537: 0.0403\n",
            "Feature 127: 0.0403\n",
            "Feature 778: 0.0403\n",
            "Feature 601: 0.0401\n",
            "Feature 72: -0.0401\n",
            "Feature 622: 0.0399\n",
            "Feature 282: 0.0397\n",
            "Feature 583: -0.0397\n",
            "Feature 561: 0.0392\n",
            "Feature 319: -0.0390\n",
            "Feature 449: 0.0387\n",
            "Feature 667: 0.0381\n",
            "Feature 54: 0.0377\n",
            "Feature 462: 0.0376\n",
            "Feature 197: -0.0376\n",
            "Feature 463: -0.0372\n",
            "Feature 674: -0.0370\n",
            "Feature 624: 0.0370\n",
            "Feature 568: -0.0369\n",
            "Feature 769: -0.0369\n",
            "Feature 825: -0.0369\n",
            "Feature 320: 0.0366\n",
            "Feature 122: 0.0365\n",
            "Feature 731: -0.0364\n",
            "Feature 268: -0.0362\n",
            "Feature 307: 0.0361\n",
            "Feature 613: -0.0355\n",
            "Feature 828: 0.0350\n",
            "Feature 488: 0.0350\n",
            "Feature 557: -0.0348\n",
            "Feature 422: 0.0348\n",
            "Feature 515: -0.0348\n",
            "Feature 549: -0.0347\n",
            "Feature 94: 0.0346\n",
            "Feature 823: 0.0341\n",
            "Feature 830: -0.0340\n",
            "Feature 399: 0.0339\n",
            "Feature 434: 0.0337\n",
            "Feature 259: -0.0334\n",
            "Feature 240: -0.0332\n",
            "Feature 585: -0.0326\n",
            "Feature 826: -0.0324\n",
            "Feature 385: -0.0323\n",
            "Feature 554: -0.0323\n",
            "Feature 400: -0.0322\n",
            "Feature 372: -0.0320\n",
            "Feature 779: 0.0320\n",
            "Feature 657: -0.0320\n",
            "Feature 241: -0.0316\n",
            "Feature 566: -0.0315\n",
            "Feature 821: 0.0312\n",
            "Feature 534: -0.0307\n",
            "Feature 617: -0.0305\n",
            "Feature 287: 0.0302\n",
            "Feature 672: 0.0301\n",
            "Feature 292: -0.0301\n",
            "Feature 76: 0.0301\n",
            "Feature 284: 0.0298\n",
            "Feature 803: -0.0298\n",
            "Feature 61: -0.0298\n",
            "Feature 753: 0.0297\n",
            "Feature 178: 0.0293\n",
            "Feature 854: -0.0291\n",
            "Feature 759: 0.0291\n",
            "Feature 309: -0.0290\n",
            "Feature 559: -0.0289\n",
            "Feature 754: -0.0287\n",
            "Feature 192: 0.0287\n",
            "Feature 527: -0.0284\n",
            "Feature 234: -0.0282\n",
            "Feature 474: -0.0281\n",
            "Feature 29: 0.0279\n",
            "Feature 343: 0.0278\n",
            "Feature 266: -0.0272\n",
            "Feature 133: -0.0270\n",
            "Feature 472: -0.0270\n",
            "Feature 504: -0.0269\n",
            "Feature 337: -0.0269\n",
            "Feature 194: -0.0269\n",
            "Feature 514: 0.0268\n",
            "Feature 477: 0.0268\n",
            "Feature 139: 0.0267\n",
            "Feature 387: 0.0266\n",
            "Feature 781: -0.0265\n",
            "Feature 296: 0.0264\n",
            "Feature 858: -0.0263\n",
            "Feature 546: 0.0262\n",
            "Feature 175: -0.0261\n",
            "Feature 436: -0.0258\n",
            "Feature 111: 0.0258\n",
            "Feature 431: 0.0257\n",
            "Feature 316: 0.0257\n",
            "Feature 612: 0.0257\n",
            "Feature 142: 0.0256\n",
            "Feature 755: 0.0256\n",
            "Feature 623: 0.0256\n",
            "Feature 396: 0.0255\n",
            "Feature 220: -0.0250\n",
            "Feature 441: -0.0247\n",
            "Feature 609: -0.0247\n",
            "Feature 252: 0.0247\n",
            "Feature 444: 0.0245\n",
            "Feature 742: -0.0244\n",
            "Feature 850: 0.0243\n",
            "Feature 91: 0.0242\n",
            "Feature 410: -0.0240\n",
            "Feature 660: 0.0240\n",
            "Feature 353: 0.0240\n",
            "Feature 149: 0.0238\n",
            "Feature 99: -0.0237\n",
            "Feature 103: -0.0237\n",
            "Feature 558: 0.0234\n",
            "Feature 275: 0.0234\n",
            "Feature 710: -0.0234\n",
            "Feature 248: -0.0232\n",
            "Feature 314: -0.0231\n",
            "Feature 645: 0.0231\n",
            "Feature 67: -0.0229\n",
            "Feature 375: 0.0229\n",
            "Feature 312: 0.0229\n",
            "Feature 590: 0.0225\n",
            "Feature 196: 0.0223\n",
            "Feature 663: 0.0223\n",
            "Feature 366: -0.0222\n",
            "Feature 215: -0.0221\n",
            "Feature 747: -0.0221\n",
            "Feature 242: -0.0218\n",
            "Feature 732: 0.0218\n",
            "Feature 92: 0.0217\n",
            "Feature 121: -0.0215\n",
            "Feature 469: -0.0214\n",
            "Feature 73: -0.0213\n",
            "Feature 84: 0.0213\n",
            "Feature 65: 0.0211\n",
            "Feature 831: -0.0210\n",
            "Feature 209: 0.0210\n",
            "Feature 695: -0.0209\n",
            "Feature 79: 0.0207\n",
            "Feature 720: -0.0206\n",
            "Feature 136: 0.0206\n",
            "Feature 673: 0.0205\n",
            "Feature 598: 0.0205\n",
            "Feature 150: 0.0203\n",
            "Feature 340: 0.0203\n",
            "Feature 689: -0.0202\n",
            "Feature 138: -0.0198\n",
            "Feature 440: 0.0196\n",
            "Feature 141: -0.0194\n",
            "Feature 804: 0.0194\n",
            "Feature 193: 0.0194\n",
            "Feature 722: 0.0192\n",
            "Feature 526: 0.0189\n",
            "Feature 123: 0.0186\n",
            "Feature 443: 0.0185\n",
            "Feature 793: -0.0184\n",
            "Feature 518: 0.0184\n",
            "Feature 551: 0.0184\n",
            "Feature 696: -0.0183\n",
            "Feature 687: 0.0182\n",
            "Feature 331: 0.0177\n",
            "Feature 87: 0.0177\n",
            "Feature 765: 0.0170\n",
            "Feature 298: 0.0169\n",
            "Feature 414: -0.0169\n",
            "Feature 144: -0.0167\n",
            "Feature 392: -0.0161\n",
            "Feature 336: -0.0159\n",
            "Feature 151: -0.0158\n",
            "Feature 552: -0.0158\n",
            "Feature 202: -0.0157\n",
            "Feature 163: 0.0156\n",
            "Feature 82: -0.0156\n",
            "Feature 185: 0.0155\n",
            "Feature 302: 0.0154\n",
            "Feature 794: -0.0154\n",
            "Feature 481: -0.0152\n",
            "Feature 88: -0.0151\n",
            "Feature 485: -0.0149\n",
            "Feature 130: -0.0149\n",
            "Feature 476: 0.0148\n",
            "Feature 86: 0.0145\n",
            "Feature 409: -0.0145\n",
            "Feature 452: -0.0144\n",
            "Feature 263: 0.0144\n",
            "Feature 429: -0.0144\n",
            "Feature 658: -0.0142\n",
            "Feature 250: -0.0142\n",
            "Feature 199: -0.0140\n",
            "Feature 853: -0.0137\n",
            "Feature 588: -0.0134\n",
            "Feature 214: -0.0133\n",
            "Feature 155: -0.0133\n",
            "Feature 349: 0.0132\n",
            "Feature 580: 0.0131\n",
            "Feature 459: 0.0131\n",
            "Feature 849: -0.0128\n",
            "Feature 183: -0.0128\n",
            "Feature 374: -0.0125\n",
            "Feature 473: 0.0124\n",
            "Feature 464: -0.0123\n",
            "Feature 126: 0.0122\n",
            "Feature 766: -0.0121\n",
            "Feature 820: -0.0121\n",
            "Feature 540: 0.0120\n",
            "Feature 494: -0.0116\n",
            "Feature 74: 0.0116\n",
            "Feature 628: -0.0115\n",
            "Feature 107: 0.0115\n",
            "Feature 572: -0.0114\n",
            "Feature 605: -0.0112\n",
            "Feature 119: -0.0112\n",
            "Feature 228: -0.0111\n",
            "Feature 238: 0.0107\n",
            "Feature 75: -0.0107\n",
            "Feature 510: -0.0102\n",
            "Feature 102: -0.0102\n",
            "Feature 382: -0.0100\n",
            "Feature 782: -0.0098\n",
            "Feature 470: 0.0096\n",
            "Feature 567: 0.0096\n",
            "Feature 328: 0.0095\n",
            "Feature 634: -0.0095\n",
            "Feature 71: -0.0094\n",
            "Feature 450: 0.0093\n",
            "Feature 124: -0.0093\n",
            "Feature 335: -0.0092\n",
            "Feature 757: -0.0090\n",
            "Feature 83: -0.0089\n",
            "Feature 11: 0.0088\n",
            "Feature 386: 0.0087\n",
            "Feature 147: -0.0085\n",
            "Feature 723: 0.0085\n",
            "Feature 741: 0.0084\n",
            "Feature 716: 0.0082\n",
            "Feature 89: 0.0082\n",
            "Feature 616: 0.0082\n",
            "Feature 500: -0.0081\n",
            "Feature 69: 0.0081\n",
            "Feature 503: -0.0081\n",
            "Feature 784: 0.0078\n",
            "Feature 190: -0.0078\n",
            "Feature 160: -0.0078\n",
            "Feature 727: 0.0077\n",
            "Feature 66: 0.0071\n",
            "Feature 520: 0.0069\n",
            "Feature 425: -0.0068\n",
            "Feature 555: 0.0067\n",
            "Feature 68: -0.0063\n",
            "Feature 177: -0.0063\n",
            "Feature 553: -0.0056\n",
            "Feature 189: 0.0056\n",
            "Feature 85: -0.0056\n",
            "Feature 492: 0.0054\n",
            "Feature 125: 0.0053\n",
            "Feature 523: -0.0051\n",
            "Feature 78: -0.0051\n",
            "Feature 745: 0.0051\n",
            "Feature 373: 0.0050\n",
            "Feature 653: 0.0047\n",
            "Feature 834: 0.0045\n",
            "Feature 77: -0.0045\n",
            "Feature 835: -0.0045\n",
            "Feature 475: 0.0044\n",
            "Feature 637: -0.0041\n",
            "Feature 496: 0.0040\n",
            "Feature 648: -0.0039\n",
            "Feature 437: 0.0034\n",
            "Feature 256: -0.0032\n",
            "Feature 276: 0.0032\n",
            "Feature 571: -0.0029\n",
            "Feature 633: 0.0028\n",
            "Feature 773: 0.0028\n",
            "Feature 180: -0.0026\n",
            "Feature 442: -0.0026\n",
            "Feature 288: 0.0026\n",
            "Feature 843: 0.0023\n",
            "Feature 424: 0.0022\n",
            "Feature 64: 0.0018\n",
            "Feature 652: 0.0017\n",
            "Feature 411: 0.0016\n",
            "Feature 564: 0.0016\n",
            "Feature 519: 0.0015\n",
            "Feature 798: -0.0015\n",
            "Feature 715: 0.0015\n",
            "Feature 380: -0.0014\n",
            "Feature 279: 0.0014\n",
            "Feature 152: 0.0013\n",
            "Feature 306: -0.0013\n",
            "Feature 81: -0.0010\n",
            "Feature 402: -0.0010\n",
            "Feature 501: -0.0009\n",
            "Feature 70: 0.0009\n",
            "Feature 627: -0.0008\n",
            "Feature 230: -0.0008\n",
            "Feature 739: 0.0007\n",
            "Feature 570: -0.0005\n",
            "Feature 80: -0.0005\n",
            "Feature 325: 0.0003\n",
            "Feature 236: 0.0002\n",
            "Feature 531: 0.0001\n",
            "Feature 680: 0.0000\n",
            "Feature 502: 0.0000\n"
          ]
        }
      ],
      "source": [
        "clf = LogisticRegression(random_state=42, penalty='l2', C=1.0)\n",
        "\n",
        "clf.fit(X_train_features, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_features)\n",
        "y_pred_proba = clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "coefficients = clf.coef_[0]\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(coefficients))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, coef in feature_importance:\n",
        "    print(f\"{feature}: {coef:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ar_dnVe64gk"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmLFKkxgRJLQ",
        "outputId": "f5a7df82-1d9b-49be-e815-446e5c9d353e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial RandomForest Model Parameters:\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "RandomForest Model Parameters after Training:\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "RandomForest Model Performance with Specific Parameters\n",
            "Accuracy: 0.6724\n",
            "ROC-AUC Score: 0.7291\n",
            "Precision: 0.7683\n",
            "Recall: 0.6840\n",
            "F1 Score: 0.7237\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 97735  51943]\n",
            " [ 79593 172281]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 97: 0.0203\n",
            "Feature 363: 0.0199\n",
            "Feature 16: 0.0188\n",
            "Feature 438: 0.0176\n",
            "Feature 464: 0.0161\n",
            "Feature 419: 0.0151\n",
            "Feature 624: 0.0138\n",
            "Feature 361: 0.0128\n",
            "Feature 224: 0.0124\n",
            "Feature 441: 0.0122\n",
            "Feature 774: 0.0119\n",
            "Feature 208: 0.0117\n",
            "Feature 397: 0.0106\n",
            "Feature 47: 0.0105\n",
            "Feature 785: 0.0104\n",
            "Feature 107: 0.0104\n",
            "Feature 403: 0.0102\n",
            "Feature 222: 0.0096\n",
            "Feature 287: 0.0087\n",
            "Feature 50: 0.0078\n",
            "Feature 147: 0.0078\n",
            "Feature 344: 0.0076\n",
            "Feature 849: 0.0076\n",
            "Feature 606: 0.0075\n",
            "Feature 95: 0.0071\n",
            "Feature 12: 0.0071\n",
            "Feature 173: 0.0069\n",
            "Feature 162: 0.0069\n",
            "Feature 797: 0.0066\n",
            "Feature 5: 0.0064\n",
            "Feature 856: 0.0063\n",
            "Feature 636: 0.0061\n",
            "Feature 646: 0.0059\n",
            "Feature 239: 0.0058\n",
            "Feature 380: 0.0057\n",
            "Feature 425: 0.0056\n",
            "Feature 490: 0.0054\n",
            "Feature 552: 0.0054\n",
            "Feature 35: 0.0054\n",
            "Feature 351: 0.0051\n",
            "Feature 26: 0.0050\n",
            "Feature 367: 0.0050\n",
            "Feature 369: 0.0049\n",
            "Feature 62: 0.0049\n",
            "Feature 51: 0.0048\n",
            "Feature 607: 0.0048\n",
            "Feature 59: 0.0048\n",
            "Feature 21: 0.0048\n",
            "Feature 293: 0.0047\n",
            "Feature 55: 0.0046\n",
            "Feature 23: 0.0046\n",
            "Feature 840: 0.0045\n",
            "Feature 32: 0.0044\n",
            "Feature 801: 0.0044\n",
            "Feature 338: 0.0043\n",
            "Feature 495: 0.0043\n",
            "Feature 413: 0.0042\n",
            "Feature 460: 0.0042\n",
            "Feature 2: 0.0042\n",
            "Feature 467: 0.0041\n",
            "Feature 393: 0.0041\n",
            "Feature 486: 0.0040\n",
            "Feature 36: 0.0039\n",
            "Feature 487: 0.0038\n",
            "Feature 46: 0.0037\n",
            "Feature 245: 0.0037\n",
            "Feature 507: 0.0036\n",
            "Feature 308: 0.0034\n",
            "Feature 488: 0.0033\n",
            "Feature 673: 0.0033\n",
            "Feature 777: 0.0032\n",
            "Feature 631: 0.0032\n",
            "Feature 60: 0.0031\n",
            "Feature 593: 0.0031\n",
            "Feature 731: 0.0031\n",
            "Feature 192: 0.0031\n",
            "Feature 515: 0.0031\n",
            "Feature 821: 0.0030\n",
            "Feature 524: 0.0030\n",
            "Feature 118: 0.0030\n",
            "Feature 155: 0.0029\n",
            "Feature 322: 0.0029\n",
            "Feature 762: 0.0028\n",
            "Feature 4: 0.0028\n",
            "Feature 791: 0.0028\n",
            "Feature 377: 0.0028\n",
            "Feature 17: 0.0027\n",
            "Feature 141: 0.0027\n",
            "Feature 45: 0.0027\n",
            "Feature 770: 0.0027\n",
            "Feature 42: 0.0027\n",
            "Feature 384: 0.0026\n",
            "Feature 44: 0.0026\n",
            "Feature 61: 0.0026\n",
            "Feature 11: 0.0026\n",
            "Feature 48: 0.0025\n",
            "Feature 194: 0.0025\n",
            "Feature 20: 0.0024\n",
            "Feature 159: 0.0023\n",
            "Feature 472: 0.0023\n",
            "Feature 834: 0.0023\n",
            "Feature 476: 0.0023\n",
            "Feature 629: 0.0023\n",
            "Feature 25: 0.0023\n",
            "Feature 794: 0.0023\n",
            "Feature 305: 0.0023\n",
            "Feature 827: 0.0023\n",
            "Feature 145: 0.0023\n",
            "Feature 655: 0.0023\n",
            "Feature 811: 0.0022\n",
            "Feature 355: 0.0022\n",
            "Feature 215: 0.0022\n",
            "Feature 784: 0.0022\n",
            "Feature 38: 0.0021\n",
            "Feature 54: 0.0021\n",
            "Feature 19: 0.0020\n",
            "Feature 362: 0.0020\n",
            "Feature 193: 0.0020\n",
            "Feature 804: 0.0019\n",
            "Feature 644: 0.0019\n",
            "Feature 852: 0.0019\n",
            "Feature 491: 0.0019\n",
            "Feature 202: 0.0018\n",
            "Feature 129: 0.0018\n",
            "Feature 708: 0.0018\n",
            "Feature 236: 0.0018\n",
            "Feature 572: 0.0018\n",
            "Feature 594: 0.0018\n",
            "Feature 27: 0.0018\n",
            "Feature 610: 0.0018\n",
            "Feature 134: 0.0017\n",
            "Feature 0: 0.0017\n",
            "Feature 732: 0.0017\n",
            "Feature 291: 0.0017\n",
            "Feature 57: 0.0017\n",
            "Feature 744: 0.0017\n",
            "Feature 578: 0.0017\n",
            "Feature 738: 0.0017\n",
            "Feature 265: 0.0017\n",
            "Feature 848: 0.0016\n",
            "Feature 847: 0.0016\n",
            "Feature 574: 0.0016\n",
            "Feature 157: 0.0016\n",
            "Feature 543: 0.0016\n",
            "Feature 285: 0.0016\n",
            "Feature 763: 0.0016\n",
            "Feature 339: 0.0016\n",
            "Feature 1: 0.0015\n",
            "Feature 814: 0.0015\n",
            "Feature 18: 0.0015\n",
            "Feature 462: 0.0015\n",
            "Feature 786: 0.0015\n",
            "Feature 406: 0.0015\n",
            "Feature 313: 0.0015\n",
            "Feature 356: 0.0015\n",
            "Feature 449: 0.0014\n",
            "Feature 63: 0.0014\n",
            "Feature 7: 0.0014\n",
            "Feature 817: 0.0014\n",
            "Feature 760: 0.0014\n",
            "Feature 675: 0.0014\n",
            "Feature 15: 0.0014\n",
            "Feature 489: 0.0014\n",
            "Feature 116: 0.0014\n",
            "Feature 724: 0.0014\n",
            "Feature 49: 0.0014\n",
            "Feature 538: 0.0014\n",
            "Feature 237: 0.0014\n",
            "Feature 520: 0.0014\n",
            "Feature 34: 0.0013\n",
            "Feature 483: 0.0013\n",
            "Feature 580: 0.0013\n",
            "Feature 851: 0.0013\n",
            "Feature 221: 0.0013\n",
            "Feature 832: 0.0013\n",
            "Feature 31: 0.0013\n",
            "Feature 105: 0.0013\n",
            "Feature 743: 0.0013\n",
            "Feature 200: 0.0013\n",
            "Feature 831: 0.0013\n",
            "Feature 388: 0.0012\n",
            "Feature 121: 0.0012\n",
            "Feature 590: 0.0012\n",
            "Feature 108: 0.0012\n",
            "Feature 41: 0.0012\n",
            "Feature 562: 0.0012\n",
            "Feature 576: 0.0012\n",
            "Feature 301: 0.0012\n",
            "Feature 513: 0.0012\n",
            "Feature 765: 0.0012\n",
            "Feature 372: 0.0012\n",
            "Feature 8: 0.0012\n",
            "Feature 421: 0.0012\n",
            "Feature 671: 0.0012\n",
            "Feature 56: 0.0011\n",
            "Feature 599: 0.0011\n",
            "Feature 13: 0.0011\n",
            "Feature 256: 0.0011\n",
            "Feature 584: 0.0011\n",
            "Feature 6: 0.0011\n",
            "Feature 775: 0.0011\n",
            "Feature 771: 0.0011\n",
            "Feature 365: 0.0011\n",
            "Feature 480: 0.0011\n",
            "Feature 76: 0.0011\n",
            "Feature 776: 0.0011\n",
            "Feature 667: 0.0011\n",
            "Feature 530: 0.0010\n",
            "Feature 747: 0.0010\n",
            "Feature 756: 0.0010\n",
            "Feature 368: 0.0010\n",
            "Feature 818: 0.0010\n",
            "Feature 741: 0.0010\n",
            "Feature 14: 0.0010\n",
            "Feature 40: 0.0010\n",
            "Feature 316: 0.0010\n",
            "Feature 348: 0.0010\n",
            "Feature 269: 0.0010\n",
            "Feature 455: 0.0010\n",
            "Feature 637: 0.0010\n",
            "Feature 24: 0.0009\n",
            "Feature 788: 0.0009\n",
            "Feature 150: 0.0009\n",
            "Feature 766: 0.0009\n",
            "Feature 614: 0.0009\n",
            "Feature 206: 0.0009\n",
            "Feature 274: 0.0009\n",
            "Feature 414: 0.0009\n",
            "Feature 420: 0.0009\n",
            "Feature 641: 0.0009\n",
            "Feature 678: 0.0009\n",
            "Feature 753: 0.0009\n",
            "Feature 226: 0.0009\n",
            "Feature 39: 0.0009\n",
            "Feature 783: 0.0009\n",
            "Feature 813: 0.0009\n",
            "Feature 443: 0.0009\n",
            "Feature 567: 0.0009\n",
            "Feature 132: 0.0009\n",
            "Feature 461: 0.0009\n",
            "Feature 683: 0.0009\n",
            "Feature 697: 0.0009\n",
            "Feature 447: 0.0008\n",
            "Feature 272: 0.0008\n",
            "Feature 845: 0.0008\n",
            "Feature 652: 0.0008\n",
            "Feature 478: 0.0008\n",
            "Feature 442: 0.0008\n",
            "Feature 640: 0.0008\n",
            "Feature 37: 0.0008\n",
            "Feature 114: 0.0008\n",
            "Feature 321: 0.0008\n",
            "Feature 191: 0.0008\n",
            "Feature 517: 0.0008\n",
            "Feature 716: 0.0008\n",
            "Feature 241: 0.0008\n",
            "Feature 343: 0.0008\n",
            "Feature 440: 0.0008\n",
            "Feature 366: 0.0008\n",
            "Feature 579: 0.0008\n",
            "Feature 536: 0.0008\n",
            "Feature 422: 0.0008\n",
            "Feature 103: 0.0008\n",
            "Feature 679: 0.0008\n",
            "Feature 183: 0.0008\n",
            "Feature 689: 0.0008\n",
            "Feature 445: 0.0008\n",
            "Feature 281: 0.0008\n",
            "Feature 635: 0.0008\n",
            "Feature 152: 0.0007\n",
            "Feature 30: 0.0007\n",
            "Feature 604: 0.0007\n",
            "Feature 328: 0.0007\n",
            "Feature 216: 0.0007\n",
            "Feature 681: 0.0007\n",
            "Feature 225: 0.0007\n",
            "Feature 349: 0.0007\n",
            "Feature 767: 0.0007\n",
            "Feature 263: 0.0007\n",
            "Feature 53: 0.0007\n",
            "Feature 326: 0.0007\n",
            "Feature 511: 0.0007\n",
            "Feature 649: 0.0007\n",
            "Feature 648: 0.0007\n",
            "Feature 383: 0.0007\n",
            "Feature 701: 0.0007\n",
            "Feature 828: 0.0007\n",
            "Feature 318: 0.0007\n",
            "Feature 555: 0.0007\n",
            "Feature 665: 0.0007\n",
            "Feature 433: 0.0007\n",
            "Feature 347: 0.0007\n",
            "Feature 773: 0.0007\n",
            "Feature 643: 0.0007\n",
            "Feature 290: 0.0007\n",
            "Feature 278: 0.0007\n",
            "Feature 627: 0.0007\n",
            "Feature 736: 0.0007\n",
            "Feature 493: 0.0007\n",
            "Feature 415: 0.0006\n",
            "Feature 706: 0.0006\n",
            "Feature 128: 0.0006\n",
            "Feature 178: 0.0006\n",
            "Feature 427: 0.0006\n",
            "Feature 446: 0.0006\n",
            "Feature 91: 0.0006\n",
            "Feature 670: 0.0006\n",
            "Feature 503: 0.0006\n",
            "Feature 261: 0.0006\n",
            "Feature 325: 0.0006\n",
            "Feature 156: 0.0006\n",
            "Feature 309: 0.0006\n",
            "Feature 692: 0.0006\n",
            "Feature 542: 0.0006\n",
            "Feature 782: 0.0006\n",
            "Feature 509: 0.0006\n",
            "Feature 642: 0.0006\n",
            "Feature 416: 0.0006\n",
            "Feature 148: 0.0006\n",
            "Feature 755: 0.0006\n",
            "Feature 136: 0.0006\n",
            "Feature 210: 0.0006\n",
            "Feature 9: 0.0006\n",
            "Feature 540: 0.0006\n",
            "Feature 754: 0.0006\n",
            "Feature 364: 0.0006\n",
            "Feature 125: 0.0006\n",
            "Feature 541: 0.0006\n",
            "Feature 710: 0.0006\n",
            "Feature 294: 0.0006\n",
            "Feature 721: 0.0006\n",
            "Feature 408: 0.0006\n",
            "Feature 809: 0.0006\n",
            "Feature 855: 0.0006\n",
            "Feature 126: 0.0006\n",
            "Feature 454: 0.0006\n",
            "Feature 752: 0.0006\n",
            "Feature 836: 0.0006\n",
            "Feature 824: 0.0006\n",
            "Feature 557: 0.0006\n",
            "Feature 248: 0.0006\n",
            "Feature 473: 0.0006\n",
            "Feature 749: 0.0006\n",
            "Feature 214: 0.0006\n",
            "Feature 518: 0.0006\n",
            "Feature 452: 0.0006\n",
            "Feature 264: 0.0006\n",
            "Feature 439: 0.0006\n",
            "Feature 602: 0.0006\n",
            "Feature 119: 0.0006\n",
            "Feature 52: 0.0005\n",
            "Feature 647: 0.0005\n",
            "Feature 154: 0.0005\n",
            "Feature 303: 0.0005\n",
            "Feature 757: 0.0005\n",
            "Feature 622: 0.0005\n",
            "Feature 582: 0.0005\n",
            "Feature 694: 0.0005\n",
            "Feature 357: 0.0005\n",
            "Feature 140: 0.0005\n",
            "Feature 417: 0.0005\n",
            "Feature 171: 0.0005\n",
            "Feature 270: 0.0005\n",
            "Feature 842: 0.0005\n",
            "Feature 539: 0.0005\n",
            "Feature 588: 0.0005\n",
            "Feature 527: 0.0005\n",
            "Feature 717: 0.0005\n",
            "Feature 311: 0.0005\n",
            "Feature 688: 0.0005\n",
            "Feature 601: 0.0005\n",
            "Feature 28: 0.0005\n",
            "Feature 853: 0.0005\n",
            "Feature 161: 0.0005\n",
            "Feature 730: 0.0005\n",
            "Feature 146: 0.0005\n",
            "Feature 437: 0.0005\n",
            "Feature 324: 0.0005\n",
            "Feature 333: 0.0005\n",
            "Feature 839: 0.0005\n",
            "Feature 133: 0.0005\n",
            "Feature 534: 0.0005\n",
            "Feature 268: 0.0005\n",
            "Feature 254: 0.0005\n",
            "Feature 479: 0.0005\n",
            "Feature 498: 0.0005\n",
            "Feature 22: 0.0005\n",
            "Feature 553: 0.0005\n",
            "Feature 806: 0.0005\n",
            "Feature 317: 0.0005\n",
            "Feature 597: 0.0005\n",
            "Feature 235: 0.0005\n",
            "Feature 375: 0.0005\n",
            "Feature 266: 0.0005\n",
            "Feature 249: 0.0005\n",
            "Feature 533: 0.0005\n",
            "Feature 409: 0.0005\n",
            "Feature 630: 0.0005\n",
            "Feature 392: 0.0005\n",
            "Feature 196: 0.0005\n",
            "Feature 685: 0.0005\n",
            "Feature 172: 0.0005\n",
            "Feature 858: 0.0005\n",
            "Feature 549: 0.0005\n",
            "Feature 825: 0.0005\n",
            "Feature 658: 0.0005\n",
            "Feature 468: 0.0004\n",
            "Feature 180: 0.0004\n",
            "Feature 734: 0.0004\n",
            "Feature 528: 0.0004\n",
            "Feature 267: 0.0004\n",
            "Feature 131: 0.0004\n",
            "Feature 803: 0.0004\n",
            "Feature 3: 0.0004\n",
            "Feature 727: 0.0004\n",
            "Feature 544: 0.0004\n",
            "Feature 712: 0.0004\n",
            "Feature 307: 0.0004\n",
            "Feature 444: 0.0004\n",
            "Feature 385: 0.0004\n",
            "Feature 353: 0.0004\n",
            "Feature 418: 0.0004\n",
            "Feature 651: 0.0004\n",
            "Feature 170: 0.0004\n",
            "Feature 508: 0.0004\n",
            "Feature 623: 0.0004\n",
            "Feature 247: 0.0004\n",
            "Feature 800: 0.0004\n",
            "Feature 510: 0.0004\n",
            "Feature 802: 0.0004\n",
            "Feature 164: 0.0004\n",
            "Feature 111: 0.0004\n",
            "Feature 179: 0.0004\n",
            "Feature 838: 0.0004\n",
            "Feature 560: 0.0004\n",
            "Feature 396: 0.0004\n",
            "Feature 198: 0.0004\n",
            "Feature 780: 0.0004\n",
            "Feature 793: 0.0004\n",
            "Feature 204: 0.0004\n",
            "Feature 723: 0.0004\n",
            "Feature 854: 0.0004\n",
            "Feature 137: 0.0004\n",
            "Feature 184: 0.0004\n",
            "Feature 232: 0.0004\n",
            "Feature 563: 0.0004\n",
            "Feature 113: 0.0004\n",
            "Feature 428: 0.0004\n",
            "Feature 561: 0.0004\n",
            "Feature 581: 0.0004\n",
            "Feature 506: 0.0004\n",
            "Feature 769: 0.0004\n",
            "Feature 404: 0.0004\n",
            "Feature 174: 0.0004\n",
            "Feature 390: 0.0004\n",
            "Feature 58: 0.0004\n",
            "Feature 149: 0.0004\n",
            "Feature 532: 0.0004\n",
            "Feature 496: 0.0004\n",
            "Feature 220: 0.0004\n",
            "Feature 733: 0.0004\n",
            "Feature 583: 0.0004\n",
            "Feature 505: 0.0004\n",
            "Feature 587: 0.0004\n",
            "Feature 276: 0.0004\n",
            "Feature 117: 0.0004\n",
            "Feature 352: 0.0004\n",
            "Feature 761: 0.0004\n",
            "Feature 748: 0.0004\n",
            "Feature 94: 0.0004\n",
            "Feature 370: 0.0004\n",
            "Feature 336: 0.0004\n",
            "Feature 556: 0.0004\n",
            "Feature 320: 0.0004\n",
            "Feature 819: 0.0004\n",
            "Feature 187: 0.0004\n",
            "Feature 482: 0.0004\n",
            "Feature 664: 0.0004\n",
            "Feature 605: 0.0004\n",
            "Feature 674: 0.0004\n",
            "Feature 243: 0.0004\n",
            "Feature 234: 0.0003\n",
            "Feature 591: 0.0003\n",
            "Feature 378: 0.0003\n",
            "Feature 603: 0.0003\n",
            "Feature 168: 0.0003\n",
            "Feature 327: 0.0003\n",
            "Feature 844: 0.0003\n",
            "Feature 787: 0.0003\n",
            "Feature 373: 0.0003\n",
            "Feature 350: 0.0003\n",
            "Feature 711: 0.0003\n",
            "Feature 381: 0.0003\n",
            "Feature 815: 0.0003\n",
            "Feature 115: 0.0003\n",
            "Feature 297: 0.0003\n",
            "Feature 312: 0.0003\n",
            "Feature 516: 0.0003\n",
            "Feature 10: 0.0003\n",
            "Feature 329: 0.0003\n",
            "Feature 238: 0.0003\n",
            "Feature 165: 0.0003\n",
            "Feature 358: 0.0003\n",
            "Feature 231: 0.0003\n",
            "Feature 188: 0.0003\n",
            "Feature 662: 0.0003\n",
            "Feature 371: 0.0003\n",
            "Feature 260: 0.0003\n",
            "Feature 29: 0.0003\n",
            "Feature 197: 0.0003\n",
            "Feature 284: 0.0003\n",
            "Feature 135: 0.0003\n",
            "Feature 434: 0.0003\n",
            "Feature 379: 0.0003\n",
            "Feature 262: 0.0003\n",
            "Feature 746: 0.0003\n",
            "Feature 551: 0.0003\n",
            "Feature 739: 0.0003\n",
            "Feature 654: 0.0003\n",
            "Feature 386: 0.0003\n",
            "Feature 33: 0.0003\n",
            "Feature 571: 0.0003\n",
            "Feature 596: 0.0003\n",
            "Feature 166: 0.0003\n",
            "Feature 700: 0.0003\n",
            "Feature 109: 0.0003\n",
            "Feature 657: 0.0003\n",
            "Feature 810: 0.0003\n",
            "Feature 660: 0.0003\n",
            "Feature 302: 0.0003\n",
            "Feature 577: 0.0003\n",
            "Feature 398: 0.0003\n",
            "Feature 334: 0.0003\n",
            "Feature 789: 0.0003\n",
            "Feature 481: 0.0003\n",
            "Feature 737: 0.0003\n",
            "Feature 545: 0.0003\n",
            "Feature 669: 0.0003\n",
            "Feature 592: 0.0003\n",
            "Feature 625: 0.0003\n",
            "Feature 621: 0.0003\n",
            "Feature 242: 0.0003\n",
            "Feature 569: 0.0003\n",
            "Feature 289: 0.0003\n",
            "Feature 337: 0.0003\n",
            "Feature 360: 0.0003\n",
            "Feature 531: 0.0003\n",
            "Feature 282: 0.0003\n",
            "Feature 430: 0.0003\n",
            "Feature 233: 0.0003\n",
            "Feature 127: 0.0003\n",
            "Feature 499: 0.0003\n",
            "Feature 181: 0.0003\n",
            "Feature 120: 0.0003\n",
            "Feature 612: 0.0003\n",
            "Feature 586: 0.0003\n",
            "Feature 463: 0.0003\n",
            "Feature 514: 0.0003\n",
            "Feature 374: 0.0003\n",
            "Feature 92: 0.0003\n",
            "Feature 504: 0.0003\n",
            "Feature 779: 0.0003\n",
            "Feature 529: 0.0003\n",
            "Feature 223: 0.0003\n",
            "Feature 725: 0.0003\n",
            "Feature 759: 0.0003\n",
            "Feature 176: 0.0003\n",
            "Feature 687: 0.0003\n",
            "Feature 830: 0.0003\n",
            "Feature 143: 0.0003\n",
            "Feature 395: 0.0003\n",
            "Feature 535: 0.0003\n",
            "Feature 258: 0.0003\n",
            "Feature 299: 0.0003\n",
            "Feature 645: 0.0003\n",
            "Feature 451: 0.0003\n",
            "Feature 163: 0.0003\n",
            "Feature 735: 0.0002\n",
            "Feature 389: 0.0002\n",
            "Feature 790: 0.0002\n",
            "Feature 573: 0.0002\n",
            "Feature 160: 0.0002\n",
            "Feature 729: 0.0002\n",
            "Feature 423: 0.0002\n",
            "Feature 246: 0.0002\n",
            "Feature 650: 0.0002\n",
            "Feature 465: 0.0002\n",
            "Feature 526: 0.0002\n",
            "Feature 693: 0.0002\n",
            "Feature 764: 0.0002\n",
            "Feature 546: 0.0002\n",
            "Feature 795: 0.0002\n",
            "Feature 522: 0.0002\n",
            "Feature 672: 0.0002\n",
            "Feature 376: 0.0002\n",
            "Feature 346: 0.0002\n",
            "Feature 485: 0.0002\n",
            "Feature 471: 0.0002\n",
            "Feature 124: 0.0002\n",
            "Feature 271: 0.0002\n",
            "Feature 568: 0.0002\n",
            "Feature 728: 0.0002\n",
            "Feature 195: 0.0002\n",
            "Feature 617: 0.0002\n",
            "Feature 101: 0.0002\n",
            "Feature 432: 0.0002\n",
            "Feature 153: 0.0002\n",
            "Feature 799: 0.0002\n",
            "Feature 519: 0.0002\n",
            "Feature 768: 0.0002\n",
            "Feature 598: 0.0002\n",
            "Feature 812: 0.0002\n",
            "Feature 212: 0.0002\n",
            "Feature 750: 0.0002\n",
            "Feature 335: 0.0002\n",
            "Feature 304: 0.0002\n",
            "Feature 841: 0.0002\n",
            "Feature 751: 0.0002\n",
            "Feature 709: 0.0002\n",
            "Feature 704: 0.0002\n",
            "Feature 718: 0.0002\n",
            "Feature 494: 0.0002\n",
            "Feature 740: 0.0002\n",
            "Feature 158: 0.0002\n",
            "Feature 843: 0.0002\n",
            "Feature 123: 0.0002\n",
            "Feature 616: 0.0002\n",
            "Feature 227: 0.0002\n",
            "Feature 474: 0.0002\n",
            "Feature 523: 0.0002\n",
            "Feature 98: 0.0002\n",
            "Feature 742: 0.0002\n",
            "Feature 259: 0.0002\n",
            "Feature 106: 0.0002\n",
            "Feature 110: 0.0002\n",
            "Feature 255: 0.0002\n",
            "Feature 611: 0.0002\n",
            "Feature 429: 0.0002\n",
            "Feature 354: 0.0002\n",
            "Feature 283: 0.0002\n",
            "Feature 677: 0.0002\n",
            "Feature 391: 0.0002\n",
            "Feature 564: 0.0002\n",
            "Feature 808: 0.0002\n",
            "Feature 431: 0.0002\n",
            "Feature 228: 0.0002\n",
            "Feature 699: 0.0002\n",
            "Feature 620: 0.0002\n",
            "Feature 139: 0.0002\n",
            "Feature 691: 0.0002\n",
            "Feature 399: 0.0002\n",
            "Feature 142: 0.0002\n",
            "Feature 595: 0.0002\n",
            "Feature 253: 0.0002\n",
            "Feature 330: 0.0002\n",
            "Feature 456: 0.0002\n",
            "Feature 497: 0.0002\n",
            "Feature 638: 0.0002\n",
            "Feature 169: 0.0002\n",
            "Feature 829: 0.0002\n",
            "Feature 436: 0.0002\n",
            "Feature 589: 0.0002\n",
            "Feature 713: 0.0002\n",
            "Feature 705: 0.0002\n",
            "Feature 298: 0.0002\n",
            "Feature 477: 0.0002\n",
            "Feature 600: 0.0002\n",
            "Feature 559: 0.0002\n",
            "Feature 547: 0.0002\n",
            "Feature 219: 0.0002\n",
            "Feature 719: 0.0002\n",
            "Feature 112: 0.0002\n",
            "Feature 502: 0.0002\n",
            "Feature 189: 0.0002\n",
            "Feature 798: 0.0002\n",
            "Feature 707: 0.0002\n",
            "Feature 300: 0.0002\n",
            "Feature 448: 0.0002\n",
            "Feature 405: 0.0002\n",
            "Feature 323: 0.0002\n",
            "Feature 65: 0.0002\n",
            "Feature 466: 0.0002\n",
            "Feature 209: 0.0002\n",
            "Feature 615: 0.0002\n",
            "Feature 43: 0.0002\n",
            "Feature 340: 0.0002\n",
            "Feature 426: 0.0002\n",
            "Feature 521: 0.0002\n",
            "Feature 722: 0.0002\n",
            "Feature 686: 0.0002\n",
            "Feature 837: 0.0002\n",
            "Feature 213: 0.0002\n",
            "Feature 359: 0.0002\n",
            "Feature 778: 0.0002\n",
            "Feature 656: 0.0002\n",
            "Feature 273: 0.0002\n",
            "Feature 745: 0.0002\n",
            "Feature 618: 0.0002\n",
            "Feature 435: 0.0002\n",
            "Feature 332: 0.0002\n",
            "Feature 792: 0.0002\n",
            "Feature 680: 0.0002\n",
            "Feature 412: 0.0002\n",
            "Feature 382: 0.0002\n",
            "Feature 726: 0.0002\n",
            "Feature 341: 0.0002\n",
            "Feature 144: 0.0002\n",
            "Feature 484: 0.0001\n",
            "Feature 684: 0.0001\n",
            "Feature 501: 0.0001\n",
            "Feature 459: 0.0001\n",
            "Feature 342: 0.0001\n",
            "Feature 257: 0.0001\n",
            "Feature 633: 0.0001\n",
            "Feature 122: 0.0001\n",
            "Feature 203: 0.0001\n",
            "Feature 796: 0.0001\n",
            "Feature 151: 0.0001\n",
            "Feature 331: 0.0001\n",
            "Feature 772: 0.0001\n",
            "Feature 823: 0.0001\n",
            "Feature 696: 0.0001\n",
            "Feature 401: 0.0001\n",
            "Feature 781: 0.0001\n",
            "Feature 525: 0.0001\n",
            "Feature 251: 0.0001\n",
            "Feature 186: 0.0001\n",
            "Feature 252: 0.0001\n",
            "Feature 218: 0.0001\n",
            "Feature 639: 0.0001\n",
            "Feature 758: 0.0001\n",
            "Feature 835: 0.0001\n",
            "Feature 306: 0.0001\n",
            "Feature 619: 0.0001\n",
            "Feature 690: 0.0001\n",
            "Feature 230: 0.0001\n",
            "Feature 458: 0.0001\n",
            "Feature 99: 0.0001\n",
            "Feature 207: 0.0001\n",
            "Feature 816: 0.0001\n",
            "Feature 182: 0.0001\n",
            "Feature 310: 0.0001\n",
            "Feature 500: 0.0001\n",
            "Feature 244: 0.0001\n",
            "Feature 64: 0.0001\n",
            "Feature 820: 0.0001\n",
            "Feature 469: 0.0001\n",
            "Feature 295: 0.0001\n",
            "Feature 394: 0.0001\n",
            "Feature 288: 0.0001\n",
            "Feature 609: 0.0001\n",
            "Feature 96: 0.0001\n",
            "Feature 201: 0.0001\n",
            "Feature 185: 0.0001\n",
            "Feature 626: 0.0001\n",
            "Feature 805: 0.0001\n",
            "Feature 698: 0.0001\n",
            "Feature 470: 0.0001\n",
            "Feature 93: 0.0001\n",
            "Feature 130: 0.0001\n",
            "Feature 702: 0.0001\n",
            "Feature 286: 0.0001\n",
            "Feature 315: 0.0001\n",
            "Feature 104: 0.0001\n",
            "Feature 512: 0.0001\n",
            "Feature 822: 0.0001\n",
            "Feature 570: 0.0001\n",
            "Feature 387: 0.0001\n",
            "Feature 199: 0.0001\n",
            "Feature 492: 0.0001\n",
            "Feature 407: 0.0001\n",
            "Feature 85: 0.0001\n",
            "Feature 138: 0.0001\n",
            "Feature 714: 0.0001\n",
            "Feature 296: 0.0001\n",
            "Feature 550: 0.0001\n",
            "Feature 585: 0.0001\n",
            "Feature 345: 0.0001\n",
            "Feature 846: 0.0001\n",
            "Feature 703: 0.0001\n",
            "Feature 175: 0.0001\n",
            "Feature 566: 0.0001\n",
            "Feature 661: 0.0001\n",
            "Feature 720: 0.0001\n",
            "Feature 205: 0.0001\n",
            "Feature 457: 0.0001\n",
            "Feature 250: 0.0001\n",
            "Feature 280: 0.0001\n",
            "Feature 807: 0.0001\n",
            "Feature 211: 0.0001\n",
            "Feature 229: 0.0001\n",
            "Feature 613: 0.0001\n",
            "Feature 653: 0.0001\n",
            "Feature 450: 0.0001\n",
            "Feature 676: 0.0001\n",
            "Feature 453: 0.0001\n",
            "Feature 634: 0.0001\n",
            "Feature 314: 0.0001\n",
            "Feature 659: 0.0001\n",
            "Feature 537: 0.0001\n",
            "Feature 402: 0.0001\n",
            "Feature 554: 0.0001\n",
            "Feature 666: 0.0001\n",
            "Feature 400: 0.0001\n",
            "Feature 275: 0.0001\n",
            "Feature 190: 0.0001\n",
            "Feature 850: 0.0001\n",
            "Feature 565: 0.0001\n",
            "Feature 279: 0.0001\n",
            "Feature 240: 0.0001\n",
            "Feature 663: 0.0001\n",
            "Feature 575: 0.0001\n",
            "Feature 632: 0.0001\n",
            "Feature 715: 0.0001\n",
            "Feature 628: 0.0001\n",
            "Feature 319: 0.0001\n",
            "Feature 277: 0.0001\n",
            "Feature 84: 0.0001\n",
            "Feature 548: 0.0001\n",
            "Feature 292: 0.0001\n",
            "Feature 100: 0.0001\n",
            "Feature 826: 0.0001\n",
            "Feature 857: 0.0001\n",
            "Feature 89: 0.0001\n",
            "Feature 475: 0.0001\n",
            "Feature 411: 0.0001\n",
            "Feature 424: 0.0001\n",
            "Feature 79: 0.0001\n",
            "Feature 167: 0.0001\n",
            "Feature 558: 0.0001\n",
            "Feature 217: 0.0001\n",
            "Feature 833: 0.0001\n",
            "Feature 74: 0.0001\n",
            "Feature 71: 0.0001\n",
            "Feature 695: 0.0000\n",
            "Feature 682: 0.0000\n",
            "Feature 69: 0.0000\n",
            "Feature 608: 0.0000\n",
            "Feature 177: 0.0000\n",
            "Feature 410: 0.0000\n",
            "Feature 668: 0.0000\n",
            "Feature 86: 0.0000\n",
            "Feature 102: 0.0000\n",
            "Feature 68: 0.0000\n",
            "Feature 82: 0.0000\n",
            "Feature 81: 0.0000\n",
            "Feature 77: 0.0000\n",
            "Feature 66: 0.0000\n",
            "Feature 67: 0.0000\n",
            "Feature 78: 0.0000\n",
            "Feature 90: 0.0000\n",
            "Feature 70: 0.0000\n",
            "Feature 75: 0.0000\n",
            "Feature 80: 0.0000\n",
            "Feature 83: 0.0000\n",
            "Feature 87: 0.0000\n",
            "Feature 73: 0.0000\n",
            "Feature 72: 0.0000\n",
            "Feature 88: 0.0000\n"
          ]
        }
      ],
      "source": [
        "rf_clf = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=10, n_jobs=-1, class_weight='balanced')\n",
        "\n",
        "print(\"Initial RandomForest Model Parameters:\")\n",
        "print(rf_clf.get_params())\n",
        "\n",
        "rf_clf.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"\\nRandomForest Model Parameters after Training:\")\n",
        "print(rf_clf.get_params())\n",
        "\n",
        "rf_y_pred = rf_clf.predict(X_test_features)\n",
        "rf_y_pred_proba = rf_clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        "rf_roc_auc = roc_auc_score(y_test, rf_y_pred_proba)\n",
        "rf_precision = precision_score(y_test, rf_y_pred)\n",
        "rf_recall = recall_score(y_test, rf_y_pred)\n",
        "rf_f1 = f1_score(y_test, rf_y_pred)\n",
        "rf_confusion_matrix = confusion_matrix(y_test, rf_y_pred)\n",
        "\n",
        "print(\"\\nRandomForest Model Performance with Specific Parameters\")\n",
        "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {rf_roc_auc:.4f}\")\n",
        "print(f\"Precision: {rf_precision:.4f}\")\n",
        "print(f\"Recall: {rf_recall:.4f}\")\n",
        "print(f\"F1 Score: {rf_f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(rf_confusion_matrix)\n",
        "\n",
        "feature_importances = rf_clf.feature_importances_\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(feature_importances))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, importance in feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-wybfDZ65eU"
      },
      "source": [
        "**XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wOOVnKF65uI",
        "outputId": "99e59c36-6266-4319-f4a2-244c8fa1c496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial XGBoost Model Parameters:\n",
            "{'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': 0.5971770962957912, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [00:20:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost Model Parameters after Training:\n",
            "{'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': 0.5971770962957912, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n",
            "\n",
            "XGBoost Model Performance with Specific Parameters\n",
            "Accuracy: 0.7391\n",
            "ROC-AUC Score: 0.8125\n",
            "Precision: 0.8207\n",
            "Recall: 0.7472\n",
            "F1 Score: 0.7822\n",
            "\n",
            "Confusion Matrix:\n",
            "[[108568  41110]\n",
            " [ 63673 188201]]\n",
            "\n",
            "Feature Importance:\n",
            "Feature 464: 0.0660\n",
            "Feature 224: 0.0384\n",
            "Feature 438: 0.0273\n",
            "Feature 624: 0.0140\n",
            "Feature 97: 0.0140\n",
            "Feature 397: 0.0129\n",
            "Feature 786: 0.0113\n",
            "Feature 774: 0.0101\n",
            "Feature 35: 0.0086\n",
            "Feature 363: 0.0085\n",
            "Feature 425: 0.0080\n",
            "Feature 50: 0.0079\n",
            "Feature 785: 0.0078\n",
            "Feature 16: 0.0076\n",
            "Feature 90: 0.0069\n",
            "Feature 287: 0.0065\n",
            "Feature 849: 0.0063\n",
            "Feature 495: 0.0057\n",
            "Feature 285: 0.0054\n",
            "Feature 5: 0.0054\n",
            "Feature 344: 0.0052\n",
            "Feature 709: 0.0051\n",
            "Feature 51: 0.0048\n",
            "Feature 46: 0.0047\n",
            "Feature 47: 0.0046\n",
            "Feature 18: 0.0044\n",
            "Feature 636: 0.0044\n",
            "Feature 467: 0.0044\n",
            "Feature 4: 0.0044\n",
            "Feature 26: 0.0042\n",
            "Feature 59: 0.0041\n",
            "Feature 55: 0.0041\n",
            "Feature 743: 0.0041\n",
            "Feature 62: 0.0040\n",
            "Feature 21: 0.0040\n",
            "Feature 12: 0.0040\n",
            "Feature 155: 0.0040\n",
            "Feature 45: 0.0039\n",
            "Feature 488: 0.0038\n",
            "Feature 31: 0.0037\n",
            "Feature 42: 0.0037\n",
            "Feature 1: 0.0036\n",
            "Feature 32: 0.0036\n",
            "Feature 23: 0.0036\n",
            "Feature 486: 0.0036\n",
            "Feature 107: 0.0035\n",
            "Feature 20: 0.0033\n",
            "Feature 788: 0.0033\n",
            "Feature 491: 0.0033\n",
            "Feature 60: 0.0033\n",
            "Feature 266: 0.0033\n",
            "Feature 8: 0.0033\n",
            "Feature 49: 0.0032\n",
            "Feature 48: 0.0032\n",
            "Feature 840: 0.0032\n",
            "Feature 754: 0.0031\n",
            "Feature 145: 0.0031\n",
            "Feature 381: 0.0031\n",
            "Feature 827: 0.0031\n",
            "Feature 30: 0.0031\n",
            "Feature 34: 0.0031\n",
            "Feature 37: 0.0030\n",
            "Feature 487: 0.0029\n",
            "Feature 63: 0.0029\n",
            "Feature 198: 0.0028\n",
            "Feature 36: 0.0028\n",
            "Feature 57: 0.0028\n",
            "Feature 7: 0.0028\n",
            "Feature 38: 0.0028\n",
            "Feature 61: 0.0028\n",
            "Feature 607: 0.0028\n",
            "Feature 17: 0.0027\n",
            "Feature 40: 0.0027\n",
            "Feature 606: 0.0027\n",
            "Feature 270: 0.0027\n",
            "Feature 162: 0.0026\n",
            "Feature 669: 0.0026\n",
            "Feature 13: 0.0026\n",
            "Feature 668: 0.0026\n",
            "Feature 623: 0.0026\n",
            "Feature 95: 0.0025\n",
            "Feature 0: 0.0025\n",
            "Feature 524: 0.0025\n",
            "Feature 580: 0.0025\n",
            "Feature 24: 0.0024\n",
            "Feature 174: 0.0024\n",
            "Feature 6: 0.0024\n",
            "Feature 269: 0.0024\n",
            "Feature 14: 0.0023\n",
            "Feature 53: 0.0023\n",
            "Feature 52: 0.0023\n",
            "Feature 27: 0.0023\n",
            "Feature 44: 0.0022\n",
            "Feature 610: 0.0022\n",
            "Feature 236: 0.0022\n",
            "Feature 2: 0.0021\n",
            "Feature 41: 0.0021\n",
            "Feature 39: 0.0021\n",
            "Feature 604: 0.0021\n",
            "Feature 579: 0.0021\n",
            "Feature 817: 0.0021\n",
            "Feature 465: 0.0021\n",
            "Feature 54: 0.0021\n",
            "Feature 732: 0.0021\n",
            "Feature 15: 0.0021\n",
            "Feature 483: 0.0020\n",
            "Feature 22: 0.0020\n",
            "Feature 631: 0.0020\n",
            "Feature 719: 0.0020\n",
            "Feature 408: 0.0020\n",
            "Feature 56: 0.0020\n",
            "Feature 11: 0.0020\n",
            "Feature 372: 0.0019\n",
            "Feature 308: 0.0019\n",
            "Feature 58: 0.0019\n",
            "Feature 385: 0.0019\n",
            "Feature 812: 0.0018\n",
            "Feature 516: 0.0018\n",
            "Feature 379: 0.0018\n",
            "Feature 818: 0.0018\n",
            "Feature 214: 0.0018\n",
            "Feature 67: 0.0018\n",
            "Feature 28: 0.0017\n",
            "Feature 334: 0.0017\n",
            "Feature 509: 0.0017\n",
            "Feature 19: 0.0017\n",
            "Feature 542: 0.0017\n",
            "Feature 86: 0.0017\n",
            "Feature 200: 0.0017\n",
            "Feature 671: 0.0017\n",
            "Feature 348: 0.0017\n",
            "Feature 117: 0.0016\n",
            "Feature 685: 0.0016\n",
            "Feature 825: 0.0016\n",
            "Feature 380: 0.0016\n",
            "Feature 499: 0.0016\n",
            "Feature 3: 0.0016\n",
            "Feature 10: 0.0016\n",
            "Feature 76: 0.0016\n",
            "Feature 208: 0.0016\n",
            "Feature 362: 0.0016\n",
            "Feature 446: 0.0016\n",
            "Feature 116: 0.0016\n",
            "Feature 365: 0.0015\n",
            "Feature 403: 0.0015\n",
            "Feature 654: 0.0015\n",
            "Feature 29: 0.0015\n",
            "Feature 373: 0.0015\n",
            "Feature 9: 0.0015\n",
            "Feature 429: 0.0015\n",
            "Feature 318: 0.0015\n",
            "Feature 68: 0.0015\n",
            "Feature 406: 0.0015\n",
            "Feature 584: 0.0015\n",
            "Feature 316: 0.0015\n",
            "Feature 746: 0.0014\n",
            "Feature 147: 0.0014\n",
            "Feature 557: 0.0014\n",
            "Feature 541: 0.0014\n",
            "Feature 114: 0.0014\n",
            "Feature 640: 0.0014\n",
            "Feature 191: 0.0014\n",
            "Feature 662: 0.0014\n",
            "Feature 126: 0.0014\n",
            "Feature 310: 0.0014\n",
            "Feature 508: 0.0014\n",
            "Feature 760: 0.0014\n",
            "Feature 378: 0.0014\n",
            "Feature 350: 0.0014\n",
            "Feature 808: 0.0014\n",
            "Feature 771: 0.0014\n",
            "Feature 856: 0.0013\n",
            "Feature 25: 0.0013\n",
            "Feature 716: 0.0013\n",
            "Feature 206: 0.0013\n",
            "Feature 96: 0.0013\n",
            "Feature 804: 0.0013\n",
            "Feature 301: 0.0013\n",
            "Feature 455: 0.0013\n",
            "Feature 338: 0.0013\n",
            "Feature 202: 0.0013\n",
            "Feature 784: 0.0013\n",
            "Feature 800: 0.0013\n",
            "Feature 282: 0.0013\n",
            "Feature 274: 0.0013\n",
            "Feature 82: 0.0013\n",
            "Feature 168: 0.0013\n",
            "Feature 72: 0.0013\n",
            "Feature 449: 0.0012\n",
            "Feature 522: 0.0012\n",
            "Feature 651: 0.0012\n",
            "Feature 791: 0.0012\n",
            "Feature 238: 0.0012\n",
            "Feature 677: 0.0012\n",
            "Feature 278: 0.0012\n",
            "Feature 358: 0.0012\n",
            "Feature 441: 0.0012\n",
            "Feature 180: 0.0012\n",
            "Feature 361: 0.0012\n",
            "Feature 482: 0.0012\n",
            "Feature 77: 0.0012\n",
            "Feature 33: 0.0012\n",
            "Feature 113: 0.0012\n",
            "Feature 43: 0.0012\n",
            "Feature 445: 0.0012\n",
            "Feature 794: 0.0012\n",
            "Feature 553: 0.0011\n",
            "Feature 73: 0.0011\n",
            "Feature 593: 0.0011\n",
            "Feature 489: 0.0011\n",
            "Feature 75: 0.0011\n",
            "Feature 81: 0.0011\n",
            "Feature 253: 0.0011\n",
            "Feature 421: 0.0011\n",
            "Feature 336: 0.0011\n",
            "Feature 364: 0.0011\n",
            "Feature 707: 0.0011\n",
            "Feature 678: 0.0011\n",
            "Feature 143: 0.0011\n",
            "Feature 529: 0.0011\n",
            "Feature 494: 0.0011\n",
            "Feature 127: 0.0011\n",
            "Feature 565: 0.0011\n",
            "Feature 686: 0.0011\n",
            "Feature 133: 0.0011\n",
            "Feature 119: 0.0011\n",
            "Feature 309: 0.0010\n",
            "Feature 572: 0.0010\n",
            "Feature 132: 0.0010\n",
            "Feature 752: 0.0010\n",
            "Feature 173: 0.0010\n",
            "Feature 858: 0.0010\n",
            "Feature 839: 0.0010\n",
            "Feature 560: 0.0010\n",
            "Feature 196: 0.0010\n",
            "Feature 85: 0.0010\n",
            "Feature 627: 0.0010\n",
            "Feature 290: 0.0010\n",
            "Feature 265: 0.0010\n",
            "Feature 454: 0.0010\n",
            "Feature 239: 0.0010\n",
            "Feature 718: 0.0010\n",
            "Feature 152: 0.0010\n",
            "Feature 355: 0.0010\n",
            "Feature 121: 0.0010\n",
            "Feature 603: 0.0010\n",
            "Feature 139: 0.0010\n",
            "Feature 437: 0.0010\n",
            "Feature 129: 0.0010\n",
            "Feature 793: 0.0010\n",
            "Feature 329: 0.0010\n",
            "Feature 775: 0.0010\n",
            "Feature 221: 0.0010\n",
            "Feature 744: 0.0010\n",
            "Feature 187: 0.0009\n",
            "Feature 79: 0.0009\n",
            "Feature 439: 0.0009\n",
            "Feature 589: 0.0009\n",
            "Feature 157: 0.0009\n",
            "Feature 767: 0.0009\n",
            "Feature 637: 0.0009\n",
            "Feature 855: 0.0009\n",
            "Feature 281: 0.0009\n",
            "Feature 232: 0.0009\n",
            "Feature 337: 0.0009\n",
            "Feature 796: 0.0009\n",
            "Feature 165: 0.0009\n",
            "Feature 730: 0.0009\n",
            "Feature 518: 0.0009\n",
            "Feature 84: 0.0009\n",
            "Feature 679: 0.0009\n",
            "Feature 386: 0.0009\n",
            "Feature 305: 0.0009\n",
            "Feature 74: 0.0009\n",
            "Feature 276: 0.0009\n",
            "Feature 306: 0.0009\n",
            "Feature 341: 0.0009\n",
            "Feature 83: 0.0009\n",
            "Feature 94: 0.0009\n",
            "Feature 110: 0.0009\n",
            "Feature 237: 0.0009\n",
            "Feature 246: 0.0009\n",
            "Feature 739: 0.0009\n",
            "Feature 792: 0.0009\n",
            "Feature 629: 0.0008\n",
            "Feature 325: 0.0008\n",
            "Feature 706: 0.0008\n",
            "Feature 415: 0.0008\n",
            "Feature 748: 0.0008\n",
            "Feature 729: 0.0008\n",
            "Feature 417: 0.0008\n",
            "Feature 715: 0.0008\n",
            "Feature 382: 0.0008\n",
            "Feature 105: 0.0008\n",
            "Feature 91: 0.0008\n",
            "Feature 705: 0.0008\n",
            "Feature 528: 0.0008\n",
            "Feature 92: 0.0008\n",
            "Feature 658: 0.0008\n",
            "Feature 701: 0.0008\n",
            "Feature 617: 0.0008\n",
            "Feature 87: 0.0008\n",
            "Feature 680: 0.0008\n",
            "Feature 649: 0.0008\n",
            "Feature 641: 0.0008\n",
            "Feature 811: 0.0008\n",
            "Feature 428: 0.0008\n",
            "Feature 399: 0.0008\n",
            "Feature 171: 0.0008\n",
            "Feature 533: 0.0008\n",
            "Feature 128: 0.0008\n",
            "Feature 460: 0.0008\n",
            "Feature 497: 0.0008\n",
            "Feature 140: 0.0008\n",
            "Feature 109: 0.0008\n",
            "Feature 853: 0.0008\n",
            "Feature 574: 0.0008\n",
            "Feature 340: 0.0008\n",
            "Feature 687: 0.0008\n",
            "Feature 462: 0.0008\n",
            "Feature 294: 0.0008\n",
            "Feature 149: 0.0008\n",
            "Feature 249: 0.0008\n",
            "Feature 582: 0.0008\n",
            "Feature 588: 0.0008\n",
            "Feature 733: 0.0008\n",
            "Feature 235: 0.0008\n",
            "Feature 479: 0.0008\n",
            "Feature 602: 0.0008\n",
            "Feature 838: 0.0007\n",
            "Feature 626: 0.0007\n",
            "Feature 852: 0.0007\n",
            "Feature 681: 0.0007\n",
            "Feature 736: 0.0007\n",
            "Feature 226: 0.0007\n",
            "Feature 549: 0.0007\n",
            "Feature 183: 0.0007\n",
            "Feature 814: 0.0007\n",
            "Feature 225: 0.0007\n",
            "Feature 646: 0.0007\n",
            "Feature 352: 0.0007\n",
            "Feature 832: 0.0007\n",
            "Feature 848: 0.0007\n",
            "Feature 801: 0.0007\n",
            "Feature 692: 0.0007\n",
            "Feature 779: 0.0007\n",
            "Feature 367: 0.0007\n",
            "Feature 710: 0.0007\n",
            "Feature 652: 0.0007\n",
            "Feature 368: 0.0007\n",
            "Feature 179: 0.0007\n",
            "Feature 197: 0.0007\n",
            "Feature 220: 0.0007\n",
            "Feature 472: 0.0007\n",
            "Feature 98: 0.0007\n",
            "Feature 393: 0.0007\n",
            "Feature 559: 0.0007\n",
            "Feature 520: 0.0007\n",
            "Feature 650: 0.0007\n",
            "Feature 614: 0.0007\n",
            "Feature 803: 0.0007\n",
            "Feature 618: 0.0007\n",
            "Feature 150: 0.0007\n",
            "Feature 642: 0.0007\n",
            "Feature 452: 0.0007\n",
            "Feature 526: 0.0007\n",
            "Feature 476: 0.0007\n",
            "Feature 194: 0.0007\n",
            "Feature 787: 0.0007\n",
            "Feature 829: 0.0007\n",
            "Feature 65: 0.0007\n",
            "Feature 468: 0.0007\n",
            "Feature 578: 0.0007\n",
            "Feature 312: 0.0007\n",
            "Feature 493: 0.0007\n",
            "Feature 242: 0.0007\n",
            "Feature 734: 0.0007\n",
            "Feature 184: 0.0007\n",
            "Feature 303: 0.0007\n",
            "Feature 761: 0.0007\n",
            "Feature 655: 0.0007\n",
            "Feature 704: 0.0007\n",
            "Feature 103: 0.0007\n",
            "Feature 824: 0.0007\n",
            "Feature 713: 0.0007\n",
            "Feature 193: 0.0007\n",
            "Feature 69: 0.0007\n",
            "Feature 821: 0.0007\n",
            "Feature 543: 0.0007\n",
            "Feature 134: 0.0007\n",
            "Feature 118: 0.0007\n",
            "Feature 210: 0.0007\n",
            "Feature 795: 0.0007\n",
            "Feature 530: 0.0007\n",
            "Feature 666: 0.0007\n",
            "Feature 369: 0.0007\n",
            "Feature 513: 0.0007\n",
            "Feature 605: 0.0007\n",
            "Feature 234: 0.0007\n",
            "Feature 339: 0.0007\n",
            "Feature 504: 0.0006\n",
            "Feature 844: 0.0006\n",
            "Feature 656: 0.0006\n",
            "Feature 327: 0.0006\n",
            "Feature 71: 0.0006\n",
            "Feature 503: 0.0006\n",
            "Feature 383: 0.0006\n",
            "Feature 816: 0.0006\n",
            "Feature 556: 0.0006\n",
            "Feature 302: 0.0006\n",
            "Feature 398: 0.0006\n",
            "Feature 461: 0.0006\n",
            "Feature 544: 0.0006\n",
            "Feature 505: 0.0006\n",
            "Feature 563: 0.0006\n",
            "Feature 433: 0.0006\n",
            "Feature 345: 0.0006\n",
            "Feature 622: 0.0006\n",
            "Feature 561: 0.0006\n",
            "Feature 375: 0.0006\n",
            "Feature 576: 0.0006\n",
            "Feature 798: 0.0006\n",
            "Feature 328: 0.0006\n",
            "Feature 714: 0.0006\n",
            "Feature 131: 0.0006\n",
            "Feature 262: 0.0006\n",
            "Feature 724: 0.0006\n",
            "Feature 324: 0.0006\n",
            "Feature 293: 0.0006\n",
            "Feature 570: 0.0006\n",
            "Feature 141: 0.0006\n",
            "Feature 175: 0.0006\n",
            "Feature 552: 0.0006\n",
            "Feature 845: 0.0006\n",
            "Feature 245: 0.0006\n",
            "Feature 291: 0.0006\n",
            "Feature 665: 0.0006\n",
            "Feature 545: 0.0006\n",
            "Feature 330: 0.0006\n",
            "Feature 540: 0.0006\n",
            "Feature 254: 0.0006\n",
            "Feature 836: 0.0006\n",
            "Feature 371: 0.0006\n",
            "Feature 854: 0.0006\n",
            "Feature 413: 0.0006\n",
            "Feature 567: 0.0006\n",
            "Feature 323: 0.0006\n",
            "Feature 782: 0.0006\n",
            "Feature 178: 0.0006\n",
            "Feature 222: 0.0006\n",
            "Feature 601: 0.0006\n",
            "Feature 742: 0.0006\n",
            "Feature 717: 0.0006\n",
            "Feature 689: 0.0006\n",
            "Feature 80: 0.0006\n",
            "Feature 156: 0.0006\n",
            "Feature 708: 0.0006\n",
            "Feature 485: 0.0006\n",
            "Feature 456: 0.0006\n",
            "Feature 414: 0.0006\n",
            "Feature 500: 0.0006\n",
            "Feature 144: 0.0006\n",
            "Feature 587: 0.0006\n",
            "Feature 473: 0.0006\n",
            "Feature 735: 0.0006\n",
            "Feature 789: 0.0006\n",
            "Feature 251: 0.0006\n",
            "Feature 783: 0.0006\n",
            "Feature 154: 0.0005\n",
            "Feature 749: 0.0005\n",
            "Feature 353: 0.0005\n",
            "Feature 517: 0.0005\n",
            "Feature 148: 0.0005\n",
            "Feature 477: 0.0005\n",
            "Feature 722: 0.0005\n",
            "Feature 696: 0.0005\n",
            "Feature 311: 0.0005\n",
            "Feature 427: 0.0005\n",
            "Feature 115: 0.0005\n",
            "Feature 720: 0.0005\n",
            "Feature 64: 0.0005\n",
            "Feature 490: 0.0005\n",
            "Feature 442: 0.0005\n",
            "Feature 507: 0.0005\n",
            "Feature 102: 0.0005\n",
            "Feature 672: 0.0005\n",
            "Feature 111: 0.0005\n",
            "Feature 189: 0.0005\n",
            "Feature 834: 0.0005\n",
            "Feature 260: 0.0005\n",
            "Feature 244: 0.0005\n",
            "Feature 600: 0.0005\n",
            "Feature 204: 0.0005\n",
            "Feature 182: 0.0005\n",
            "Feature 153: 0.0005\n",
            "Feature 753: 0.0005\n",
            "Feature 611: 0.0005\n",
            "Feature 268: 0.0005\n",
            "Feature 731: 0.0005\n",
            "Feature 625: 0.0005\n",
            "Feature 112: 0.0005\n",
            "Feature 142: 0.0005\n",
            "Feature 596: 0.0005\n",
            "Feature 120: 0.0005\n",
            "Feature 847: 0.0005\n",
            "Feature 777: 0.0005\n",
            "Feature 657: 0.0005\n",
            "Feature 725: 0.0005\n",
            "Feature 241: 0.0005\n",
            "Feature 212: 0.0005\n",
            "Feature 388: 0.0005\n",
            "Feature 161: 0.0005\n",
            "Feature 321: 0.0005\n",
            "Feature 727: 0.0005\n",
            "Feature 758: 0.0005\n",
            "Feature 322: 0.0005\n",
            "Feature 125: 0.0005\n",
            "Feature 813: 0.0005\n",
            "Feature 217: 0.0005\n",
            "Feature 389: 0.0005\n",
            "Feature 498: 0.0005\n",
            "Feature 170: 0.0005\n",
            "Feature 630: 0.0005\n",
            "Feature 688: 0.0005\n",
            "Feature 673: 0.0005\n",
            "Feature 539: 0.0005\n",
            "Feature 586: 0.0005\n",
            "Feature 780: 0.0005\n",
            "Feature 370: 0.0005\n",
            "Feature 343: 0.0005\n",
            "Feature 264: 0.0005\n",
            "Feature 108: 0.0005\n",
            "Feature 842: 0.0005\n",
            "Feature 231: 0.0005\n",
            "Feature 135: 0.0005\n",
            "Feature 333: 0.0005\n",
            "Feature 314: 0.0005\n",
            "Feature 377: 0.0005\n",
            "Feature 451: 0.0005\n",
            "Feature 66: 0.0005\n",
            "Feature 297: 0.0005\n",
            "Feature 551: 0.0005\n",
            "Feature 166: 0.0005\n",
            "Feature 480: 0.0005\n",
            "Feature 851: 0.0005\n",
            "Feature 275: 0.0005\n",
            "Feature 326: 0.0005\n",
            "Feature 247: 0.0005\n",
            "Feature 407: 0.0005\n",
            "Feature 806: 0.0005\n",
            "Feature 819: 0.0005\n",
            "Feature 683: 0.0005\n",
            "Feature 419: 0.0005\n",
            "Feature 564: 0.0004\n",
            "Feature 349: 0.0004\n",
            "Feature 188: 0.0004\n",
            "Feature 420: 0.0004\n",
            "Feature 635: 0.0004\n",
            "Feature 271: 0.0004\n",
            "Feature 699: 0.0004\n",
            "Feature 169: 0.0004\n",
            "Feature 315: 0.0004\n",
            "Feature 721: 0.0004\n",
            "Feature 620: 0.0004\n",
            "Feature 458: 0.0004\n",
            "Feature 354: 0.0004\n",
            "Feature 300: 0.0004\n",
            "Feature 331: 0.0004\n",
            "Feature 89: 0.0004\n",
            "Feature 837: 0.0004\n",
            "Feature 757: 0.0004\n",
            "Feature 531: 0.0004\n",
            "Feature 70: 0.0004\n",
            "Feature 228: 0.0004\n",
            "Feature 192: 0.0004\n",
            "Feature 737: 0.0004\n",
            "Feature 675: 0.0004\n",
            "Feature 809: 0.0004\n",
            "Feature 711: 0.0004\n",
            "Feature 347: 0.0004\n",
            "Feature 616: 0.0004\n",
            "Feature 432: 0.0004\n",
            "Feature 810: 0.0004\n",
            "Feature 768: 0.0004\n",
            "Feature 404: 0.0004\n",
            "Feature 527: 0.0004\n",
            "Feature 478: 0.0004\n",
            "Feature 99: 0.0004\n",
            "Feature 320: 0.0004\n",
            "Feature 515: 0.0004\n",
            "Feature 643: 0.0004\n",
            "Feature 317: 0.0004\n",
            "Feature 759: 0.0004\n",
            "Feature 436: 0.0004\n",
            "Feature 697: 0.0004\n",
            "Feature 790: 0.0004\n",
            "Feature 211: 0.0004\n",
            "Feature 359: 0.0004\n",
            "Feature 313: 0.0004\n",
            "Feature 78: 0.0004\n",
            "Feature 209: 0.0004\n",
            "Feature 357: 0.0004\n",
            "Feature 402: 0.0004\n",
            "Feature 648: 0.0004\n",
            "Feature 645: 0.0004\n",
            "Feature 592: 0.0004\n",
            "Feature 512: 0.0004\n",
            "Feature 395: 0.0004\n",
            "Feature 123: 0.0004\n",
            "Feature 444: 0.0004\n",
            "Feature 797: 0.0004\n",
            "Feature 257: 0.0004\n",
            "Feature 802: 0.0004\n",
            "Feature 769: 0.0004\n",
            "Feature 423: 0.0004\n",
            "Feature 151: 0.0004\n",
            "Feature 615: 0.0004\n",
            "Feature 571: 0.0004\n",
            "Feature 272: 0.0004\n",
            "Feature 351: 0.0004\n",
            "Feature 106: 0.0004\n",
            "Feature 167: 0.0004\n",
            "Feature 532: 0.0004\n",
            "Feature 591: 0.0004\n",
            "Feature 569: 0.0004\n",
            "Feature 830: 0.0004\n",
            "Feature 435: 0.0004\n",
            "Feature 799: 0.0004\n",
            "Feature 684: 0.0004\n",
            "Feature 773: 0.0004\n",
            "Feature 647: 0.0004\n",
            "Feature 255: 0.0004\n",
            "Feature 728: 0.0004\n",
            "Feature 766: 0.0003\n",
            "Feature 575: 0.0003\n",
            "Feature 307: 0.0003\n",
            "Feature 374: 0.0003\n",
            "Feature 581: 0.0003\n",
            "Feature 660: 0.0003\n",
            "Feature 430: 0.0003\n",
            "Feature 831: 0.0003\n",
            "Feature 554: 0.0003\n",
            "Feature 448: 0.0003\n",
            "Feature 243: 0.0003\n",
            "Feature 523: 0.0003\n",
            "Feature 283: 0.0003\n",
            "Feature 229: 0.0003\n",
            "Feature 664: 0.0003\n",
            "Feature 694: 0.0003\n",
            "Feature 267: 0.0003\n",
            "Feature 726: 0.0003\n",
            "Feature 703: 0.0003\n",
            "Feature 597: 0.0003\n",
            "Feature 776: 0.0003\n",
            "Feature 181: 0.0003\n",
            "Feature 295: 0.0003\n",
            "Feature 555: 0.0003\n",
            "Feature 292: 0.0003\n",
            "Feature 457: 0.0003\n",
            "Feature 190: 0.0003\n",
            "Feature 261: 0.0003\n",
            "Feature 815: 0.0003\n",
            "Feature 299: 0.0003\n",
            "Feature 263: 0.0003\n",
            "Feature 568: 0.0003\n",
            "Feature 213: 0.0003\n",
            "Feature 762: 0.0003\n",
            "Feature 712: 0.0003\n",
            "Feature 805: 0.0003\n",
            "Feature 332: 0.0003\n",
            "Feature 693: 0.0003\n",
            "Feature 280: 0.0003\n",
            "Feature 431: 0.0003\n",
            "Feature 172: 0.0003\n",
            "Feature 233: 0.0003\n",
            "Feature 124: 0.0003\n",
            "Feature 122: 0.0003\n",
            "Feature 401: 0.0003\n",
            "Feature 434: 0.0003\n",
            "Feature 594: 0.0003\n",
            "Feature 741: 0.0003\n",
            "Feature 203: 0.0003\n",
            "Feature 583: 0.0003\n",
            "Feature 750: 0.0003\n",
            "Feature 392: 0.0003\n",
            "Feature 756: 0.0003\n",
            "Feature 471: 0.0003\n",
            "Feature 259: 0.0003\n",
            "Feature 590: 0.0003\n",
            "Feature 216: 0.0003\n",
            "Feature 218: 0.0003\n",
            "Feature 547: 0.0003\n",
            "Feature 702: 0.0003\n",
            "Feature 653: 0.0003\n",
            "Feature 700: 0.0003\n",
            "Feature 130: 0.0003\n",
            "Feature 525: 0.0003\n",
            "Feature 535: 0.0003\n",
            "Feature 496: 0.0003\n",
            "Feature 424: 0.0003\n",
            "Feature 511: 0.0003\n",
            "Feature 284: 0.0003\n",
            "Feature 335: 0.0003\n",
            "Feature 256: 0.0002\n",
            "Feature 248: 0.0002\n",
            "Feature 674: 0.0002\n",
            "Feature 628: 0.0002\n",
            "Feature 644: 0.0002\n",
            "Feature 422: 0.0002\n",
            "Feature 663: 0.0002\n",
            "Feature 384: 0.0002\n",
            "Feature 598: 0.0002\n",
            "Feature 391: 0.0002\n",
            "Feature 250: 0.0002\n",
            "Feature 185: 0.0002\n",
            "Feature 770: 0.0002\n",
            "Feature 376: 0.0002\n",
            "Feature 416: 0.0002\n",
            "Feature 538: 0.0002\n",
            "Feature 723: 0.0002\n",
            "Feature 101: 0.0002\n",
            "Feature 481: 0.0002\n",
            "Feature 667: 0.0002\n",
            "Feature 176: 0.0002\n",
            "Feature 751: 0.0002\n",
            "Feature 833: 0.0002\n",
            "Feature 390: 0.0002\n",
            "Feature 745: 0.0001\n",
            "Feature 676: 0.0001\n",
            "Feature 146: 0.0001\n",
            "Feature 186: 0.0001\n",
            "Feature 394: 0.0001\n",
            "Feature 740: 0.0001\n",
            "Feature 501: 0.0001\n",
            "Feature 453: 0.0001\n",
            "Feature 160: 0.0001\n",
            "Feature 356: 0.0001\n",
            "Feature 342: 0.0001\n",
            "Feature 104: 0.0001\n",
            "Feature 763: 0.0001\n",
            "Feature 240: 0.0001\n",
            "Feature 223: 0.0000\n",
            "Feature 230: 0.0000\n",
            "Feature 298: 0.0000\n",
            "Feature 88: 0.0000\n",
            "Feature 93: 0.0000\n",
            "Feature 100: 0.0000\n",
            "Feature 136: 0.0000\n",
            "Feature 137: 0.0000\n",
            "Feature 138: 0.0000\n",
            "Feature 158: 0.0000\n",
            "Feature 159: 0.0000\n",
            "Feature 163: 0.0000\n",
            "Feature 164: 0.0000\n",
            "Feature 177: 0.0000\n",
            "Feature 195: 0.0000\n",
            "Feature 199: 0.0000\n",
            "Feature 201: 0.0000\n",
            "Feature 205: 0.0000\n",
            "Feature 207: 0.0000\n",
            "Feature 215: 0.0000\n",
            "Feature 219: 0.0000\n",
            "Feature 227: 0.0000\n",
            "Feature 252: 0.0000\n",
            "Feature 258: 0.0000\n",
            "Feature 273: 0.0000\n",
            "Feature 277: 0.0000\n",
            "Feature 279: 0.0000\n",
            "Feature 286: 0.0000\n",
            "Feature 288: 0.0000\n",
            "Feature 289: 0.0000\n",
            "Feature 296: 0.0000\n",
            "Feature 304: 0.0000\n",
            "Feature 319: 0.0000\n",
            "Feature 346: 0.0000\n",
            "Feature 360: 0.0000\n",
            "Feature 366: 0.0000\n",
            "Feature 387: 0.0000\n",
            "Feature 396: 0.0000\n",
            "Feature 400: 0.0000\n",
            "Feature 405: 0.0000\n",
            "Feature 409: 0.0000\n",
            "Feature 410: 0.0000\n",
            "Feature 411: 0.0000\n",
            "Feature 412: 0.0000\n",
            "Feature 418: 0.0000\n",
            "Feature 426: 0.0000\n",
            "Feature 440: 0.0000\n",
            "Feature 443: 0.0000\n",
            "Feature 447: 0.0000\n",
            "Feature 450: 0.0000\n",
            "Feature 459: 0.0000\n",
            "Feature 463: 0.0000\n",
            "Feature 466: 0.0000\n",
            "Feature 469: 0.0000\n",
            "Feature 470: 0.0000\n",
            "Feature 474: 0.0000\n",
            "Feature 475: 0.0000\n",
            "Feature 484: 0.0000\n",
            "Feature 492: 0.0000\n",
            "Feature 502: 0.0000\n",
            "Feature 506: 0.0000\n",
            "Feature 510: 0.0000\n",
            "Feature 514: 0.0000\n",
            "Feature 519: 0.0000\n",
            "Feature 521: 0.0000\n",
            "Feature 534: 0.0000\n",
            "Feature 536: 0.0000\n",
            "Feature 537: 0.0000\n",
            "Feature 546: 0.0000\n",
            "Feature 548: 0.0000\n",
            "Feature 550: 0.0000\n",
            "Feature 558: 0.0000\n",
            "Feature 562: 0.0000\n",
            "Feature 566: 0.0000\n",
            "Feature 573: 0.0000\n",
            "Feature 577: 0.0000\n",
            "Feature 585: 0.0000\n",
            "Feature 595: 0.0000\n",
            "Feature 599: 0.0000\n",
            "Feature 608: 0.0000\n",
            "Feature 609: 0.0000\n",
            "Feature 612: 0.0000\n",
            "Feature 613: 0.0000\n",
            "Feature 619: 0.0000\n",
            "Feature 621: 0.0000\n",
            "Feature 632: 0.0000\n",
            "Feature 633: 0.0000\n",
            "Feature 634: 0.0000\n",
            "Feature 638: 0.0000\n",
            "Feature 639: 0.0000\n",
            "Feature 659: 0.0000\n",
            "Feature 661: 0.0000\n",
            "Feature 670: 0.0000\n",
            "Feature 682: 0.0000\n",
            "Feature 690: 0.0000\n",
            "Feature 691: 0.0000\n",
            "Feature 695: 0.0000\n",
            "Feature 698: 0.0000\n",
            "Feature 738: 0.0000\n",
            "Feature 747: 0.0000\n",
            "Feature 755: 0.0000\n",
            "Feature 764: 0.0000\n",
            "Feature 765: 0.0000\n",
            "Feature 772: 0.0000\n",
            "Feature 778: 0.0000\n",
            "Feature 781: 0.0000\n",
            "Feature 807: 0.0000\n",
            "Feature 820: 0.0000\n",
            "Feature 822: 0.0000\n",
            "Feature 823: 0.0000\n",
            "Feature 826: 0.0000\n",
            "Feature 828: 0.0000\n",
            "Feature 835: 0.0000\n",
            "Feature 841: 0.0000\n",
            "Feature 843: 0.0000\n",
            "Feature 846: 0.0000\n",
            "Feature 850: 0.0000\n",
            "Feature 857: 0.0000\n"
          ]
        }
      ],
      "source": [
        "negative_class_count = sum(y_train == 0)\n",
        "positive_class_count = sum(y_train == 1)\n",
        "scale_pos_weight = negative_class_count / positive_class_count\n",
        "\n",
        "xgb_clf = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=scale_pos_weight)\n",
        "\n",
        "print(\"Initial XGBoost Model Parameters:\")\n",
        "print(xgb_clf.get_params())\n",
        "\n",
        "xgb_clf.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"\\nXGBoost Model Parameters after Training:\")\n",
        "print(xgb_clf.get_params())\n",
        "\n",
        "xgb_y_pred = xgb_clf.predict(X_test_features)\n",
        "xgb_y_pred_proba = xgb_clf.predict_proba(X_test_features)[:, 1]\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
        "xgb_roc_auc = roc_auc_score(y_test, xgb_y_pred_proba)\n",
        "xgb_precision = precision_score(y_test, xgb_y_pred)\n",
        "xgb_recall = recall_score(y_test, xgb_y_pred)\n",
        "xgb_f1 = f1_score(y_test, xgb_y_pred)\n",
        "xgb_confusion_matrix = confusion_matrix(y_test, xgb_y_pred)\n",
        "\n",
        "print(\"\\nXGBoost Model Performance with Specific Parameters\")\n",
        "print(f\"Accuracy: {xgb_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {xgb_roc_auc:.4f}\")\n",
        "print(f\"Precision: {xgb_precision:.4f}\")\n",
        "print(f\"Recall: {xgb_recall:.4f}\")\n",
        "print(f\"F1 Score: {xgb_f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(xgb_confusion_matrix)\n",
        "\n",
        "feature_importances = xgb_clf.feature_importances_\n",
        "feature_names = X_train_features.columns if hasattr(X_train_features, 'columns') else [f'Feature {i}' for i in range(len(feature_importances))]\n",
        "\n",
        "feature_importance = sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, importance in feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
